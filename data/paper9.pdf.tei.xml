<?xml version="1.0" encoding="UTF-8"?><TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coords="1,99.98,79.85,395.73,12.90;1,134.04,95.79,327.21,12.90;5,224.56,150.48,49.77,4.74;5,221.01,155.66,17.78,4.74;5,221.01,160.85,36.76,4.74;5,286.02,133.48,34.66,5.34;5,447.57,129.03,26.67,5.34">Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-02-17">17 Feb 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.89,126.91,61.46,10.75"><forename type="first">Shao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.30,126.91,67.32,10.75"><forename type="first">Xihuai</forename><surname>Wang</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.04,126.91,77.95,10.75"><forename type="first">Wenhao</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName coords="1,391.45,126.91,59.45,10.75"><forename type="first">Chaoran</forename><surname>Li</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,134.16,140.92,59.29,10.75"><forename type="first">Junru</forename><surname>Song</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,203.90,140.92,50.62,10.75"><forename type="first">Tingyu</forename><surname>Li</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.98,140.92,40.20,10.75"><forename type="first">Lin</forename><surname>Qiu</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1" coords="1,251.80,183.30,42.84,10.37">
								<note type="raw_affiliation"><label>2</label> Meituan ,</note>
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.65,140.92,59.44,10.75"><forename type="first">Xuezhi</forename><surname>Cao</surname></persName>
							<affiliation key="aff1" coords="1,251.80,183.30,42.84,10.37">
								<note type="raw_affiliation"><label>2</label> Meituan ,</note>
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,385.55,140.92,68.10,10.75"><forename type="first">Xunliang</forename><surname>Cai</surname></persName>
							<affiliation key="aff1" coords="1,251.80,183.30,42.84,10.37">
								<note type="raw_affiliation"><label>2</label> Meituan ,</note>
								<address>
									<settlement>Meituan</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,153.36,154.94,45.69,10.75"><forename type="first">Wen</forename><surname>Yao</surname></persName>
							<affiliation key="aff2" coords="1,302.11,183.30,202.53,10.37">
								<note type="raw_affiliation"><label>3</label> Intelligent Game and Decision Laboratory</note>
								<orgName type="laboratory">Intelligent Game and Decision Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,209.52,154.94,75.29,10.75"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.27,154.94,73.97,10.75"><forename type="first">Xinbing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.70,154.94,50.26,10.75"><forename type="first">Ying</forename><surname>Wen</surname></persName>
							<affiliation key="aff0" coords="1,95.12,183.30,149.21,10.37">
								<note type="raw_affiliation"><label>1</label> Shanghai Jiao Tong University ,</note>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coords="1,99.98,79.85,395.73,12.90;1,134.04,95.79,327.21,12.90;5,224.56,150.48,49.77,4.74;5,221.01,155.66,17.78,4.74;5,221.01,160.85,36.76,4.74;5,286.02,133.48,34.66,5.34;5,447.57,129.03,26.67,5.34">Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-02-17">17 Feb 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">6B057255C938C7D3C47DBF8CD7D8F5D9</idno>
					<idno type="arXiv">arXiv:2502.11882v1[cs.AI]</idno>
					<note type="submission">: [......]}, Action: {'You': ('assemble', {'food': 'BeefBurger'})}, Delivery: {......}, Missed Orders: {.......}</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-02-18T10:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s coords="1,87.87,249.46,184.92,8.64;1,87.87,261.41,185.90,8.64;1,87.87,273.37,184.25,8.64;1,87.87,285.32,129.14,8.64">Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction.</s><s coords="1,226.43,285.32,47.34,8.64;1,87.87,297.28,184.25,8.64;1,87.87,309.23,184.25,8.64;1,87.87,321.19,185.90,8.64;1,87.87,333.14,22.31,8.64">Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions.</s><s coords="1,116.65,333.14,157.12,8.64;1,87.87,344.92,185.50,8.82;1,87.52,357.05,186.27,8.64;1,87.87,369.01,161.96,8.64">Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks.</s><s coords="1,258.82,369.01,13.31,8.64;1,87.87,380.96,184.25,8.64;1,87.87,392.74,185.91,8.82;1,87.87,404.69,184.25,8.82;1,87.87,416.83,102.69,8.64">We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration.</s><s coords="1,200.47,416.65,73.31,8.59;1,87.87,428.60,184.25,8.82;1,87.87,440.74,185.90,8.64;1,87.87,452.69,93.78,8.64">DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making.</s><s coords="1,188.53,452.52,83.59,8.59;1,87.63,464.47,186.15,8.82;1,87.87,476.60,184.25,8.64;1,87.87,488.56,185.90,8.64;1,87.87,500.51,30.77,8.64">DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions.</s><s coords="1,123.52,500.51,148.61,8.64;1,87.87,512.47,184.25,8.64;1,87.87,524.43,185.49,8.64;1,87.87,536.38,185.90,8.64;1,87.87,548.34,132.52,8.64">We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks.</s><s coords="1,226.12,548.34,46.01,8.64;1,87.87,560.29,185.91,8.64;1,87.87,572.25,185.90,8.64;1,87.87,584.20,185.90,8.64;1,87.87,596.16,74.81,8.64">To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1" coords="1,70.87,645.37,82.81,10.75">Introduction</head><p><s coords="1,70.87,669.17,220.08,9.46;1,70.87,682.72,218.27,9.46;1,70.87,696.27,220.08,9.46;1,70.87,709.82,132.00,9.46">Large language models (LLMs) have revolutionized generalization capabilities and interaction methods, driving the application of human-AI collaboration in real-world tasks.</s><s coords="1,206.25,709.82,82.89,9.46;1,70.87,723.37,218.65,9.46;1,306.14,395.58,220.07,9.46;1,306.14,409.13,219.63,9.46;1,306.14,422.68,220.08,9.46;1,306.14,436.23,35.54,9.46">LLM-based agents have already been successfully applied to many collaborative tasks with humans, such as writing <ref type="bibr" coords="1,323.71,409.13,81.48,9.46" target="#b38">(Wan et al., 2024)</ref> and coding <ref type="bibr" coords="1,461.60,409.13,64.17,9.46;1,306.14,422.68,23.65,9.46" target="#b26">(Prather et al., 2024)</ref>, where humans and the agents interact turnby-turn.</s><s coords="1,350.40,436.23,174.02,9.46;1,306.14,449.78,218.26,9.46;1,306.14,463.33,218.27,9.46;1,306.14,476.88,218.26,9.46;1,306.14,490.43,67.51,9.46">However, many collaborative tasks in shared workspaces require entities involved in the collaboration to cooperate simultaneously in the environment <ref type="bibr" coords="1,364.06,476.88,103.56,9.46" target="#b32">(Salikutluk et al., 2024;</ref><ref type="bibr" coords="1,470.34,476.88,54.07,9.46;1,306.14,490.43,62.73,9.46" target="#b8">Dourish and Bellotti, 1992)</ref>.</s><s coords="1,377.03,490.43,147.38,9.46;1,306.14,503.98,218.26,9.46;1,306.14,517.53,220.08,9.46;1,306.14,531.08,218.27,9.46;1,306.14,544.62,218.27,9.46;1,306.14,558.17,220.08,9.46;1,306.14,571.72,191.84,9.46">Unlike turn-by-turn collaborative tasks, the simultaneous collaboration tasks that are time-sensitive require real-time responses to partners and interaction with the environment <ref type="bibr" coords="1,498.45,531.08,25.96,9.46;1,306.14,544.62,49.75,9.46" target="#b33">(Shao et al., 2024;</ref><ref type="bibr" coords="1,358.21,544.62,74.49,9.46" target="#b11">Gong et al., 2024)</ref>, as well as reasoning about dynamically changing human partners' strategies and environments <ref type="bibr" coords="1,409.25,571.72,83.95,9.46" target="#b39">(Wang et al., 2024)</ref>.</s><s coords="1,502.16,571.72,22.25,9.46;1,306.14,585.27,218.27,9.46;1,306.14,598.40,218.26,9.88;1,306.14,611.94,218.27,9.81;1,306.14,625.49,91.83,9.81">Such simultaneous human-AI collaboration tasks present two challenges for LLM-based agents: real-time responsiveness and autonomous collaboration adapted to humans.</s></p><p><s coords="1,317.05,643.79,207.73,9.46;1,306.14,657.34,220.07,9.46;1,306.14,670.89,32.45,9.46">The real-time responsiveness issues faced by LLMs in inference time have been widely discussed.</s><s coords="1,346.43,670.89,177.98,9.46;1,306.14,684.44,218.65,9.46;1,305.78,697.99,218.63,9.46;1,306.14,711.54,218.27,9.46;1,306.14,725.09,218.27,9.46;1,306.14,738.63,43.02,9.46">Larger models with stronger reasoning capabilities often suffer from significant latency <ref type="bibr" coords="1,305.78,697.99,84.41,9.46" target="#b52">(Zhou et al., 2024)</ref>, making it difficult for them to respond quickly to dynamic changes in human interactions and environments in highly real-time scenarios.</s><s coords="1,352.55,738.63,173.67,9.46;1,306.14,751.99,218.27,9.66;1,306.14,765.73,218.27,9.46;2,70.87,74.72,218.27,9.46;2,70.87,88.27,218.27,9.46;2,70.87,101.82,220.08,9.46;2,70.47,115.37,115.19,9.46">The combination of fast and slow thinking using System 1 and System 2 based on Dual Process Theory (DPT) <ref type="bibr" coords="1,410.75,765.73,83.39,9.46" target="#b16">(Kahneman, 2011;</ref><ref type="bibr" coords="1,497.49,765.73,26.93,9.46;2,70.87,74.72,94.61,9.46" target="#b9">Evans and Stanovich, 2013)</ref> has already been applied to address real-time issues via the combination of large and small models in language agent frameworks <ref type="bibr" coords="2,100.81,115.37,79.96,9.46">(Liu et al., 2024b)</ref>.</s><s coords="2,190.63,115.37,98.51,9.46;2,70.87,128.92,220.08,9.46;2,70.87,142.47,218.27,9.46;2,70.87,155.82,113.63,9.66">However, this method still cannot resolve the contradiction between latency and performance fundamentally, as it uses small models as System 1.</s></p><p><s coords="2,81.78,169.57,209.17,9.46;2,70.87,183.12,218.26,9.46;2,70.87,196.67,220.08,9.46;2,70.87,210.22,67.11,9.46">The agent frameworks designed for collaborating with humans also face challenges of insufficient autonomy and difficulty in adapting to human strategy variability.</s><s coords="2,144.18,210.22,144.96,9.46;2,70.87,223.76,218.27,9.46;2,70.87,237.31,191.78,9.46">Agents in the shared workspace tasks are regarded as independent collaborators joining the partnership <ref type="bibr" coords="2,173.69,237.31,84.20,9.46" target="#b7">(Dafoe et al., 2021)</ref>.</s><s coords="2,266.03,237.31,24.91,9.46;2,70.87,250.86,220.08,9.46;2,70.87,264.41,218.27,9.46;2,70.51,277.96,218.63,9.46;2,70.87,291.51,178.80,9.46">However, most collaborative agent frameworks still require human input to output actions or strategies <ref type="bibr" coords="2,70.51,277.96,83.23,9.46">(Liu et al., 2024b;</ref><ref type="bibr" coords="2,157.58,277.96,81.20,9.46" target="#b12">Guan et al., 2023)</ref>, failing to collaborate with humans autonomously.</s><s coords="2,254.70,291.51,36.24,9.46;2,70.87,305.06,220.08,9.46;2,70.87,318.61,218.27,9.46;2,70.47,332.16,218.66,9.46;2,70.87,345.71,218.26,9.46;2,70.51,359.26,218.63,9.46;2,70.87,372.81,220.18,9.46">Furthermore, humans in shared workspace tasks might perceive and engage with agents like how they interact with human partners for fostering collaboration like inferring agents' intentions to adjust strategies <ref type="bibr" coords="2,70.51,359.26,91.19,9.46" target="#b50">(Zhang et al., 2024b)</ref>, which further enhances the challenge of simultaneous human-AI collaboration.</s><s coords="2,70.87,386.36,220.08,9.46;2,70.87,399.90,220.08,9.46;2,70.87,413.45,220.07,9.46;2,70.87,427.00,218.27,9.46;2,70.87,440.55,197.12,9.46">Researchers also point out that LLMs are still limited in their ability to adapt to dynamic human strategy changes <ref type="bibr" coords="2,128.89,413.45,92.07,9.46">(Zhang et al., 2024c)</ref>, making it difficult to transition reasoning into decision-making for effective adaptation <ref type="bibr" coords="2,174.67,440.55,88.62,9.46" target="#b30">(Riemer et al., 2024)</ref>.</s></p><p><s coords="2,81.78,454.10,207.36,9.46;2,70.87,467.65,218.65,9.46;2,70.51,481.00,220.44,9.66;2,70.87,494.55,160.81,9.66">To address these challenges, we propose DPT-Agent, which leverages Dual Process Theory (DPT) to integrate FSM-based System 1 and LLMdriven System 2, as shown in Figure <ref type="figure" coords="2,223.66,494.75,4.01,9.46" target="#fig_0">1</ref>.</s><s coords="2,234.87,494.75,54.27,9.46;2,70.87,508.30,220.07,9.46;2,70.87,521.65,220.08,9.66;2,70.87,535.40,218.27,9.46;2,70.87,548.95,218.65,9.46;2,70.51,562.30,218.62,9.66;2,70.87,576.04,220.18,9.46">Based on the intuitive thinking and fast decision-making characteristics of System 1, we use a Finite-state Machine (FSM) for low-level action decision-making and execution, while employing a code-as-policy <ref type="bibr" coords="2,70.51,562.49,84.35,9.46" target="#b22">(Liang et al., 2023)</ref> approach to enable System 2's slow thinking to guide and control fast decisions.</s><s coords="2,70.87,589.40,218.65,9.66;2,70.87,603.14,218.27,9.46;2,70.87,616.69,218.27,9.46;2,70.87,630.24,218.27,9.46;2,70.87,643.79,218.27,9.46;2,70.51,657.34,146.26,9.46">For slow thinking (System 2), we design a Theory of Mind (ToM) mechanism for actively inferring human intentions and reflecting on environmental feedback based on how humans infer the partners and situations in shared workspace collaboration <ref type="bibr" coords="2,70.51,657.34,141.47,9.46" target="#b17">(Krych-Appelbaum et al., 2007)</ref>.</s><s coords="2,220.71,657.34,68.61,9.46;2,70.87,670.89,220.08,9.46;2,70.87,684.44,218.46,9.46;2,70.87,697.99,119.36,9.46">We also further improve the performance of the reflection mechanism with an asynchronous design to achieve better efficiency in self-evolution.</s></p><p><s coords="2,81.78,711.54,209.17,9.46;2,70.87,725.09,218.27,9.46;2,70.87,738.63,218.27,9.46;2,70.87,752.18,218.27,9.46;2,70.47,765.73,218.66,9.46;2,306.14,74.72,218.27,9.46;2,306.14,88.27,37.40,9.46">Building on the shared workspace task environment which is a hard version of Overcooked from <ref type="bibr" coords="2,70.87,738.63,84.09,9.46" target="#b50">Zhang et al. (2024b)</ref>, we further develop a real-time simultaneous human-AI collaboration environment with new layouts and conduct multiple experiments in single agent setup, with rule-based agent and real humans.</s><s coords="2,348.78,88.27,175.63,9.46;2,306.14,101.82,220.08,9.46;2,306.14,115.37,220.08,9.46;2,306.14,128.92,220.08,9.46;2,306.14,142.47,25.66,9.46">We aim to understand: 1) DPT-Agent's capability in real-time tasks, 2) DPT-Agent's capability in collaboration, and 3) DPT-Agent's performance in collaboration with humans simultaneously.</s></p><p><s coords="2,317.05,156.11,207.36,9.46;2,306.14,169.66,218.27,9.46;2,306.14,183.21,82.74,9.46">In the experiments collaborating with rule-based agents, DPT-Agent outperforms strong language agent frameworks.</s><s coords="2,393.37,183.21,131.05,9.46;2,306.14,196.76,220.08,9.46;2,306.14,210.31,220.08,9.46;2,306.14,223.85,220.07,9.46;2,306.14,237.40,220.07,9.46;2,306.14,250.95,25.76,9.46">When collaborating with real humans, DPT-Agent also outperforms these baselines in both subjective and objective results, showing the significant improvement brought by asynchronous reflection and ToM module to infer humans.</s></p><p><s coords="2,317.05,264.59,197.87,9.46">In summary, our contributions are as follows:</s></p><p><s coords="2,319.16,282.48,207.06,9.46;2,327.96,295.84,196.45,9.66;2,327.96,309.58,198.25,9.46;2,327.96,323.13,163.94,9.46">• We experimentally analyze LLMs independently as System 1 and System 2 in real-time tasks, highlighting the challenge of the tradeoff between performance and latency.</s></p><p><s coords="2,319.16,341.02,207.06,9.46;2,327.96,354.38,198.26,9.66;2,327.96,367.93,198.26,9.66;2,327.96,381.67,198.27,9.46;2,327.96,395.22,142.21,9.46">• We propose DPT-Agent that integrates FSMbased System 1 for fast and intuitive decisionmaking and LLM-driven System 2 for deliberate and analytical reasoning, effectively balancing latency and performance.</s></p><p><s coords="2,319.16,413.11,207.06,9.46;2,327.96,426.66,198.27,9.46;2,327.96,440.21,196.45,9.46;2,327.96,453.76,198.26,9.46;2,327.96,467.31,143.91,9.46">• We conduct extensive experiments with rulebased agents and human participants, demonstrating that DPT-Agent outperforms existing language agent frameworks in real-time simultaneous human-AI collaboration.</s></p><p><s coords="2,317.05,490.19,207.36,9.46;2,306.14,503.73,218.27,9.46;2,306.14,517.28,220.08,9.46;2,306.14,530.83,219.63,9.46;2,305.75,544.38,217.43,9.46">To the best of our knowledge, DPT-Agent is the first agent framework that can achieve successful real-time simultaneous human-AI collaboration autonomously in the hard version of Overcooked, which is one step closer to real-world application.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2" coords="2,306.14,567.31,93.74,10.75">Related Works</head><p><s coords="2,306.14,589.17,129.61,9.81">Dual Process Theory (DPT).</s><s coords="2,446.66,589.59,79.55,9.46;2,306.14,603.14,218.27,9.46;2,306.14,616.69,220.08,9.46;2,306.14,630.04,220.08,9.66;2,306.14,643.59,219.63,9.66;2,306.14,657.34,152.34,9.46">Dual Process Theory (DPT) <ref type="bibr" coords="2,355.47,603.14,128.89,9.46" target="#b9">(Evans and Stanovich, 2013)</ref> refers to human cognition operates through two distinct systems: System 1, which is fast, automatic, and intuitive, and System 2, which is slower, deliberate, and analytical <ref type="bibr" coords="2,371.86,657.34,81.84,9.46" target="#b16">(Kahneman, 2011)</ref>.</s><s coords="2,463.27,657.34,61.14,9.46;2,306.14,670.89,218.26,9.46;2,306.14,684.44,36.15,9.46">DPT explains how humans think during the perception-decision process.</s><s coords="2,348.80,684.24,177.42,9.66;2,306.14,697.79,220.08,9.66;2,306.14,711.54,196.28,9.46">The ability to effectively integrate System 1 and System 2 helps humans accomplish complex perception and decision-making tasks.</s><s coords="2,508.91,711.54,17.30,9.46;2,306.14,725.09,220.08,9.46;2,306.14,738.63,218.27,9.46;2,306.14,752.18,218.64,9.46;2,306.14,765.54,218.27,9.66;3,70.87,74.72,64.17,9.46">Numerous LLM-based reasoning frameworks also utilized DPT to facilitate human-related interactions like dialogue <ref type="bibr" coords="2,364.67,752.18,70.30,9.46" target="#b15">(He et al., 2024)</ref> and mitigate latency issues via using a small model as System 1 <ref type="bibr" coords="2,505.25,765.73,19.16,9.46;3,70.87,74.72,59.27,9.46">(Liu et al., 2024b)</ref>.</s><s coords="3,142.60,74.72,146.54,9.46;3,70.87,88.08,220.07,9.65;3,70.87,101.82,218.27,9.46;3,70.87,115.37,218.27,9.46;3,70.87,128.92,220.08,9.46;3,70.87,142.47,104.17,9.46">Many current agent frameworks use System 2-based approaches to assist with planning and decision-making <ref type="bibr" coords="3,187.79,101.82,70.52,9.46" target="#b48">(Yu et al., 2024;</ref><ref type="bibr" coords="3,261.04,101.82,28.10,9.46;3,70.87,115.37,53.70,9.46">Zhang et al., 2024c)</ref>, such as chain-of-thought (CoT) <ref type="bibr" coords="3,268.64,115.37,20.49,9.46;3,70.87,128.92,50.24,9.46" target="#b40">(Wei et al., 2022)</ref>, ReAct <ref type="bibr" coords="3,159.22,128.92,73.75,9.46" target="#b45">(Yao et al., 2022)</ref>, and Reflexion <ref type="bibr" coords="3,87.66,142.47,82.64,9.46" target="#b34">(Shinn et al., 2024)</ref>.</s><s coords="3,178.42,142.47,111.09,9.46;3,70.87,155.82,218.81,9.66;3,70.87,169.57,218.27,9.46;3,70.87,182.92,213.62,9.66">DPT-Agent is inspired by DPT, further alleviating latency issues in System 1 and endowing the agent with greater autonomy and adaptability to humans in the design of System 2.</s></p><p><s coords="3,70.87,204.32,185.16,9.81">Simultaneous Human-AI Collaboration.</s><s coords="3,266.93,204.75,22.20,9.46;3,70.87,218.30,218.27,9.46;3,70.87,231.85,220.08,9.46;3,70.87,245.39,218.27,9.46;3,70.51,258.94,218.63,9.46;3,70.87,272.49,220.08,9.46;3,70.87,286.04,19.90,9.46">Most tasks related to LLMs in human-AI collaboration research pose lower demands on real-time responsiveness, such as task-oriented dialogue systems <ref type="bibr" coords="3,70.51,258.94,74.45,9.46" target="#b46">(Yi et al., 2024)</ref> and word-guessing <ref type="bibr" coords="3,239.07,258.94,50.06,9.46;3,70.87,272.49,52.38,9.46" target="#b2">(Ashktorab et al., 2021)</ref>, where players take actions turn-byturn.</s><s coords="3,94.09,286.04,195.04,9.46;3,70.87,299.59,220.08,9.46;3,70.87,313.14,218.65,9.46;3,70.87,326.69,199.23,9.46">However, collaborative tasks in the real world are often simultaneous, requiring real-time reasoning, which presents latency challenges for many LLM-based frameworks <ref type="bibr" coords="3,181.72,326.69,78.80,9.46" target="#b22">(Liang et al., 2023</ref>).</s><s coords="3,273.64,326.69,17.30,9.46;3,70.87,340.24,220.08,9.46;3,70.87,353.79,220.08,9.46;3,70.87,367.34,218.27,9.46;3,70.87,380.89,219.17,9.46;3,70.87,394.44,88.34,9.46">Another significant challenge of simultaneous collaborative tasks is adapting to humans, who are unfamiliar partners not encountered during training <ref type="bibr" coords="3,260.80,367.34,28.33,9.46;3,70.87,380.89,54.35,9.46" target="#b39">(Wang et al., 2024;</ref><ref type="bibr" coords="3,128.89,380.89,67.91,9.46" target="#b19">Li et al., 2023;</ref><ref type="bibr" coords="3,200.49,380.89,89.55,9.46" target="#b5">Carroll et al., 2019;</ref><ref type="bibr" coords="3,70.87,394.44,83.72,9.46">Zhang et al., 2024a)</ref>.</s><s coords="3,162.55,394.44,128.40,9.46;3,70.87,407.99,218.26,9.46;3,70.87,421.53,220.07,9.46;3,70.47,435.08,220.56,9.46">Theory of Mind (ToM) <ref type="bibr" coords="3,263.63,394.44,22.76,9.46;3,70.87,407.99,84.05,9.46" target="#b28">(Rabinowitz et al., 2018;</ref><ref type="bibr" coords="3,157.64,407.99,114.14,9.46" target="#b3">Baron-Cohen et al., 1985)</ref> has been introduced to enhance reasoning in human-AI collaborative scenarios <ref type="bibr" coords="3,193.80,435.08,92.45,9.46" target="#b42">(Wester et al., 2024)</ref>.</s><s coords="3,70.87,448.63,218.27,9.46;3,70.87,462.18,219.63,9.46;3,70.47,475.73,218.66,9.46;3,70.87,489.28,129.29,9.46">However, studies have pointed out that LLMs fail to achieve functional ToM <ref type="bibr" coords="3,193.33,462.18,92.37,9.46" target="#b30">(Riemer et al., 2024)</ref>, where reasoning cannot be effectively implemented in decision-making processes.</s><s coords="3,203.53,489.28,86.96,9.46;3,70.87,502.83,218.26,9.46;3,70.87,516.38,218.27,9.46;3,70.87,529.93,218.27,9.46;3,70.87,543.48,140.26,9.46">To adapt to humans, DPT-Agent integrates DPT and ToM to support the entire process from perception to reasoning and decision-making, achieving functional ToM while ensuring real-time performance.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3" coords="3,70.87,566.81,205.70,10.75">Why We Need Dual Process Theory?</head><p><s coords="3,70.53,589.39,218.61,9.46;3,70.87,602.94,220.08,9.46;3,70.87,616.48,220.08,9.46;3,70.87,630.03,218.27,9.46;3,70.51,643.39,218.63,9.66;3,70.87,657.13,30.60,9.46">To understand the necessity of DPT in real-time simultaneous human-AI collaboration, we first examine the real-time responsiveness and task completion capabilities of using large language models (LLMs) independently as System 1 and System 2 agents.</s></p><p><s coords="3,81.78,670.89,208.73,9.46;3,70.87,684.24,218.27,9.66;3,70.51,697.79,218.62,9.66;3,70.87,711.34,220.08,9.66;3,70.87,725.09,218.27,9.46;3,70.87,738.63,173.10,9.46">In the Overcooked environment <ref type="bibr" coords="3,229.35,670.89,61.16,9.46;3,70.87,684.44,29.29,9.46" target="#b50">(Zhang et al., 2024b)</ref>, we employ a single-agent setup, Counter Circuit (shown on the left in Figure <ref type="figure" coords="3,226.43,697.99,3.89,9.46" target="#fig_2">4</ref>), to compare the performance of typical LLM-based System 1only agents using mainstream LLMs of varying sizes with that of an FSM-based agent.</s><s coords="3,247.67,738.63,43.27,9.46;3,70.87,752.18,218.27,9.46;3,70.87,765.73,219.63,9.46;3,305.75,282.08,218.66,9.66;3,306.14,295.82,118.78,9.46">Additionally, we include the DeepSeek-R1 series reasoning model <ref type="bibr" coords="3,102.11,765.73,75.55,9.46" target="#b13">(Guo et al., 2025</ref>) and OpenAI's o3-mini, which incorporate System 2 capabilities with long CoT as agents for this task.</s></p><p><s coords="3,317.05,309.76,209.17,9.66;3,306.14,323.50,220.08,9.46;3,306.14,337.05,218.27,9.46;3,306.14,350.60,45.51,9.46">To evaluate the performance of the System 1only agents in real-time task completion, we assess action output latency, task score, and score efficiency.</s><s coords="3,355.79,350.60,169.98,9.46;3,306.14,364.15,220.08,9.46;3,306.14,377.70,218.26,9.46;3,306.14,391.25,136.66,9.46">Each model is evaluated over 20 runs, using the same game introduction prompt (Appendix B), instruction prompt (Appendix C.1), and output prompt (Appendix D.1).</s></p><p><s coords="3,317.05,405.38,209.17,9.46;3,305.87,418.73,219.90,9.66;3,306.14,432.48,218.27,9.46;3,306.14,446.03,219.63,9.46;3,306.14,459.58,220.18,9.46">As shown in Figure <ref type="figure" coords="3,410.72,405.38,4.17,9.46" target="#fig_1">2</ref>, with detailed data provided in Appendix G, as independent System 1, models with fewer than 20B parameters excel in latency but often have near-zero score efficiency, indicating fast responses but ineffective actions.</s><s coords="3,306.14,473.13,218.27,9.46;3,306.14,486.68,218.27,9.46;3,306.14,500.23,80.15,9.46">Since missed orders lead to score deductions, some high-score-efficiency models with high latency still score below zero.</s><s coords="3,393.21,500.23,131.20,9.46;3,306.14,513.77,218.66,9.46;3,306.14,527.32,100.99,9.46">The models that can balance capability in generating scoring actions with low latency perform better.</s><s coords="3,410.82,527.32,115.40,9.46;3,306.14,540.68,218.45,9.66;3,306.14,554.42,218.27,9.46;3,306.14,567.97,218.27,9.46;3,306.14,581.52,220.08,9.46;3,306.14,594.87,218.26,9.66;3,305.75,608.62,117.15,9.46">When the reasoning models use long CoT as the System 2, despite their stronger reasoning capabilities, their performance presents even lower score efficiency and overall scores compared to many smaller models functioning as System 1. Additionally, all agents perform worse than the FSM agent.</s></p><p><s coords="3,317.05,622.75,209.17,9.46;3,306.14,636.10,218.27,9.66;3,306.14,649.85,220.07,9.46;3,306.14,663.40,220.17,9.46">These results show that LLM-based independent System 1 and System 2 agents struggle with low-latency models lacking capability and highcapability models suffering from excessive latency.</s><s coords="3,305.80,676.95,220.41,9.46;3,305.75,690.30,218.66,9.66;3,306.14,704.05,176.17,9.46">This phenomenon highlights the need for a framework to integrate System 1 and System 2, balancing capability and latency in real-time tasks.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4" coords="3,306.14,728.68,135.02,10.75">DPT-Agent Framework</head><p><s coords="3,305.80,752.18,220.42,9.46;3,306.14,765.73,218.27,9.46;4,70.87,74.30,218.27,9.88;4,70.87,87.85,220.18,9.88">To enable real-time responsiveness and seamless autonomous collaboration that aligns with human cognitive processes, we propose Dual Process Theory Agent framework (DPT-Agent).</s><s coords="4,70.87,101.63,220.08,9.66;4,70.87,115.17,219.63,9.66;4,70.47,128.92,207.84,9.46">DPT-Agent integrates both System 1, which facilitates fast, intuitive decision-making, and System 2, which supports deliberate, analytical reasoning.</s></p><p><s coords="4,70.87,151.99,61.06,9.81">Formulation.</s><s coords="4,142.83,152.41,146.30,9.46;4,70.87,165.96,220.08,9.46;4,70.87,179.51,220.08,9.46;4,70.87,193.06,76.41,9.46">We model real-time simultaneous human-AI collaboration as a two-agent decentralized Markov decision process (DEC-MDP) <ref type="bibr" coords="4,262.47,179.51,23.73,9.46;4,70.87,193.06,71.81,9.46" target="#b4">(Bernstein et al., 2002)</ref>.</s><s coords="4,150.61,193.06,138.52,9.46;4,70.87,206.26,54.74,9.81;4,125.60,204.31,2.88,6.99;4,128.99,206.26,24.47,9.57;4,153.45,204.31,4.88,6.99;4,158.83,206.26,130.30,9.81;4,70.87,219.81,38.64,9.81;4,109.50,217.86,2.88,6.99;4,115.61,219.81,27.33,9.81;4,142.94,217.86,4.88,6.99;4,151.04,220.16,138.09,9.46;4,70.87,233.36,218.27,9.81;4,70.87,246.91,220.08,9.81;4,70.87,260.46,83.90,9.81;4,154.76,258.51,2.88,6.99;4,159.73,260.46,18.78,9.57;4,178.50,258.51,4.88,6.99;4,186.38,260.81,104.12,9.46;4,70.87,274.01,201.27,10.18">The framework is defined by the tuple ⟨S, {A i }, {A h }, ρ, P, r⟩ where S is the state space, A i and A h denote the agent's and human's action spaces, ρ : S → [0, 1] is the initial state distribution, P : S × A × S → [0, 1] governs transitions with A = A i × A h as the joint action space, and r : S × A → R is the reward function.</s><s coords="4,278.01,274.36,11.13,9.46;4,70.87,287.56,161.96,9.81;4,232.82,285.61,2.88,6.99;4,232.82,292.26,3.06,6.99;4,239.41,287.56,19.02,9.57;4,258.42,285.61,2.88,6.99;4,264.53,287.91,24.60,9.46;4,70.87,301.11,98.67,9.81;4,169.54,299.15,4.88,6.99;4,169.54,305.81,3.06,6.99;4,178.36,301.11,19.43,9.57;4,197.79,299.15,4.88,6.99;4,206.12,301.46,84.82,9.46;4,70.87,314.66,143.66,10.63;4,214.52,312.70,2.88,6.99;4,214.52,319.36,3.06,6.99;4,218.08,314.66,10.62,9.57;4,228.69,312.70,4.88,6.99;4,228.69,319.36,3.06,6.99;4,234.07,314.66,55.06,9.81;4,70.87,328.20,169.69,10.63">At each timestep t, the agent executes a i t ∈ A i while the human performs a h t ∈ A h simultaneously, inducing the joint action a t = (a i t , a h t ) that drives state transitions through P(s t+1 |s t , a t ).</s><s coords="4,243.84,328.55,45.48,9.46;4,70.87,342.10,218.27,9.46;4,70.87,355.65,98.81,9.46">We further develop modular formulations for DPT-Agent in the following sections.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1" coords="4,70.87,380.19,190.65,9.81;4,95.41,393.74,48.49,9.81">System 2: Deliberate and Analytical Reasoning</head><p><s coords="4,70.35,413.12,219.16,9.46;4,70.87,426.48,220.07,9.66;4,70.87,440.22,141.10,9.46">When facing complex situations, humans often rely on System 2 to process large amounts of information to aid decision-making.</s><s coords="4,218.15,440.22,70.99,9.46;4,70.87,453.57,220.08,9.66;4,70.87,467.32,218.27,9.46;4,70.87,480.87,218.27,9.46;4,70.87,494.42,218.27,9.46;4,70.47,507.97,201.33,9.46">Inspired by this process, we designed System 2 for DPT-Agent, integrating environmental feedback for Theory of Mind and self-evolution-based inference, which aims to enable advanced reasoning and planning while dynamically adapting to human partners.</s><s coords="4,275.17,507.97,13.96,9.46;4,70.87,521.52,219.63,9.46;4,70.87,535.07,218.27,9.46;4,70.87,548.62,210.39,9.46">We also refine the reflection mechanism <ref type="bibr" coords="4,233.82,521.52,56.68,9.46;4,70.87,535.07,24.94,9.46" target="#b34">(Shinn et al., 2024)</ref> by using asynchronous reflection to facilitate efficient and flexible self-evolution of strategies.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1" coords="4,70.87,571.68,206.69,9.81">Theory of Mind for Inferring Human</head><p><s coords="4,70.87,589.59,220.07,9.46;4,70.87,603.14,218.27,9.46;4,70.87,616.69,220.08,9.46;4,70.87,630.24,218.27,9.46;4,70.87,643.79,219.63,9.46;4,70.05,657.34,27.76,9.46">Equipped with the Theory of Mind (ToM) capability, individuals can infer others' mental states as beliefs by analyzing their actions and communication history, allowing them to understand and anticipate their behaviors <ref type="bibr" coords="4,183.28,643.79,107.22,9.46;4,70.05,657.34,23.13,9.46" target="#b27">(Premack and Woodruff, 1978)</ref>.</s><s coords="4,101.20,657.34,189.74,9.46;4,70.87,670.89,218.65,9.46;4,70.87,684.44,220.08,9.46;4,70.87,697.99,165.47,9.46">In the context of ToM, belief refers to an individual's perception of events, which subsequently shapes their actions <ref type="bibr" coords="4,157.77,684.44,114.93,9.46" target="#b3">(Baron-Cohen et al., 1985;</ref><ref type="bibr" coords="4,275.45,684.44,10.33,9.46;4,70.87,697.99,88.92,9.46" target="#b28">Rabinowitz et al., 2018;</ref><ref type="bibr" coords="4,162.00,697.99,69.74,9.46" target="#b41">Wen et al., 2019)</ref>.</s><s coords="4,239.55,697.99,49.58,9.46;4,70.87,711.54,218.27,9.46;4,70.87,725.09,220.08,9.46;4,70.87,738.63,218.27,9.46;4,70.87,752.18,195.73,9.46">We develop a Theory of Mind module that enables the agent to construct a belief about the human, encompassing aspects such as tendencies, conventions, and plans, based on observed human behaviors.</s><s coords="4,271.84,752.18,17.30,9.46;4,70.87,765.73,218.27,9.46;4,306.14,74.72,218.27,9.46;4,305.87,88.08,203.60,9.65">The belief output from the ToM module influences the strategy by guiding both the strategy reflection in System 2 and the decision-making in System 1.</s></p><p><s coords="4,317.05,102.17,207.36,9.46;4,306.14,115.37,218.27,9.81;4,306.14,128.92,218.27,10.63;4,306.14,142.47,30.16,10.63;4,336.30,140.52,2.88,6.99;4,336.30,147.40,4.23,6.99;4,341.03,142.47,10.62,9.57;4,351.65,140.52,4.88,6.99;4,351.65,147.40,4.23,6.99;4,357.03,142.47,36.32,10.63">To formulate the ToM process, we denote the history from time-step 0 to time-step t of the game that the agent perceives as τ 0:t = {(s 0 , a i 0 , a h 0 , r 0 ), . . .</s><s coords="4,395.17,142.47,28.37,10.63;4,423.54,140.52,2.88,6.99;4,423.54,147.17,3.06,6.99;4,427.10,142.47,10.62,9.57;4,437.71,140.52,4.88,6.99;4,437.71,147.17,3.06,6.99;4,443.09,142.47,25.81,10.63">, (s t , a i t , a h t , r t )}.</s><s coords="4,472.54,142.82,52.24,9.46;4,306.14,156.02,220.08,10.63;4,306.14,169.92,220.08,9.46;4,306.14,183.47,218.27,9.46;4,306.14,197.02,218.27,9.46;4,306.14,210.57,60.22,9.46">The Theory of Mind module takes in the history τ 0:t , summarizes the history, infers the conventions and tendencies of the human, and explains how the agent's policy can be adjusted to coordinate better with the human player.</s><s coords="4,369.61,210.57,154.79,9.46;4,306.14,224.12,220.18,9.46">The Theory of Mind module outputs the belief in natural language, as shown in Figure <ref type="figure" coords="4,518.30,224.12,4.01,9.46" target="#fig_10">3</ref>.</s><s coords="4,305.80,237.32,220.42,9.81;4,306.14,250.86,36.63,9.81;4,342.77,248.91,5.14,6.99;4,351.44,250.86,70.91,10.63;4,422.34,248.91,15.96,6.99;4,443.80,250.86,38.73,9.81;4,482.53,248.91,15.96,6.99;4,501.60,251.21,22.81,9.46;4,306.14,264.41,218.27,10.63;4,305.75,277.96,192.85,9.81">The n-th ToM process execution can be formalized as b n = LLM τ 0:tn , b n-1 , where b n-1 is the n -1-th generated belief and t n is the time-step when the n-th belief inference is performed.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2" coords="4,306.14,300.01,164.98,9.81">Asynchronous Reflection for</head><p><s coords="4,338.87,313.56,63.97,9.81">Self-evolution</s></p><p><s coords="4,305.80,330.69,218.61,9.46;4,306.14,344.23,218.27,9.46;4,306.14,357.78,196.88,9.46">The Asynchronous Reflection module enables the agent to improve its policy in such a long-horizon interaction process for higher performance.</s><s coords="4,509.84,357.78,14.58,9.46;4,306.14,371.33,218.27,9.46;4,306.14,384.88,220.08,9.46;4,306.14,398.43,219.63,9.46;4,306.14,411.98,220.08,9.46;4,306.14,425.53,112.61,9.46">We design the "Behavior Guideline," where the agent maintains and iteratively updates language guidelines for the self-evolution of the current policy, based on the generated belief about the human partner and the game history.</s><s coords="4,422.72,425.53,103.49,9.46;4,306.14,439.08,218.26,9.46;4,306.14,452.63,220.08,9.46;4,306.14,465.98,218.27,9.66;4,306.14,479.73,220.07,9.46;4,306.14,493.28,220.08,9.46;4,306.14,506.83,151.94,9.46">The Asynchronous Reflection module proceeds asynchronously with the decision-making process and allows real-time responsiveness to be handled by System 1, enabling the reflection process to focus on thinking without worrying about decision delays, thus facilitating more thorough self-evolution.</s><s coords="4,463.86,506.48,62.36,9.81;4,306.14,520.37,218.27,9.46">The m-th Reflection process execution can be formalized as</s></p><formula xml:id="formula_0" coords="4,306.14,531.62,124.24,12.59">g m = LLM τ 0:tm , b n , g m-1</formula><p><s coords="4,435.88,533.57,40.34,9.81;4,476.23,531.62,5.14,6.99;4,484.70,533.92,41.52,9.46;4,306.14,547.12,146.85,9.81;4,453.38,545.17,7.49,6.99;4,464.09,547.47,62.13,9.46;4,306.14,560.67,170.47,9.81">, where b n is the latest inferred belief about human, g m is the "Behavior Guideline" that is updated m times.</s></p><p><s coords="4,317.05,574.92,207.35,9.46;4,305.75,588.47,218.66,9.46;4,306.14,601.82,218.26,9.66;4,306.14,615.22,37.35,9.81;4,343.88,613.52,8.42,6.91;4,357.21,615.22,167.20,9.81;4,306.14,628.77,209.08,10.63">Given the modular formulation of the ToM and Asynchronous Reflection modules, we derive the formulation of the whole System 2 process as a policy π S2 : T × B × G → B × G, where T = {τ 0:t = (s 0 , a 0 , . . . ) | s t ∈ S, a t ∈ A, t = 0, . . .</s><s coords="4,517.04,628.77,5.45,9.57;4,306.14,642.67,149.45,9.46">} is the space of the game history.</s><s coords="4,462.70,642.47,61.71,9.66;4,306.14,655.87,39.33,9.81;4,345.87,654.17,8.42,6.91;4,360.24,656.22,164.17,9.46;4,306.14,669.77,218.27,9.46;4,306.14,683.32,218.27,9.46;4,306.14,696.52,4.68,9.57;4,310.82,694.56,5.14,6.99;4,316.46,696.52,10.06,9.57;4,326.90,694.56,7.49,6.99;4,337.92,696.52,93.09,11.22;4,431.51,696.52,9.53,9.57;4,441.04,694.56,15.96,6.99;4,457.50,696.52,10.06,9.57;4,467.94,694.56,18.31,6.99;4,486.75,696.52,6.97,9.57">The System 2 policy π S2 iteratively updates the belief about the human player and the behavior guidelines given the game history, which can be denoted as b n , g m = LLM(τ 0,max(tn,tm) , b n-1 , g m-1 ).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2" coords="4,306.14,720.04,195.93,9.81;4,330.69,733.59,36.37,9.81">System 1: Fast and Intuitive Decision Making</head><p><s coords="4,306.14,752.18,218.27,9.46;4,305.87,765.54,220.35,9.66">In time-sensitive tasks, humans typically rely on System 1 to make intuitive decisions without engag-</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="5,74.13,107.13,21.34,96.00">DPT-Agent</head><p><s coords="5,70.87,260.84,142.14,9.03">Figure <ref type="figure" coords="5,100.14,261.23,3.95,8.64" target="#fig_10">3</ref>: DPT-Agent Framework.</s><s coords="5,216.84,261.05,307.73,8.82;5,70.87,273.18,174.35,8.64">In System 2, the historical states from the history buffer periodically trigger the ToM module to infer human behaviors.</s><s coords="5,248.50,273.18,275.91,8.64;5,70.87,285.14,453.54,8.64;5,70.87,297.09,78.22,8.64">The reflection module then analyzes the belief output from the ToM module, along with game score feedback and other historical state information, to summarize its own behaviors and generate guidelines.</s><s coords="5,152.18,296.92,372.23,8.82;5,70.87,309.05,292.81,8.64">Within System 1, the code-as-policy generator utilizes the current state, belief and guidelines to generate code-as-policy when necessary, enabling control over the FSM.</s><s coords="5,366.16,309.05,158.25,8.64;5,70.87,321.00,453.54,8.64;5,70.87,332.96,337.45,8.64">When no specific input is provided, the FSM continues operating autonomously, generating macro actions to ensure the agent maintains continuous action output, thereby guaranteeing real-time responsiveness in simultaneous collaboration.</s></p><p><s coords="5,70.87,366.81,218.26,9.46;5,70.87,380.36,138.39,9.46">ing in complex reasoning and keep asynchronous reasoning while taking action.</s><s coords="5,217.06,380.36,72.08,9.46;5,70.87,393.72,218.65,9.66;5,70.87,407.46,220.07,9.46;5,70.87,421.01,218.27,9.46;5,70.87,434.56,76.96,9.46">Inspired by this process, we implement System 1 in DPT-Agent by combining a code-as-policy generator and Finitestate Machine (FSM) to enable intuitive and rapid decision-making.</s><s coords="5,156.64,434.56,132.50,9.46;5,70.87,447.91,218.27,9.66;5,70.59,461.46,218.55,9.66;5,70.87,475.21,79.68,9.46">The code-as-policy approach also establishes a decision pipeline from System 2 to System 1, which allows System 2 to influence and refine actions.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1" coords="5,70.87,500.22,153.39,9.81">Code-as-Policy Generator</head><p><s coords="5,70.53,519.24,220.42,9.46;5,70.87,532.79,218.64,9.46;5,70.87,546.14,218.27,9.66;5,70.87,559.69,220.08,9.66;5,70.87,573.43,36.16,9.46">To enhance the performance of the agent, we designed the code-as-policy generator to effectively bridge the gap between System 2's guidelines and inferred beliefs, and System 1's rapid decisionmaking.</s><s coords="5,113.72,573.24,175.41,9.66;5,70.87,586.98,218.26,9.46;5,70.87,600.34,220.08,9.66;5,70.87,613.88,218.27,9.66;5,70.87,627.63,123.02,9.46">By incorporating System 2's reasoning into the decision pipeline, we ensure that the agent can leverage System 2's reasoning abilities to gradually transform System 2's inferences into actionable decisions within an episode.</s><s coords="5,81.78,642.48,209.17,9.46;5,70.87,656.03,220.08,9.46;5,70.87,669.58,218.27,9.46;5,70.87,683.13,219.63,9.46;5,70.47,696.68,147.38,9.46">The Code-as-policy generator takes in the history, guidelines and inferred beliefs, and outputs executable code that consists of task-completing rules and modifies the logic of the Finite-state Machine, which is detailed in section 4.2.2.</s><s coords="5,221.23,696.68,69.71,9.46;5,70.87,710.03,218.27,9.66;5,70.87,723.58,218.26,9.66;5,70.87,737.33,218.27,9.46;5,70.87,750.88,101.98,9.46">This process allows System 1 to refine its intuitive responses with thoughts derived from System 2, thus enhancing the agent's overall decision-making capabilities in dynamic environments.</s></p><p><s coords="5,81.78,765.73,207.73,9.46;5,306.14,366.47,218.27,10.63;5,306.14,380.01,63.89,10.77;5,370.02,378.06,5.14,6.99;5,375.66,380.01,10.06,9.57;5,386.10,378.06,7.49,6.99;5,394.09,380.01,43.49,9.81;5,437.58,378.06,5.14,6.99;5,445.94,380.01,23.54,9.81;5,469.87,378.06,7.49,6.99;5,480.58,380.36,43.83,9.46;5,306.14,393.91,220.08,9.46;5,306.14,407.11,220.08,9.81;5,306.14,421.01,113.72,9.46">The policy generation process of Code-as-policy generator at time-step t can be formalized as c t = LLM (τ t-λ:t , b n , g m ), where b n and g m represents the latest belief about human and the latest guidelines respectively, and λ is the interval the Code-aspolicy generator executes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2" coords="5,306.14,446.72,218.48,9.81">Finite-state Machine &amp; Action Executor</head><p><s coords="5,305.80,465.95,218.61,9.66;5,306.14,479.69,218.27,9.46;5,306.14,493.24,220.07,9.46;5,306.14,506.79,220.08,9.46;5,306.14,520.34,218.27,9.46;5,306.14,533.89,152.42,9.46">To implement rapid response in system 1, we adopt the Finite-state Machine (FSM) method (Russell and Norvig, 2016), which is a widely used computational model that enables structured and efficient decision-making by transitioning between pre-defined states based on inputs.</s><s coords="5,461.94,533.89,63.83,9.46;5,305.75,547.44,218.66,9.46;5,306.14,560.99,220.08,9.46;5,306.14,574.54,140.35,9.46">In DPT-Agent, we leverage FSM to facilitate fast and intuitive decision-making by defining each state as a specific agent context or situation.</s><s coords="5,452.27,574.54,72.15,9.46;5,306.14,588.09,218.27,9.46;5,306.14,601.63,218.27,9.46;5,306.14,615.18,108.60,9.46">State transitions are triggered by environment dynamics, allowing the agent to adapt efficiently without relying on external LLM responses.</s></p><p><s coords="5,317.05,630.24,209.17,9.46;5,306.14,643.79,218.27,9.46;5,306.14,657.34,218.27,9.46;5,306.14,670.89,137.05,9.46">When LLM generates code-as-policy, the executable code changes the pre-defined logics of FSM and thus facilitates the adaption to human and performance improvement.</s><s coords="5,446.56,670.89,77.85,9.46;5,306.14,684.44,218.27,9.46;5,306.14,697.64,220.08,9.81;5,306.14,711.54,218.27,9.46;5,306.14,725.09,32.25,9.46">The FSM takes in the code-as-policy and game states, and outputs macro actions, denoted as ma, which are highlevel combinations of atomic actions for specific targets.</s><s coords="5,344.69,725.09,181.53,9.46;5,306.14,738.63,218.27,9.46;5,306.14,752.18,124.94,9.46">For example, in Overcooked, macro actions include food ingredients preparation, food assembling and food serving.</s><s coords="5,434.41,752.18,90.00,9.46;5,306.14,765.73,218.27,9.46;6,70.87,74.72,218.27,9.46;6,70.87,88.27,86.38,9.46">The generated macro actions are sent to an action executor for conversion into atomic actions that can be directly executed in the environment.</s><s coords="6,160.75,88.27,128.39,9.46;6,70.87,101.82,220.08,9.46;6,70.87,115.37,30.39,9.46">The action executor employs script policies, ensuring smooth and efficient execution.</s><s coords="6,104.64,115.37,184.50,9.46;6,70.87,128.92,218.26,9.46;6,70.87,142.47,218.65,9.46;6,70.87,156.02,219.63,9.46;6,70.05,169.57,28.74,9.46">Upon receiving a macro action, the action executor selects an appropriate execution plan and performs path planning to determine the necessary atomic actions using the A* algorithm <ref type="bibr" coords="6,240.76,156.02,49.74,9.46;6,70.05,169.57,23.95,9.46" target="#b14">(Hart et al., 1968)</ref>.</s><s coords="6,104.78,169.57,184.36,9.46;6,70.87,183.12,186.64,9.46">The Detailed design and implementation of the FSM is provided in Appendix A.1.</s><s coords="6,262.57,183.12,26.57,9.46;6,70.87,196.32,219.54,10.63;6,70.87,209.87,24.25,9.81;6,95.11,207.91,2.88,6.99;6,95.11,214.57,3.06,6.99;6,101.70,209.87,87.21,10.63">These processes can be formalized as ma t = FSM(c t , s t ) and a i t = Executor (ma t ) .</s><s coords="6,81.78,224.60,209.17,9.46;6,70.87,237.95,220.08,9.66;6,70.87,251.35,42.48,9.81;6,113.74,249.65,8.42,6.91;6,128.46,251.35,160.67,9.81;6,70.87,264.90,17.53,9.57;6,88.79,263.20,8.42,6.91;6,101.92,264.90,187.22,10.63;6,70.87,278.44,126.19,10.77;6,197.05,276.49,5.14,6.99;6,202.69,278.44,10.06,9.57;6,213.13,276.49,7.49,6.99;6,221.12,278.44,28.97,10.63">Given the formulation of these modules, we derive the formulation of the whole System 1 process as π S1 : S × B × G → A. At time-step t, π S1 generates executable atomic action a t = Executor(FSM(LLM(τ t-λ , b n , g m ), s t )).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5" coords="6,70.87,304.29,125.19,10.75">Experimental Design</head><p><s coords="6,70.87,328.41,220.08,9.46;6,70.87,341.96,218.27,9.46;6,70.87,355.51,220.17,9.46;6,70.51,369.06,161.67,9.46">In this section, we introduce the new real-time simultaneous human-AI collaboration environment and tasks we designed based on <ref type="bibr" coords="6,232.37,355.51,58.67,9.46;6,70.51,369.06,35.23,9.46" target="#b50">Zhang et al. (2024b)</ref> and our experimental setup.</s><s coords="6,235.88,369.06,54.61,9.46;6,70.47,382.61,219.04,9.46;6,70.87,396.16,220.07,9.46;6,70.87,409.71,218.27,9.46;6,70.87,423.26,187.17,9.46">Specifically, we aim to understand: 1) DPT-Agent's capability in real-time tasks, 2) DPT-Agent's capability in collaboration, and 3) DPT-Agent's performance when collaborating with humans simultaneously.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1" coords="6,70.87,448.10,194.43,9.81;6,95.41,461.65,184.27,9.81">Overcooked Challenge for Real-time Simultaneous Human-AI Collaboration</head><p><s coords="6,70.53,481.20,218.61,9.46;6,70.87,494.75,218.27,9.46;6,70.87,508.30,218.27,9.46;6,70.47,521.85,220.56,9.46;6,70.51,535.40,220.44,9.46;6,70.87,548.95,218.27,9.46;6,70.51,562.49,219.99,9.46;6,70.87,576.04,189.71,9.46">To effectively evaluate the performance of DPT-Agent in real-time simultaneous human-AI collaboration, we implement the real-time shared workspace environment proposed by <ref type="bibr" coords="6,237.74,521.85,53.30,9.46;6,70.51,535.40,33.26,9.46" target="#b50">Zhang et al. (2024b)</ref>, using a challenging version of Overcooked based on the original Overcooked game <ref type="bibr" coords="6,70.51,562.49,89.81,9.46" target="#b5">(Carroll et al., 2019;</ref><ref type="bibr" coords="6,163.05,562.49,87.98,9.46" target="#b35">Strouse et al., 2021;</ref><ref type="bibr" coords="6,253.74,562.49,36.76,9.46;6,70.87,576.04,19.24,9.46" target="#b19">Li et al., 2023</ref><ref type="bibr" coords="6,97.25,576.04,24.35,9.46" target="#b21">Li et al., , 2024;;</ref><ref type="bibr" coords="6,123.95,576.04,64.00,9.46" target="#b47">Yu et al., 2023;</ref><ref type="bibr" coords="6,190.28,576.04,65.69,9.46" target="#b43">Wu et al., 2021)</ref>.</s><s coords="6,263.83,576.04,25.50,9.46;6,70.87,589.59,172.70,9.46">In our experiments, we introduce a new layout.</s><s coords="6,246.93,589.59,42.20,9.46;6,70.87,603.14,218.27,9.46;6,70.87,616.49,219.00,9.66;6,70.87,630.04,218.26,9.66;6,70.20,643.59,218.93,9.66;6,70.47,657.34,167.46,9.46">As shown in Figure <ref type="figure" coords="6,113.84,603.14,4.15,9.46" target="#fig_2">4</ref>, we adopt the basic layout, referred to as New Counter Circuit, from <ref type="bibr" coords="6,201.70,616.69,88.17,9.46" target="#b50">Zhang et al. (2024b)</ref> and design a new layout, named New Asymmetric Advantages, building on the original Overcooked AI environment <ref type="bibr" coords="6,143.75,657.34,89.40,9.46" target="#b5">(Carroll et al., 2019)</ref>.</s><s coords="6,241.72,657.34,49.23,9.46;6,70.87,670.89,220.08,9.46;6,70.87,684.44,104.95,9.46">The implementation is based on the gym-cooking environment <ref type="bibr" coords="6,96.39,684.44,69.85,9.46" target="#b43">(Wu et al., 2021</ref>).</s><s coords="6,180.85,684.44,109.65,9.46;6,70.87,697.99,218.27,9.46;6,70.87,711.54,47.29,9.46">In the real-time settings, each timestep corresponds to 0.25 seconds in the real world.</s><s coords="6,121.57,711.54,169.38,9.46;6,70.59,725.09,218.54,9.46;6,70.87,738.63,218.54,9.46;6,70.87,752.18,45.72,9.46">Time-sensitive elements within the environment, such as overcooked beef and expiring orders, underscore the importance of timely task execution.</s><s coords="6,121.93,752.18,167.21,9.46;6,70.87,765.73,220.07,9.46;6,306.14,243.59,165.45,9.46">Additionally, layout conflicts and the complexity of the burger-making process empha- size the critical role of collaboration.</s><s coords="6,476.13,243.59,50.08,9.46;6,306.14,257.14,218.27,9.46;6,306.14,270.69,67.57,9.46">Further details about the environment and tasks can be found in Appendix A.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2" coords="6,306.14,292.92,117.58,9.81">Experimental Setup</head><p><s coords="6,306.14,310.97,218.27,9.46;6,306.14,324.52,220.08,9.46;6,306.14,338.07,218.27,9.46;6,306.14,351.62,219.63,9.46;6,306.14,365.17,80.97,9.46">Based on the Overcooked challenge, we set up three series of experiments to validate the effectiveness of DPT-Agent using the commonly adopted ReAct <ref type="bibr" coords="6,335.70,351.62,72.72,9.46" target="#b45">(Yao et al., 2022)</ref> and Reflexion <ref type="bibr" coords="6,472.00,351.62,53.78,9.46;6,306.14,365.17,25.96,9.46" target="#b34">(Shinn et al., 2024)</ref> framework.</s><s coords="6,393.72,365.17,130.69,9.46;6,305.75,378.72,220.48,9.46;6,306.14,392.27,218.26,9.46;6,306.14,405.82,20.71,9.46">We first compare DPT-Agent with baselines in a single agent setting to understand the DPT-Agent's capability of a real-time task.</s><s coords="6,334.04,405.82,190.38,9.46;6,306.14,419.37,220.08,9.46;6,306.14,432.92,161.33,9.46">Next, we use three specialized rule-based agents as partners to evaluate the simultaneous collaboration capability of DPT-Agent.</s><s coords="6,473.85,432.92,50.56,9.46;6,306.14,446.47,218.27,9.46;6,306.14,460.02,220.08,9.46;6,306.14,473.57,100.69,9.46">Finally, we conduct human-involved experiments to compare baseline frameworks with DPT-Agent in collaboration with real humans.</s><s coords="6,411.54,473.57,112.88,9.46;6,306.14,487.11,218.27,9.46;6,306.14,500.66,220.08,9.46;6,306.14,514.21,188.52,9.46">The baseline frameworks in experiments are implemented in a manner that ensures a fair comparison via using the same output way of code-as-policy with DPT-Agent.</s><s coords="6,498.06,514.21,26.34,9.46;6,306.14,527.76,218.27,9.46;6,306.14,541.11,181.93,9.66">Based on this implementation, the ReAct and Reflexion become System 1 + System 2 frameworks.</s><s coords="6,491.46,541.31,34.76,9.46;6,306.14,554.86,218.26,9.46;6,306.14,568.41,220.07,9.46;6,306.14,581.96,220.08,9.46;6,306.14,595.51,218.46,9.46;6,306.14,609.06,130.68,9.46">The implementation details can be found in Appendices B to D. All the open-source models used in experiments are deployed locally with NVIDIA A800-SXM4-80GB and NVIDIA H100-80GB-HBM3 for the best latency performance.</s><s coords="6,440.20,609.06,84.21,9.46;6,306.14,622.61,200.26,9.46">Model deployment details can be found in Appendices G and H.</s><s coords="6,509.30,622.61,15.29,9.46;6,306.14,636.16,201.48,9.46">For close-source models, we use the original API.</s><s coords="6,510.36,636.16,14.05,9.46;6,306.14,649.70,218.27,9.46;6,306.14,663.25,218.27,9.46;6,306.14,676.80,162.99,9.46">All the models' temperature is set to 0. The whole experiment cost 517.5 A800 GPU hours, 228 H100 GPU hours and $735 in API in total.</s><s coords="6,472.86,676.80,53.36,9.46;6,306.14,690.35,218.27,9.46;6,306.14,703.90,218.27,9.46;6,306.14,717.45,23.80,9.46">For reliability, all the experiments are repeated 20 runs and reported as the inter-quartile mean and the standard error.</s><s coords="6,336.75,717.45,189.46,9.46;6,306.14,731.00,154.22,9.46">The details of the metrics used in experiments can be found in Appendix E.</s></p><p><s coords="6,306.14,751.76,134.82,9.81">Capability in Real-time Task.</s><s coords="6,451.87,752.18,72.72,9.46;6,306.14,765.73,220.08,9.46;7,70.87,319.09,193.70,9.81">We first consider the real-time performance and task completion ca-  Capability in Simultaneous Collaboration.</s><s coords="7,275.48,319.52,15.47,9.46;7,70.87,333.07,220.08,9.46;7,70.87,346.62,220.07,9.46;7,70.87,360.17,220.08,9.46;7,70.87,373.72,47.60,9.46">Expanding on the previous experiment, we use rulebased agents as partners to evaluate the performance of DPT-Agent in simultaneous collaboration tasks.</s><s coords="7,129.42,373.72,161.52,9.46;7,70.87,387.27,218.45,9.46;7,70.87,400.82,220.18,9.46">We employ three specialized rulebased agents: one for beef preparation, one for lettuce preparation, and one for burger assembly.</s></p><p><s coords="7,70.87,414.37,220.07,9.46;7,70.87,427.72,218.26,9.66;7,70.87,441.46,218.65,9.46;7,70.05,455.01,219.09,9.46;7,70.87,468.56,192.15,9.46">In Map 1, we compare ReAct and Reflexion implemented as System 1 + System 2 frameworks and DPT-Agent w/o ToM with DPT-Agent driven by 11 high-performing LLMs on the same map as the previous experiment in a two-player setting.</s></p><p><s coords="7,70.87,507.87,220.08,9.81;7,70.87,521.42,97.00,9.81">Real-time Simultaneous Collaboration Experiments with Human.</s><s coords="7,178.78,521.85,110.36,9.46;7,70.87,535.40,220.08,9.46;7,70.87,548.95,202.59,9.46">To evaluate DPT-Agent's capabilities of collaborating with humans, we conduct experiments with 71 university students.</s><s coords="7,277.64,548.95,11.49,9.46;7,70.87,562.49,220.08,9.46;7,70.47,576.04,161.76,9.46">To balance response latency and capability, all frameworks are powered by GPT-4o-mini.</s><s coords="7,235.63,576.04,53.50,9.46;7,70.87,589.40,220.08,9.66;7,70.87,602.95,218.27,9.66;7,70.53,616.69,96.96,9.46">We enhance all baselines by incorporating an FSM-based System 1 and perform an ablation study to assess the ToM module's impact.</s><s coords="7,170.91,616.69,120.04,9.46;7,70.87,630.24,218.27,9.46;7,70.05,643.79,219.09,9.46;7,70.87,657.34,127.10,9.46">We compare ReAct + FSMbased System 1, Reflexion + FSM-based System 1, DPT-Agent, and DPT-Agent w/o ToM on two cooperative two-player maps.</s><s coords="7,201.37,657.34,87.76,9.46;7,70.87,670.89,220.18,9.46">Participants are split into two groups, each playing on a different map.</s><s coords="7,70.35,684.44,218.78,9.46;7,70.87,697.99,218.27,9.46;7,70.87,711.54,144.89,9.46">Within each group, every participant plays two games, each lasting 500 timesteps, with each of the four agents in random order.</s><s coords="7,220.56,711.54,68.58,9.46;7,70.87,725.09,129.89,9.46">We also collect subjective human preferences.</s><s coords="7,204.14,725.09,85.00,9.46;7,70.87,738.63,220.08,9.46;7,70.87,752.18,218.27,9.46;7,70.87,765.73,104.67,9.46">Detailed participant demographics, experiment implementation, instructions, recruitment, and payment information are provided in Appendix I.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6" coords="7,306.14,224.44,55.12,10.75">Results</head><p><s coords="7,306.14,247.60,220.07,9.46;7,306.14,261.15,218.27,9.46;7,306.14,274.70,210.27,9.46">In this section, we present the results of experiments and analyze DPT-Agent's effectiveness in real-time simultaneous human-AI collaboration.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1" coords="7,306.14,298.19,158.40,9.81">Capability in Real-time Task</head><p><s coords="7,305.75,316.98,218.66,9.46;7,306.14,330.53,220.08,9.46;7,305.75,344.08,220.47,9.46;7,306.14,357.63,220.08,9.46;7,306.14,370.98,190.79,9.66">As shown in Figures <ref type="figure" coords="7,401.68,316.98,13.44,9.46" target="#fig_4">5(a</ref>) and 5(b) (detailed data in Appendix G), under ReAct and Reflexion framework, the score efficiency of most models has significantly improved compared with when they functioned as independent System 1 (Figure <ref type="figure" coords="7,484.88,371.17,4.02,9.46" target="#fig_1">2</ref>).</s><s coords="7,501.16,371.17,25.06,9.46;7,306.14,384.72,218.27,9.46;7,306.14,398.08,218.27,9.66;7,305.87,411.63,54.74,9.66">However, the score of many models has declined with an increase in latency due to more complex System 2 reasoning.</s><s coords="7,365.22,411.82,161.00,9.46;7,305.32,425.37,219.08,9.46;7,306.14,438.92,220.08,9.46;7,306.14,452.47,37.14,9.46">Low-latency models, like Qwen2.5-14b, still struggle with capability issues, failing to achieve higher final scores despite good score efficiency.</s><s coords="7,347.98,452.47,176.43,9.46;7,306.14,466.02,218.27,9.46;7,306.14,479.57,218.27,9.46;7,306.14,493.12,120.61,9.46">Further comparison of the performance of DPT-Agent in Figure <ref type="figure" coords="7,411.90,466.02,4.36,9.46" target="#fig_4">5</ref>(c) reveals that inference models with high latency and larger models get a significant improvement.</s><s coords="7,433.21,493.12,91.20,9.46;7,306.14,506.67,220.08,9.46;7,306.14,520.22,218.27,9.46;7,306.14,533.76,218.27,9.46;7,306.14,547.31,66.65,9.46">DPT-Agent can help these high latency models convert the high score efficiency and reasoning capability to scores, which demonstrates the effectiveness of DPT-Agent in real-time tasks.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2" coords="7,306.14,570.81,218.26,9.81">Capability in Simultaneous Collaboration</head><p><s coords="7,305.75,589.59,218.66,9.46;7,306.14,603.14,220.07,9.46;7,306.14,616.69,218.27,9.46;7,306.14,630.24,127.61,9.46">As shown in Table <ref type="table" coords="7,388.24,589.59,4.03,9.46" target="#tab_1">1</ref>, DPT-Agent achieved the best performance across the majority of models, especially on the widely recognized general-purpose SOTA models like GPT-4o.</s><s coords="7,442.60,630.24,81.82,9.46;7,306.14,643.79,218.27,9.46;7,306.14,657.34,218.27,9.46;7,306.14,670.89,218.46,9.46;7,306.14,684.44,188.04,9.46">This phenomenon aligns with the conclusions from the experiments in single-agent settings, where larger models can overcome the latency limitations and achieve better performance with the help of DPT-Agent.</s><s coords="7,500.26,684.44,25.96,9.46;7,306.14,697.99,218.27,9.46;7,306.14,711.54,220.08,9.46;7,306.14,725.09,122.13,9.46">Additionally, when facing rule-based agents that can only perform a single task, DPT-Agent can maintain a high contribution rate.</s><s coords="7,431.65,725.09,92.76,9.46;7,306.14,738.63,65.52,9.46">For some models like Llama3.3-70b,</s><s coords="7,374.47,738.63,149.94,9.46;7,306.14,752.18,218.65,9.46;7,306.14,765.73,178.81,9.46">DPT-Agent w/o ToM outperforms the complete DPT-Agent, which may be closely related to the model's ToM capabilities.</s><s coords="7,489.88,765.73,36.34,9.46">We pro-</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="9,70.87,404.31,59.12,10.75">Limitations</head><p><s coords="9,70.87,427.00,218.26,9.46;9,70.87,440.55,218.27,9.46;9,70.87,454.10,220.08,9.46;9,70.87,467.65,218.27,9.46;9,70.87,481.20,29.35,9.46">DPT-Agent has already made breakthrough progress in the task of simultaneous Human-AI collaboration, providing a solid foundation for designing more complex agent frameworks in the future.</s><s coords="9,105.76,481.20,183.37,9.46;9,70.87,494.75,103.34,9.46">However, DPT-Agent still has significant room for improvement.</s><s coords="9,177.61,494.75,111.52,9.46;9,70.87,508.10,220.08,9.66;9,70.87,521.65,218.27,9.66;9,70.47,535.40,220.57,9.46">First, providing guidance and code-as-policy to DPT-Agent FSM-driven System 1 remains a major challenge for many models with weaker capabilities, especially small models.</s><s coords="9,70.87,548.95,218.45,9.46;9,70.87,562.49,218.27,9.46;9,70.87,576.04,68.57,9.46">Many models are still limited by errors in their output, which cannot be verified and thus lead to invalid policies.</s><s coords="9,142.82,576.04,146.31,9.46;9,70.87,589.59,220.08,9.46;9,70.87,603.14,28.66,9.46">Secondly, using lambda functions to control the FSM still has a certain lack of flexibility.</s><s coords="9,104.33,603.14,184.81,9.46;9,70.87,616.69,218.27,9.46;9,70.87,630.24,172.12,9.46">However, given the current limitations of model capabilities, it might be hard for models to directly output valid state machine code.</s><s coords="9,246.28,630.24,42.85,9.46;9,70.53,643.79,218.61,9.46;9,70.87,657.34,218.27,9.46;9,70.87,670.89,24.05,9.46">And since ToM ability is a complex higher-order reasoning capability, it imposes high demands on the model itself.</s><s coords="9,98.25,670.89,190.89,9.46;9,70.87,684.44,218.27,9.46;9,70.87,697.99,68.61,9.46">This limitation makes it more likely for ToM failures to occur when DPT-Agent is applied to smaller models.</s><s coords="9,142.86,697.99,146.27,9.46;9,70.87,711.54,218.27,9.46;9,70.87,725.09,220.08,9.46;9,70.87,738.63,220.08,9.46;9,70.87,752.18,220.18,9.46">Big models with strong reasoning capabilities suffer from high latency, which reduces the timeliness of reasoning, which is another limitation of DPT-Agent, making it challenging to consistently outperform FSM across different models.</s></p><p><s coords="9,70.87,765.73,218.27,9.46;9,306.14,74.72,218.27,9.46;9,306.14,88.27,220.18,9.46">Our current experiments are still conducted on a small scale, and since the human subjects are all university students, there may be potential biases.</s></p><p><s coords="9,306.14,101.82,218.27,9.46;9,305.75,115.37,218.66,9.46;9,306.14,128.92,107.86,9.46">Conducting larger-scale experiments in the future will help deepen our understanding of simultaneous human-AI collaboration.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="12,70.87,73.58,125.83,10.75">A Environment Details</head><p><s coords="12,70.35,95.21,220.14,9.46;12,70.87,108.76,144.74,9.46;12,215.61,106.71,3.99,6.91;12,224.61,108.76,65.88,9.46;12,70.87,122.31,104.84,9.46;12,175.70,120.26,3.99,6.91;12,182.91,122.31,76.41,9.46">We implement the environment from <ref type="bibr" coords="12,232.81,95.21,57.69,9.46;12,70.87,108.76,31.52,9.46" target="#b50">(Zhang et al., 2024b)</ref> based on overcooked-ai 1 <ref type="bibr" coords="12,224.61,108.76,65.88,9.46;12,70.87,122.31,25.45,9.46" target="#b5">(Carroll et al., 2019)</ref> and gym-cooking 2 <ref type="bibr" coords="12,182.91,122.31,71.71,9.46" target="#b43">(Wu et al., 2021)</ref>.</s></p><p><s coords="12,70.87,142.36,26.88,9.81">State.</s><s coords="12,108.66,142.79,180.47,9.46;12,70.87,156.34,220.18,9.46">Both the agent and the human have full access to the game states and each other's actions.</s><s coords="12,70.87,169.89,218.27,9.46;12,70.87,183.44,218.27,9.46;12,70.87,196.99,220.07,9.46;12,70.87,210.54,57.65,9.46">Players can directly see the status of all items in the game interface, such as the location where items are placed and their current state (e.g., beef cooking in a pan).</s><s coords="12,131.90,210.54,157.23,9.46;12,70.87,224.08,220.08,9.46;12,70.87,237.63,64.18,9.46">Players can also view the remaining game time and current score through the information displayed.</s><s coords="12,138.42,237.63,152.07,9.46;12,70.87,251.18,218.27,9.46;12,70.87,264.73,218.27,9.46;12,70.87,278.28,165.55,9.46">The remaining time for each order, the progress of chopping lettuce, the process of cooking beef, and the process of extinguishing a fire are shown through progress bars.</s><s coords="12,240.45,278.28,48.69,9.46;12,70.87,291.83,218.27,9.46;12,70.87,305.38,218.27,9.46;12,70.87,318.93,24.55,9.46">All actions taken by teammates, the teammates' location, and the items they are holding are fully visible to each other.</s></p><p><s coords="12,70.87,338.99,33.83,9.81">Action.</s><s coords="12,115.61,339.41,173.53,9.46;12,70.87,352.96,218.27,9.46;12,70.87,366.51,218.27,9.46;12,69.42,380.06,46.03,9.46">In this environment, the actions that the human and the agent can take to control the chefs include moving up, down, left, and right, as well as "interact".</s><s coords="12,118.86,380.06,171.64,9.46;12,70.87,393.61,220.08,9.46;12,70.87,407.16,112.28,9.46">All activities such as picking up items, serving dishes, and extinguishing fires are considered as "interact" actions.</s><s coords="12,186.54,407.16,102.60,9.46;12,70.87,420.71,137.94,9.46">The specific interaction rules are illustrated in Figure <ref type="figure" coords="12,200.56,420.71,4.12,9.46" target="#fig_5">6</ref>.</s><s coords="12,212.19,420.71,78.76,9.46;12,70.87,433.91,128.61,9.81;12,199.48,432.21,22.58,6.91;12,222.56,434.26,2.67,9.46">We denote the actions to control the chefs as A control .</s><s coords="12,228.59,434.26,60.54,9.46;12,70.87,447.46,124.14,9.81;12,195.00,445.76,22.58,6.91;12,218.08,447.81,2.73,9.46">The agent and the human share the same A control .</s><s coords="12,70.87,702.66,38.93,9.81">Reward.</s><s coords="12,120.71,703.09,170.23,9.46;12,70.87,716.64,218.27,9.46;12,306.14,179.05,220.18,9.46">The scores for completing the three different types of orders vary and serving the wrong burger or missing an order will result in a penalty.</s></p><p><s coords="12,305.80,192.60,192.02,9.46">The specific rewards are detailed in Table <ref type="table" coords="12,489.64,192.60,4.09,9.46" target="#tab_4">4</ref>.</s></p><p><s coords="12,306.14,213.08,50.40,9.81">Timesteps.</s><s coords="12,367.45,213.51,158.32,9.46;12,306.14,227.06,203.92,9.46">In the environment implementation, one timestep is 0.25 sencond in the real world.</s><s coords="12,513.44,227.06,10.97,9.46;12,306.14,240.61,219.62,9.46">At most one action can be executed at each time step.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="12,306.14,262.57,120.49,9.81">A.1 FSM in Overcooked</head><p><s coords="12,306.14,280.47,218.27,9.46;12,306.14,294.02,140.80,9.46">Follow the <ref type="bibr" coords="12,354.86,280.47,86.16,9.46" target="#b50">Zhang et al. (2024b)</ref>, the macro actions included are summarized below.</s></p><p><s coords="12,319.16,316.11,49.60,9.88">• Prepare:</s></p><p><s coords="12,339.34,336.13,186.43,9.88;12,348.33,350.11,35.74,9.46;12,339.34,365.22,186.88,9.88;12,349.78,379.20,155.14,9.46">-Valid Objects: "Beef", "Lettuce", "Bread" -Function: Prepare an appointed ingredient until it can be used to assemble.</s></p><p><s coords="12,319.16,401.29,56.28,9.88">• Assemble:</s></p><p><s coords="12,339.34,421.31,186.88,9.88;12,349.78,435.29,133.49,9.46;12,339.34,450.40,185.07,9.88;12,349.78,464.38,174.63,9.46;12,349.78,477.93,26.25,9.46">-Valid Objects: "BeefBurger", "Lettuce-Burger", "BeefLettuceBurger" -Function: Assemble an appointed burger if all necessary ingredients are ready.</s></p><p><s coords="12,319.16,500.02,47.18,9.88">• Pass on:</s></p><p><s coords="12,339.34,520.04,152.69,9.88;12,339.34,535.58,185.25,9.88;12,349.78,549.56,152.57,9.46">-Valid Objects: "Plate", "Bread" -Function: Put the object onto the center counters to deliver it to the partner.</s></p><p><s coords="12,319.16,571.65,38.26,9.88">• Serve:</s></p><p><s coords="12,339.34,591.67,186.88,9.88;12,349.78,605.65,133.49,9.46;12,339.34,620.77,185.25,9.88;12,349.78,634.74,69.39,9.46">-Valid Objects: "BeefBurger", "Lettuce-Burger", "BeefLettuceBurger" -Function: Deliver an assembled burger to the customer.</s></p><p><s coords="12,319.16,656.83,65.86,9.88">• Putout Fire:</s></p><p><s coords="12,339.34,676.86,83.62,9.88;12,339.34,692.40,185.25,9.88;12,349.78,706.37,114.87,9.46">-Valid Objects: --Function: Pick up the fire extinguisher and put out the fire, if any.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="13,70.87,73.58,235.88,10.75">B General Game Prompt of All Experiments</head><formula xml:id="formula_1" coords="13,71.55,106.08,312.79,6.97">-------------------------------System Prompt -------------------------------</formula><p><s coords="13,71.33,122.02,425.71,6.97;13,71.46,129.99,28.34,6.97">As a player in a collaborative cooking game , you are working with a human player to complete hamburger orders .</s></p><p><s coords="13,71.45,137.96,300.34,6.97">Focus on cooperation , player engagement , fulfillment , and score accrual .</s></p><p><s coords="13,71.55,153.91,4.15,6.97">-</s></p><formula xml:id="formula_2" coords="13,71.22,153.91,304.76,38.85">------------------------------Game Prompt ------------------------------- # Game Introduction ## Game Scene</formula><p><s coords="13,71.39,201.73,371.54,6.97">The game environment is set in a kitchen , designed for a collaborative cooking challenge .</s><s coords="13,447.98,201.73,40.72,6.97;13,71.49,209.70,413.28,6.97">The layout includes a central counter area surrounded by various stations and essential elements for gameplay .</s><s coords="13,489.77,209.70,32.66,6.97;13,75.67,217.67,132.93,6.97">Here ' s a detailed breakdown of the scene :</s></p><p><s coords="13,71.33,233.61,3.49,6.97;13,71.39,313.31,450.78,6.97;13,75.52,321.28,446.70,6.97;13,71.22,329.25,3.49,6.97">- You are controlling one of the two chefs in the kitchen , and your goal is to work together with your partner to fulfill customer orders efficiently and accurately by writing codes to improve your policies in the game .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="13,71.33,345.19,74.22,6.97;13,71.39,361.13,65.82,6.97">## Game Mechanisms ### Game Objects</head><p><s coords="13,71.42,377.07,300.36,6.97">Each object is a represented as a tuple of `( object_name , object_status )</s></p><p><s coords="13,372.73,377.07,7.49,6.97;13,88.07,385.04,429.97,6.97;13,87.95,393.01,74.67,6.97">`. -** Beef **: Includes `(" Beef " , " Fresh ") `, `(" Beef " , " In -progress ") `, `(" Beef " , " Well -cooked ") `, `(" Beef ", " Overcooked ") `.</s><s coords="13,167.66,393.01,338.03,6.97;13,88.21,400.98,429.86,6.97;13,88.13,408.95,36.79,6.97">Note that `(" Beef " , " In -progress ") `will become `(" Beef " , " Well -cooked ") `after a certain time , and `(" Beef " , " Well -cooked ") `will become `(" Beef " , " Overcooked ") `if left on the pan for too long .</s></p><p><s coords="13,88.07,416.92,325.45,6.97">-** Lettuce **: Includes `(" Lettuce " , " Unchopped ") `and `(" Lettuce " , " Chopped ")</s></p><p><s coords="13,414.57,416.92,7.48,6.97;13,88.07,424.89,174.76,6.97">`. -** Bread **: Represented as `(" Bread " , "")</s></p><p><s coords="13,263.94,424.89,7.49,6.97;13,88.07,432.86,333.76,6.97">`. -** BeefLettuce **: A mixture of ingredients , represented as `(" BeefLettuce " , "")</s></p><p><s coords="13,422.94,432.86,7.48,6.97;13,88.07,440.83,425.99,6.97;13,88.13,448.80,11.51,6.97">`. -** Burgers **: Types include `(" BeefBurger " , "") `, `(" LettuceBurger " , "") `, and `(" BeefLettuceBurger " , "")</s></p><p><s coords="13,100.75,448.80,7.48,6.97;13,88.07,456.77,174.76,6.97">`. -** Plate **: Represented as `(" Plate " , "")</s></p><p><s coords="13,263.94,456.77,7.49,6.97;13,88.07,464.74,266.81,6.97">`. -** FireExtinguisher **: Represented as `(" FireExtinguisher " , "")</s></p><p><s coords="13,355.99,464.74,7.49,6.97;13,88.07,472.71,283.78,6.97">`. -** Fire **: Indicates an active fire , represented as `(" Fire " , "") `.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="13,71.39,488.65,49.07,6.97">### Counters</head><p><s coords="13,71.45,504.59,262.68,6.97">Especially , we count the status of the counters in the kitchen :</s></p><p><s coords="13,88.07,512.56,149.82,6.97">-" Empty ": No object on the counter .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="13,71.39,528.50,103.53,6.97">### Valid Actions in Code</head><p><s coords="13,71.33,544.44,216.77,6.97">To play the game , you can use the following actions :</s></p><p><s coords="13,71.33,560.38,258.62,6.97">-** Prepare Actions **: Used to prepare individual ingredients .</s><s coords="13,335.04,560.38,166.29,6.97;13,71.46,568.35,183.17,6.97">Each ingredient can be prepared with the option to either place it on a plate or not .</s><s coords="13,259.72,568.35,145.54,6.97">Here are the valid prepare actions :</s></p><p><s coords="13,88.07,576.32,409.25,6.97;13,88.22,584.29,204.12,6.97">-Preparing `(" Beef " , " Well -cooked ") `: Get a `(" Beef " , " Fresh ") `and cook it into a `(" Beef " , " Inprogress ") `and then a `(" Beef " , " Well -cooked ") `.</s><s coords="13,297.34,584.29,203.96,6.97;13,88.20,592.26,287.77,6.97">Pay attention to avoid overcooking it , which will result in a `(" Beef " , " Overcooked ") `and a `(" Fire " , "") `in the pan .</s></p><p><s coords="13,96.44,600.23,389.55,6.97;13,105.09,608.20,397.63,6.97;13,96.60,616.17,425.83,6.97;13,88.21,624.14,36.58,6.97">-`(" prepare " , {" food ": " Beef " , " plate ": True }) -`(" prepare " , {" food ": " Beef " , " plate ": False }) -Preparing `(" Lettuce " , " Chopped ") `: Get a `(" Lettuce " , " Unchopped ") `and chop it into a `(" Lettuce " , " Chopped ")</s></p><p><s coords="13,125.85,624.14,7.48,6.97;13,104.81,632.11,414.65,6.97;13,113.46,640.08,431.10,6.97;13,96.60,648.05,371.43,6.97;13,96.44,656.02,3.49,6.97">`. -`(" prepare " , {" food ": " Lettuce " , " plate ": True }) -`(" prepare " , {" food ": " Lettuce " , " plate ": False }) -Preparing `(" Bread " , "") `: Get a `(" Bread " , "") `and put it on the counter or in a plate .</s><s coords="13,105.09,656.02,389.26,6.97;13,105.09,663.99,393.78,6.97;13,109.08,679.93,396.43,6.97;13,88.15,687.90,404.99,6.97">-`(" prepare " , {" food ": " Bread " , " plate ": True }) -`(" prepare " , {" food ": " Bread " , " plate ": False }) Ǹote that when there is no `(" Beef " , " Fresh ") `, `(" Lettuce " , " Unchopped ") `or `(" Bread " , "") `in the kitchen , the prepare actions will automatically get the ingredients from the respective stations .</s></p><p><s coords="13,71.33,703.84,434.36,6.97;13,71.46,711.81,237.56,6.97">-** Assemble Actions **: Used to assemble burgers with the already prepared ingredients ( `(" Beef " , " Wellcooked ") `, `(" Lettuce " , " Chopped ") `and `(" Bread " , "") `).</s><s coords="13,314.14,711.81,178.82,6.97;13,71.49,719.78,128.74,6.97">These actions will only be performed if all required ingredients are ready .</s><s coords="13,205.29,719.78,300.40,6.97">See the ** Cookbook ** section for the burger types and their ingredients .</s></p><p><s coords="13,79.70,727.75,347.71,6.97;13,88.35,735.72,313.94,6.97;13,88.35,743.69,380.89,6.97;13,79.70,759.63,400.88,6.97">-`(" assemble " , {" food ": " LettuceBurger "}) -`(" assemble " , {" food ": " BeefBurger "}) -`(" assemble " , {" food ": " BeefLettuceBurger "}) -** Pass On Action **: Used to pass something to your partner by putting it on the central counter .</s></p><p><s coords="13,79.70,767.60,223.39,6.97;14,79.70,76.59,280.75,6.97;14,88.35,84.56,514.80,6.97;14,88.35,92.53,531.53,6.97;14,88.35,100.51,523.16,6.97;14,88.35,108.48,472.95,6.97;14,88.35,116.45,322.32,6.97;14,88.35,124.42,313.94,6.97;14,88.35,132.39,339.05,6.97;14,88.35,140.36,372.52,6.97;14,88.35,148.33,372.53,6.97;14,79.70,164.27,296.27,6.97;14,79.70,172.24,3.49,6.97">-`(" pass_on " , {" thing ": " Plate "}) `13 -`(" pass_on " , {" thing ": " Bread "}) -`(" pass_on " , {" thing ": " Lettuce " , " thing_status ": " Chopped "}) -`(" pass_on " , {" thing ": " Lettuce " , " thing_status ": " Unchopped "}) -`(" pass_on " , {" thing ": " Beef " , " thing_status ": " Well -cooked "}) -`(" pass_on " , {" thing ": " Beef " , " thing_status ": " Fresh "}) -`(" pass_on " , {" thing ": " BeefLettuce "}) -`(" pass_on " , {" thing ": " BeefBurger "}) -`(" pass_on " , {" thing ": " LettuceBurger "}) -`(" pass_on " , {" thing ": " BeefLettuceBurger "}) -`(" pass_on " , {" thing ": " FireExtinguisher "}) -** Serve Actions **: Used to serve the assembled burgers to the customer .</s><s coords="14,88.35,172.24,288.84,6.97;14,88.35,180.21,313.94,6.97;14,88.35,188.18,355.79,6.97;14,79.70,204.12,863.08,6.97;14,87.84,212.09,137.50,6.97;14,79.70,220.06,3.49,6.97">-`(" serve ", {" food ": " BeefBurger "}) -`(" serve ", {" food ": " LettuceBurger "}) -`(" serve ", {" food ": " BeefLettuceBurger "}) -** Put Out Fire Action **: Used to pick up the fire extinguisher and put out the fire on the pan when the Beef `is overcooked and catches fire .</s><s coords="14,88.35,220.06,180.05,6.97;14,79.70,236.00,413.43,6.97;14,79.70,243.97,3.49,6.97">-`(" putout_fire " , {}) -** Clean A Counter Action **: Used to clean a counter by dropping all objects on it to the trash can .</s><s coords="14,88.35,243.97,99.15,6.97">-`(" clean_a_counter " , {})</s></p><p><s coords="14,188.35,243.97,105.45,6.97">###</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="14,88.22,259.91,32.23,6.97">Cookbook</head><p><s coords="14,71.33,275.85,434.36,6.97">In this collaborative kitchen game , the goal is to prepare and serve burgers efficiently to earn points .</s><s coords="14,510.74,275.85,11.51,6.97;14,75.61,283.82,388.19,6.97">The game features three types of burgers : `LettuceBurger `, `BeefBurger `, and `BeefLettuceBurger `.</s><s coords="14,468.94,283.82,49.13,6.97;14,71.45,291.79,199.92,6.97">Here are the rules and how the actions fit into the gameplay :</s></p><p><s coords="14,71.33,307.73,82.70,6.97">-** LettuceBurger **:</s></p><p><s coords="14,79.70,315.70,489.97,6.97;14,88.07,323.67,65.96,6.97;14,88.07,331.64,241.61,6.97;14,88.07,339.61,724.30,6.97;14,79.70,347.58,61.78,6.97;14,79.70,355.55,498.34,6.97;14,88.07,363.52,65.96,6.97;14,88.07,371.49,249.98,6.97;14,88.07,379.46,699.19,6.97;14,79.70,387.43,91.07,6.97;14,79.70,395.40,715.93,6.97;14,88.07,403.37,65.96,6.97;14,88.07,411.34,49.22,6.97;14,104.81,419.31,241.61,6.97;14,104.81,427.28,245.79,6.97;14,104.81,435.25,757.77,6.97;14,96.57,443.22,40.72,6.97;14,104.81,451.19,241.61,6.97;14,104.81,459.16,707.56,6.97;14,113.32,467.13,237.28,6.97;14,104.81,475.10,757.77,6.97;14,96.57,483.07,49.03,6.97;14,104.81,491.04,245.79,6.97;14,104.81,499.01,682.45,6.97;14,113.32,506.98,233.09,6.97;14,104.81,514.95,757.77,6.97;14,96.57,522.92,44.87,6.97;14,104.81,530.89,783.07,6.97;14,129.97,538.86,511.16,6.97;14,87.95,546.83,3.49,6.97;14,71.33,554.80,845.85,6.97;14,100.62,562.77,53.58,6.97">-** Ingredients **: `(" Lettuce " , " Chopped ") `, `(" Bread " , "") -** Preparation **: -Prepare `(" Lettuce " , " Chopped ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " LettuceBurger "}) -** BeefBurger **: -** Ingredients **: `(" Beef " , " Well -cooked ") `, `(" Bread " , "") -** Preparation **: -Prepare `(" Beef " , " Well -cooked ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " BeefBurger "}) -** BeefLettuceBurger **: -** Ingredients **: `(" Lettuce " , " Chopped ") `, `(" Beef " , " Well -cooked ") `, `(" Bread " , "") -** Preparation **: -Method One -Prepare `(" Lettuce " , " Chopped ") `if not already prepared -Prepare `(" Beef " , " Well -cooked ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " BeefLettuceBurger "}) -Method Two -Prepare `(" Lettuce " , " Chopped ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " LettuceBurger "}) -Prepare `(" Beef " , " Well -cooked ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " BeefLettuceBurger "}) -Method Three -Prepare `(" Beef " , " Well -cooked ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " BeefBurger "}) -Prepare `(" Lettuce " , " Chopped ") `if not already prepared -Assemble the ingredients using the action : `(" assemble " , {" food ": " BeefLettuceBurger "}) -Method Four -If there is a prepared `(" BeefLettuce " , "") `, you can directly assemble the `BeefLettuceBurger ùsing the action : `(" assemble " , {" food ": " BeefLettuceBurger "}) Ǹote : -The `Bread `will be automatically used , from prepared `Bread `or the Bread Station , when the `assemble àction is performed .</s><s coords="14,159.26,562.77,166.50,6.97">You can also prepare `Bread `in advance .</s></p><p><s coords="14,71.33,570.74,321.38,6.97">-** Preparation Flexibility **: You can complete a burger in a flexible order .</s><s coords="14,397.77,570.74,482.56,6.97;14,142.35,578.71,275.47,6.97">For example , when making a BeefLettuceBurger ', you can prepare the `Lettuce `before the `Beef `, or vice versa .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="14,71.39,602.62,74.19,6.97;14,71.33,618.56,82.70,6.97">### Scoring System -** Points Earned **:</head><p><s coords="14,79.82,626.53,241.76,6.97">There are orders from customers that need to be fulfilled .</s><s coords="14,326.67,626.53,158.10,6.97">Each order has a specific point value :</s></p><p><s coords="14,79.70,634.50,116.10,6.97;14,79.70,642.47,103.55,6.97;14,79.70,650.44,132.84,6.97;14,71.33,658.41,74.33,6.97">-`LettuceBurger `: 15 points -`BeefBurger `: 20 points -`BeefLettuceBurger `: 25 points -** Points Lost **:</s></p><p><s coords="14,79.70,666.38,195.85,6.97">-Missing an order results in losing 10 points .</s><s coords="14,280.68,666.38,241.75,6.97">Ensure that each order is completed within the given time .</s></p><p><s coords="14,79.70,674.35,342.30,6.97">-Serving an item that is not in the order lists also results in losing 10 points .</s><s coords="14,427.09,674.35,95.06,6.97;14,84.03,682.32,132.94,6.97">Make sure only demanded burgers are served to customers .</s></p><p><s coords="14,71.39,706.23,74.24,6.97;14,71.33,714.20,442.55,6.97;14,71.46,722.17,296.15,6.97">### Important Tips -** Unreachable Orders **: If the remaining time for an order is less than the time required to prepare the ingredients , it is better to skip that order and focus on the next one .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="14,70.87,751.29,236.32,10.75">C DPT-Agent Implementation in Overcooked</head><p><s coords="15,70.87,74.30,117.37,9.81">C.1 Instruction Prompt</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="15,70.87,91.94,133.32,9.81">C.1.1 Game State Example</head><p><s coords="15,71.22,112.89,3.49,6.97;15,87.95,120.86,49.51,6.97;15,104.69,128.83,87.17,6.97;15,104.69,136.80,112.28,6.97;15,104.69,144.77,112.28,6.97;15,104.69,152.74,108.09,6.97;15,104.69,160.71,116.46,6.97;15,104.69,168.68,108.09,6.97;15,104.69,176.65,70.43,6.97;15,104.69,184.62,95.54,6.97;15,104.69,192.59,91.36,6.97;15,104.69,200.56,103.91,6.97;15,104.69,208.53,120.65,6.97;15,104.69,216.50,91.36,6.97;15,104.69,224.47,116.46,6.97;15,104.69,232.44,62.07,6.97;15,87.95,240.41,7.67,6.97;15,87.95,248.38,53.70,6.97;15,104.69,256.35,49.44,6.97;15,87.95,264.32,7.67,6.97;15,87.95,272.30,45.33,6.97;15,104.69,280.27,3.49,6.97;15,121.43,288.24,87.29,6.97;15,121.43,296.21,70.32,6.97;15,104.69,304.18,7.67,6.97;15,104.69,312.15,3.49,6.97;15,121.43,320.12,99.84,6.97;15,121.43,328.09,70.32,6.97;15,104.69,336.06,3.49,6.97;15,87.95,344.03,7.67,6.97;15,87.95,352.00,112.28,6.97;15,104.69,359.97,129.13,6.97;15,87.95,367.94,3.49,6.97;15,71.22,375.91,3.49,6.97;15,225.69,456.19,204.57,6.97;15,87.95,464.16,7.79,6.97;15,87.95,472.13,53.82,6.97;15,87.95,480.10,62.07,6.97;15,71.22,488.07,3.49,6.97">{ " objects ": { (" Beef " , " Fresh " ) : 1 , (" Beef " , " In -progress " ) : 1 , (" Beef " , " Well -cooked " ) : 0 , (" Beef " , " Overcooked " ) : 1 , (" Lettuce " , " Unchopped " ) : 3 , (" Lettuce " , " Chopped " ) : 1 , (" Bread " , " " ) : 4 , (" BeefLettuce " , " " ) : 0 , (" BeefBurger " , " " ) : 0 , (" LettuceBurger " , " " ) : 1 , (" BeefLettuceBurger " , " " ) : 0 , (" Plate " , " Empty " ) : 2 , (" FireExtinguisher " , " " ) : 1 , (" Fire " , " " ) : 0 }, " counters " : { " Empty " : 18 , }, " orders ": [ { " name " : " BeefBurger " , " remain_time " : 30 }, { " name " : " LettuceBurger " , " remain_time " : 45 } ], " inventory_other_player " : { " player_1 " : ( " Plate " , " Empty " ) , } } ) " , ( " prepare " , { " food " : " Beef " , " plate " : False }) ) , " BeefBurger " , " LettuceBurger " ]</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="15,70.87,403.36,145.68,9.81">C.1.2 Assigned Task Example</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="15,70.87,515.52,91.52,9.81">C.1.3 Instructions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="15,71.22,536.47,57.59,6.97;15,71.33,552.41,28.26,6.97"># Instructions ## Goal</head><p><s coords="15,71.45,568.35,433.99,6.97;15,71.45,576.32,24.18,6.97">Based on these settings , you need to consider how to play the game with your partner to achieve a higher score .</s><s coords="15,100.68,576.32,350.61,6.97">The agent will automatically prepare the burger order with the least remaining time .</s><s coords="15,456.35,576.32,65.81,6.97;15,75.61,584.29,384.05,6.97">You will receive game history and your task is to respond to urgent situations for improving the performance .</s></p><p><s coords="15,71.33,600.23,82.58,6.97;15,71.33,616.17,70.14,6.97">## Input Information ** Game History **:</s></p><p><s coords="15,88.07,624.14,246.06,6.97">-A sequence of game scenes that have occurred in the past .</s><s coords="15,339.22,624.14,132.99,6.97;15,104.81,632.11,229.33,6.97">Each game scene is consisted of : -Remained Timestep : The remained timestep of the game .</s></p><p><s coords="15,104.81,640.08,162.38,6.97">-Score : The current score of the game .</s></p><p><s coords="15,104.81,648.05,338.11,6.97">-Game State : The occurrences of objects , orders , and other players ' inventories .</s></p><p><s coords="15,104.81,656.02,287.91,6.97">-Action : Actions taken by your agent and the human -controlled agent .</s></p><p><s coords="15,104.81,663.99,346.49,6.97">-Delivery : The food that have been delivered and the corresponding obtained score .</s></p><p><s coords="15,104.81,671.96,405.07,6.97">-Missed Orders : The orders that have not been completed in time and the obtained punished score .</s><s coords="15,104.69,679.93,66.25,6.97;15,71.33,687.90,111.99,6.97">{ MESSAGE_PROMPT } ** Current Assigned Tasks **:</s></p><p><s coords="15,88.07,695.87,371.59,6.97">-The current actions and orders you assigned to the agent that need to be done urgently .</s><s coords="15,71.33,703.84,99.44,6.97">** Behavior Guidelines **:</s></p><p><s coords="15,88.07,711.81,417.62,6.97">-The behavior guidelines are the suggestions you have given to the agent based on the game history .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="15,71.22,719.78,95.54,6.97;15,71.39,735.72,57.48,6.97">{ INFERRED_HUMAN_PROMPT } ### Game State</head><p><s coords="15,71.39,751.66,229.27,6.97">The current state of the game includes various details .</s><s coords="15,305.65,751.66,212.32,6.97;15,71.49,759.63,40.87,6.97">Here 's a detailed description based on the provided structure :</s></p><p><s coords="16,71.33,76.59,61.77,6.97">1. ** Objects **:</s></p><p><s coords="16,88.07,84.56,338.12,6.97">-The `objects `dictionary records the number of objects with different statuses .</s><s coords="16,431.28,84.56,86.73,6.97;16,88.07,92.53,250.20,6.97">Each entry is a tuple of `( object_name , object_status )`mapped to `object_number `.</s></p><p><s coords="16,88.07,100.51,57.77,6.97">-For example :</s></p><p><s coords="16,104.81,108.48,300.42,6.97">-`(" LettuceBurger " , "") : 1`indicates that there is 1 `LettuceBurger `.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2." coords="16,71.33,124.42,57.59,6.97">** Orders **:</head><p><s coords="16,88.07,132.39,308.82,6.97">-The `orders `list contains the current orders that need to be completed .</s><s coords="16,401.98,132.39,107.61,6.97;16,88.16,140.36,20.01,6.97">Each order is a dictionary with :</s></p><p><s coords="16,104.81,148.33,417.58,6.97">-`name `: The name of the order , which can be `BeefBurger `, `LettuceBurger `, or `BeefLettuceBurger `.</s></p><p><s coords="16,104.81,156.30,404.78,6.97;16,104.94,164.27,61.81,6.97">-`remain_time `: The remaining time to complete the order , with smaller remaining time indicating higher urgency .</s></p><p><s coords="16,71.33,180.21,153.83,6.97">3. ** Inventory of the Other Player **:</s></p><p><s coords="16,88.07,188.18,363.23,6.97">-The `inventory_other_player `dictionary records the objects held by the other player .</s><s coords="16,456.39,188.18,61.65,6.97;16,87.92,196.15,258.81,6.97;16,88.07,204.12,388.08,6.97;16,88.25,212.09,53.40,6.97">Each entry maps `other_agent_id `to a tuple of `( object_name , object_status ) `. -This helps in understanding what the other player is currently holding , allowing for better coordination .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="16,71.42,228.03,95.10,6.97">#### Example Game State</head><p><s coords="16,71.39,243.97,170.68,6.97">Now I will show you a game state example .</s><s coords="16,247.07,243.97,107.81,6.97;16,71.33,251.94,241.88,6.97">In this example , there are -1 fresh beef , 1 in -progress beef , and 1 overcooked beef .</s><s coords="16,318.21,251.94,82.87,6.97">No well -cooked beef .</s></p><p><s coords="16,71.33,259.91,183.30,6.97">-3 unchopped lettuce and 1 chopped lettuce .</s></p><p><s coords="16,71.33,267.88,124.72,6.97">-4 bread prepared in advance .</s></p><p><s coords="16,71.33,275.85,413.43,6.97">-No assembled BeefLettuce , BeefBurgers , or BeefLettuceBurgers , but there is 1 LettuceBurger ready .</s></p><p><s coords="16,71.33,283.82,120.53,6.97">-2 empty plates on counters .</s></p><p><s coords="16,71.33,291.79,170.75,6.97">-1 fire extinguisher and no active fire .</s></p><p><s coords="16,71.33,299.76,82.87,6.97">-18 empty counters .</s></p><p><s coords="16,71.33,307.73,438.54,6.97">-2 orders pending : a BeefBurger with 30 seconds remaining and a LettuceBurger with 45 seconds remaining .</s></p><p><s coords="16,71.33,315.70,141.46,6.97">-Player 1 holding an empty plate .</s></p><p><s coords="16,71.42,331.64,195.75,6.97">Note that you will only receive the json below :</s></p><formula xml:id="formula_3" coords="16,71.22,347.58,82.99,22.91">{ GAME_STATE_EXAMPLE } ### Assigned Tasks</formula><p><s coords="16,71.33,379.46,446.79,6.97;16,71.50,387.43,145.29,6.97">In this game , the `assigned tasks `are the actions and orders which you assign to the agent that need to ** prioritize and complete urgently **.</s></p><p><s coords="16,71.49,403.37,279.38,6.97">Assigned tasks can be actions with pre -conditions , and order names .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="16,71.42,419.31,86.70,6.97">#### Assigned Actions</head><p><s coords="16,71.49,435.25,262.65,6.97">Assigned tasks can contains pairs of preconditions and actions .</s><s coords="16,339.22,435.25,183.08,6.97;16,75.57,443.22,338.06,6.97">Each pair specifies a condition that must be met and the corresponding action that should be taken when the condition is true .</s><s coords="16,418.63,443.22,86.94,6.97;16,71.42,451.19,99.52,6.97">Here ' s a breakdown of what each element means :</s></p><p><s coords="16,71.33,467.13,82.70,6.97">1. ** Precondition **:</s></p><p><s coords="16,88.07,475.10,350.67,6.97">-A lambda function that takes `json_state `as an input and returns a boolean value .</s></p><p><s coords="16,88.07,483.07,321.38,6.97">-It indicates whether a specific condition is met in the current game state .</s></p><p><s coords="16,88.07,491.04,425.99,6.97;16,88.13,499.01,421.01,6.97;16,88.10,506.98,141.34,6.97">-For example : When you want to detect whether there are fewer than 3 well -cooked or in -process beefs , you can use `" lambda json_state : json_state <ref type="bibr" coords="16,267.88,499.01,145.64,6.97">[ ' objects '][( ' Beef ', 'Well -cooked ')</ref> ] + json_state <ref type="bibr" coords="16,472.91,499.01,36.23,6.97;16,88.10,506.98,107.83,6.97">[' objects '][( ' Beef ' , 'In -progress ')</ref> ] &lt; 3" `.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2." coords="16,71.33,522.92,57.59,6.97">** Action **:</head><p><s coords="16,88.07,530.89,258.62,6.97">-A tuple containing the action name and the action arguments .</s></p><p><s coords="16,88.07,538.86,354.85,6.97">-The action name is a string , and the action arguments are provided as a dictionary .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="16,71.42,554.80,82.53,6.97">#### Assigned Orders</head><p><s coords="16,71.39,570.74,421.75,6.97">The `assigned_tasks `can also contains the names of the orders that need to be completed in sequence .</s></p><p><s coords="16,71.33,586.68,262.80,6.97">-Each order ( element ) in this list is an order name in string .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="16,71.42,602.62,111.84,6.97">#### Example Assigned Tasks</head><p><s coords="16,71.39,618.56,229.27,6.97">Now I will show you an example of assigned tasks below .</s><s coords="16,305.65,618.56,208.41,6.97">In this example , the agent do the following tasks :</s></p><p><s coords="16,71.33,626.53,442.72,6.97">-prepare beef if the number of well -cooked or in -process beefs are fewer than the number of requirements .</s></p><p><s coords="16,71.33,634.50,95.43,6.97">-prepare a BeefBurger .</s></p><p><s coords="16,71.33,642.47,107.98,6.97">-prepare a LettuceBurger .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="16,71.22,658.41,99.72,6.97">{ ASSIGNED_TASKS_EXAMPLE }</head><p><s coords="16,71.42,674.35,304.55,6.97">Note that `assigned_tasks `will be executed in sequence ** only once ** , i .</s><s coords="16,376.67,674.35,7.67,6.97">e .</s><s coords="16,385.04,674.35,137.27,6.97;16,75.57,682.32,241.82,6.97">, the actions will be executed if the preconditions are met and the orders will be prepared .</s><s coords="16,322.39,682.32,187.31,6.97;16,71.46,690.29,183.12,6.97">If you want to prioritize some tasks , you can assign them in the head of `assigned_tasks `.</s><s coords="16,259.76,690.29,254.09,6.97;16,71.33,698.26,49.39,6.97">Please pay attention to put the most urgent tasks in the head of the list .</s><s coords="16,71.33,714.20,451.10,6.97;16,71.48,722.17,178.85,6.97">** Urgent Needs **: `assigned_tasks `are mainly used for urgent needs you have found according to the latest ( current ) game state { LATEST_MESSAGE_PROMPT }.</s><s coords="17,71.39,189.39,430.12,6.97">You should return a text code block as your thought about how to prepare and serve burgers effectively .</s><s coords="17,71.28,197.36,28.32,6.97;17,71.33,205.33,170.75,6.97">```text Be concise and clear , less than 50 words .</s><s coords="17,71.33,213.30,275.23,6.97">If no urgent responses are needed , return " Things are going well ".</s><s coords="17,71.33,221.27,179.11,6.97">Do not directly copy the previous thoughts .</s><s coords="17,71.28,229.24,3.42,6.97;17,75.71,245.18,91.04,6.97;17,71.46,261.12,425.85,6.97">``{ MESSAGE_OUTPUT_FORMAT } Return a ** json ** code block representation of the new assigned tasks that the agent will do urgently .</s><s coords="17,71.28,269.09,28.32,6.97;17,71.33,277.06,450.92,6.97;17,75.57,285.03,241.64,6.97">```json ** Pay attention that the agent will automatically prepare the burger order with the least remaining time and you should only assign tasks when changes are necessary .**</s><s coords="17,71.39,293.00,442.49,6.97;17,71.48,300.97,183.15,6.97">You can either keep some of the current assigned tasks if you find them still necessary , or substitute the current assigned tasks with the new ones , i .</s><s coords="17,255.33,300.97,7.67,6.97">e .</s><s coords="17,263.69,300.97,254.37,6.97;17,71.46,308.94,28.34,6.97">, you don ' t need to include the current assigned tasks in the output .</s><s coords="17,71.39,316.91,438.25,6.97;17,71.48,324.88,208.26,6.97">You should make sure that the completed burgers are served to the customers in time , by letting the agent perform in default mode or adding serving actions .</s><s coords="17,284.79,324.88,224.85,6.97;17,71.42,332.85,20.01,6.97">But do not serve the burgers that are not in the order list .</s><s coords="17,71.39,340.82,438.31,6.97;17,71.39,348.79,133.02,6.97">You should return an empty list ( `[] `) here when the agent can automatically finish the orders itself and not urgent responses are needed .</s><s coords="17,71.33,356.76,187.48,6.97">Be careful to write correct lambda functions .</s><s coords="17,71.33,364.73,204.22,6.97">Do not directly copy the previous assigned tasks .</s><s coords="17,71.39,372.70,417.56,6.97">The JSON will be used in Python as `eval ( json_string ) `, so make sure it is in the correct format , e .</s><s coords="17,489.65,372.70,7.67,6.97">g .</s><s coords="17,498.02,372.70,20.05,6.97;17,71.19,380.67,204.32,6.97;17,71.28,388.64,7.46,6.97;17,78.74,414.63,4.09,9.81">, use `True `and `False `instead of `true `and `false `. ``C .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2" coords="17,82.83,414.63,155.17,9.81">Prompts of Policy Reflection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="17,71.22,434.66,57.59,6.97"># OutputFormat</head><p><s coords="17,71.46,450.60,220.82,6.97;17,71.39,466.54,308.77,6.97">Please output in parts and in the following template : You should return new ** Behavior Guidelines ** in the following code block .</s><s coords="17,71.28,474.51,28.32,6.97;17,71.48,482.48,375.63,6.97">```text Analyze the past game history and identify areas for improvement or successful strategies .</s><s coords="17,452.20,482.48,65.87,6.97;17,71.39,490.45,250.18,6.97">Then explain how the agent 's policy will be adjusted based on the reflection .</s><s coords="17,71.42,498.42,204.12,6.97;17,71.33,506.39,158.19,6.97">Here are some suggestions for writing guidelines : -What leads to the lost of scores , e .</s><s coords="17,230.22,506.39,7.67,6.97">g .</s><s coords="17,238.59,506.39,233.62,6.97;17,71.33,514.36,3.49,6.97">, missed orders and served wrong food , in the past game ?</s><s coords="17,79.79,514.36,204.13,6.97;17,71.33,522.33,3.49,6.97">-What leads to the waste of time in the past game ?</s><s coords="17,79.76,522.33,191.61,6.97;17,71.33,530.30,3.49,6.97">-How to adjust the agent 's policy to save time ?</s><s coords="17,79.79,530.30,216.68,6.97;17,71.33,538.27,3.49,6.97">-What are the successful strategies in the past game ?</s><s coords="17,79.76,538.27,275.30,6.97;17,71.33,546.24,3.49,6.97">-How to coordinate with the human player to achieve a higher score ?</s><s coords="17,79.76,546.24,271.12,6.97;17,71.33,554.21,3.49,6.97">-How the agent 's policy should be adjusted to improve performance ?</s><s coords="17,79.76,554.21,112.11,6.97">-Why the beef is overcooked ?</s><s coords="17,196.92,554.21,124.66,6.97;17,71.33,562.18,3.49,6.97">How to avoid overcooking beef ?</s><s coords="17,79.82,562.18,250.13,6.97">-Other suggestions for improving the performance of the team .</s><s coords="17,71.39,570.15,254.20,6.97">The guidelines should be given ** based on the game history **.</s><s coords="17,71.39,578.12,149.76,6.97">You should return a text code block .</s><s coords="17,226.15,578.12,174.93,6.97">Be concise and clear , less than 100 words .</s><s coords="17,71.28,586.09,7.46,6.97;17,78.74,612.08,4.09,9.81">``C .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3" coords="17,82.83,612.08,189.95,9.81">Prompts of Theory of Mind Module</head><p><s coords="17,71.39,632.11,430.11,6.97">You should return new ** inference on the human player ' s behavior pattern ** in the following code block .</s><s coords="17,71.28,640.08,28.32,6.97;17,71.48,648.05,409.11,6.97">```text Analyze the past game history and identify patterns or tendencies in the human player 's behaviors .</s><s coords="17,485.67,648.05,15.62,6.97;17,71.48,656.02,379.82,6.97">Then explain how the agent ' s policy will be adjusted to coordinate better with the human player .</s><s coords="17,71.42,663.99,199.94,6.97;17,71.33,671.96,262.80,6.97">Here are some suggestions for writing inference : -What are the human player ' s preferences in completing orders ?</s><s coords="17,339.19,671.96,153.70,6.97;17,71.48,679.93,400.73,6.97">For example , whether the human player prefers to complete orders with the least remaining time or orders with the most remaining time ?</s><s coords="17,477.30,679.93,36.54,6.97;17,71.42,687.90,442.40,6.97;17,71.42,695.87,20.01,6.97">This will help you determine which orders you should focus on to avoid missing any order and to prevent making extra food .</s></p><p><s coords="17,71.33,703.84,325.56,6.97">-How does the human player prioritize tasks when multiple orders are pending ?</s><s coords="17,401.95,703.84,99.38,6.97;17,71.45,711.81,433.97,6.97;17,71.49,719.78,137.11,6.97;17,71.33,727.75,3.49,6.97">For example , whether the human player tends to do order by order or tries to complete multiple orders simultaneously by preparing multiple ingredients in parallel ?</s><s coords="17,79.82,727.75,262.68,6.97">-Which processes does the human player prefer to complete first ?</s><s coords="17,347.56,727.75,153.70,6.97;17,71.48,735.72,300.31,6.97">For example , whether the human player prefers to prepare which ingredients , assemble burgers or serve burgers ?</s><s coords="17,376.88,735.72,120.18,6.97;17,71.49,743.69,149.66,6.97">This will affect your choices regarding which tasks to prioritize .</s><s coords="17,226.21,743.69,283.49,6.97;17,71.46,751.66,283.59,6.97">For example , when human player prefers to preparing ingredients , you choose to serve more dishes can effectively improve team efficiency .</s><s coords="17,360.14,751.66,153.64,6.97;17,71.41,759.63,442.53,6.97;17,71.39,767.60,70.26,6.97">When human player prefers to assemble burgers , you can choose to prepare more ingredients and pass on to the counter to meet the requirements of the human player .</s></p><p><s coords="18,71.33,76.59,442.61,6.97;18,71.33,84.56,237.69,6.97">-Consider whether there are any patterns between human player 's behavior , the current orders that need to be completed , and the ingredients available on the field .</s><s coords="18,314.08,84.56,208.10,6.97;18,75.52,92.53,237.69,6.97">For example , humans tend to prepare a large amount of beef when multiple orders for beef burgers are needed .</s><s coords="18,318.30,92.53,195.55,6.97;18,71.39,100.51,53.52,6.97">Such implicit patterns can help you adjust your own behavior .</s></p><p><s coords="18,71.33,108.48,279.54,6.97">-How the agent 's policy should be adjusted to improve performance ?</s><s coords="18,355.93,108.48,128.67,6.97;18,71.51,116.45,446.74,6.97;18,71.39,124.42,308.77,6.97">For example , if you believe the ingredients you ' ve prepared or the burgers you ' ve made are meant for the human player to assemble or serve , you should pass them to the counter to facilitate efficient collaboration .</s><s coords="18,71.39,132.39,250.02,6.97">The inference should be given ** based on the game history **.</s><s coords="18,71.39,140.36,149.76,6.97">You should return a text code block .</s><s coords="18,226.15,140.36,174.93,6.97">Be concise and clear , less than 100 words .</s><s coords="18,71.28,148.33,8.22,6.97">``D</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,91.45,176.30,294.40,10.75">Implementation of Act, ReAct and Reflexion Frameworks</head><p><s coords="18,70.87,197.98,454.91,9.46;18,70.87,211.53,347.84,9.46">ReAct <ref type="bibr" coords="18,101.71,197.98,76.16,9.46" target="#b45">(Yao et al., 2022)</ref> is a framework that integrates reasoning and acting by allowing agents to plan, interpret environments, and interact dynamically to improve decision-making.</s><s coords="18,422.63,211.53,103.14,9.46;18,70.87,225.08,453.54,9.46;18,70.87,238.63,455.45,9.46">Reflexion <ref type="bibr" coords="18,468.66,211.53,57.12,9.46;18,70.87,225.08,25.43,9.46" target="#b34">(Shinn et al., 2024)</ref> is a framework that enhances language model agents by enabling self-reflection, allowing them to learn from past mistakes, refine their reasoning, and iteratively improve decision-making in future tasks.</s><s coords="18,70.35,252.18,249.09,9.46">We use Act to name the LLM as Indenpendent System 1.</s></p><p><s coords="18,81.78,265.73,287.99,9.46">We implement Act, ReAct and Refelxion in Overcooked challenge.</s><s coords="18,373.12,265.73,151.29,9.46;18,70.87,279.28,275.70,9.46">The three frameworks use the same prompt in the instruction part with DPT-Agent in Appendix C.1.</s><s coords="18,349.95,279.28,174.46,9.46;18,70.87,292.82,207.99,9.46">We outline the specific differences in the output prompts for the three frameworks below.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,70.87,314.41,134.12,9.81">D.1 Output Prompts of Act</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,71.22,335.80,57.59,6.97"># OutputFormat</head><p><s coords="18,71.45,351.74,417.33,6.97;18,71.51,359.72,216.60,6.97">Based on the current game state , considering the remaining time for the orders and the status of all ingredients on the kitchen , decide your next action .</s><s coords="18,71.42,367.69,388.24,6.97">Note that your actions should help advance the orders you ' re working on and the game process .</s><s coords="18,464.66,367.69,40.91,6.97;18,71.42,375.66,229.23,6.97">Be sure to also consider your previous actions and their outcomes .</s><s coords="18,71.46,383.63,183.17,6.97">Please output a valid action in JSON format .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,70.87,410.94,146.84,9.81">D.2 Output Prompts of ReAct</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,71.22,432.34,57.59,6.97"># OutputFormat</head><p><s coords="18,71.46,448.28,166.43,6.97">Please output in the following template :</s></p><p><s coords="18,71.39,464.22,430.12,6.97">You should return a text code block as your thought about how to prepare and serve burgers effectively .</s><s coords="18,71.28,472.19,28.32,6.97;18,71.33,480.16,170.75,6.97">```text Be concise and clear , less than 50 words .</s><s coords="18,71.33,488.13,275.23,6.97">If no urgent responses are needed , return " Things are going well ".</s><s coords="18,71.33,496.10,179.11,6.97">Do not directly copy the previous thoughts .</s><s coords="18,71.28,504.07,3.63,6.97;18,75.47,520.01,442.65,6.97;18,71.49,527.98,36.69,6.97">``Ỳ our action should be a ** json ** code block representation of the new assigned tasks that the agent will do urgently .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,71.28,543.92,28.32,6.97">```json</head><p><s coords="18,71.39,551.89,446.64,6.97;18,71.42,559.86,86.96,6.97">You can either keep some of the current assigned tasks if you find them still necessary , or substitute them with the new ones , i .</s><s coords="18,159.08,559.86,7.67,6.97">e .</s><s coords="18,167.45,559.86,288.03,6.97">, you don 't have to include the current assigned tasks in the output .</s><s coords="18,71.39,567.83,425.67,6.97;18,71.48,575.80,32.52,6.97">You should make sure that the completed burgers are served to the customers in time , by adding serving actions .</s><s coords="18,109.05,575.80,250.19,6.97">But do not serve the burgers that are not in the order list .</s><s coords="18,71.39,583.77,262.74,6.97">You should return enough assigned tasks to keep the agent busy .</s><s coords="18,71.33,591.74,187.48,6.97">Be careful to write correct lambda functions .</s><s coords="18,71.33,599.71,204.22,6.97">Do not directly copy the previous assigned tasks .</s><s coords="18,71.39,607.68,417.56,6.97">The JSON will be used in Python as `eval ( json_string ) `, so make sure it is in the correct format , e .</s><s coords="18,489.65,607.68,7.67,6.97">g .</s><s coords="18,498.02,607.68,20.05,6.97;18,71.19,615.65,204.32,6.97;18,71.28,623.62,7.46,6.97">, use `True `and `False `instead of `true `and `false `. ``D</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,78.52,650.93,153.74,9.81">.3 Output Prompts of Reflexion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="18,71.22,672.33,57.59,6.97"># OutputFormat</head><p><s coords="18,71.45,688.27,308.71,6.97">Based on a previous reasoning , you should improve based on self refection .</s><s coords="18,385.31,688.27,124.39,6.97;18,71.48,696.24,375.63,6.97">Diagnose a possible reason for failure and devise a new , concise , high level plan that aims to mitigate the same failure .</s><s coords="18,452.16,696.24,49.07,6.97;18,71.49,704.21,40.87,6.97">Use complete sentences .</s><s coords="18,71.39,712.18,438.37,6.97;18,71.33,720.15,279.54,6.97">You should return a text code block as your reflection when you meet the following failure situations : 1) Fire , 2) Missing Order , 3) Loss Score , 4) Other unexpected situations .</s><s coords="18,71.28,728.12,28.32,6.97;18,71.33,736.09,174.93,6.97">```text Be concise and clear , less than 100 words .</s><s coords="18,71.33,744.06,245.94,6.97">If no reflection is needed , return " Things are going well ".</s><s coords="18,71.33,752.03,187.48,6.97">Do not directly copy the previous reflection .</s><s coords="18,71.28,760.00,226.36,6.97">```1</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="19,70.87,73.58,59.09,10.75">E Metrics</head><p><s coords="19,70.87,433.24,40.34,9.81">Latency.</s><s coords="19,122.12,433.67,168.83,9.46;19,70.87,447.22,220.08,9.46;19,70.87,460.77,60.45,9.46">The time in second that from the request to the output of a macro action or a code-aspolicy output.</s></p><p><s coords="19,70.87,480.77,129.39,9.81">Agent Contribution Rate.</s><s coords="19,211.16,481.20,77.97,9.46;19,70.87,494.75,218.27,9.46;19,70.87,508.30,218.54,9.46;19,70.87,521.85,57.44,9.46">A concept from <ref type="bibr" coords="19,70.87,494.75,94.33,9.46" target="#b50">Zhang et al. (2024b)</ref> to demonstrate the agent's contribution in each order based on the overcook environment.</s></p><p><s coords="19,81.78,535.40,209.27,9.46;19,70.51,548.60,218.90,9.81;19,70.47,562.49,218.66,9.46;19,70.87,576.04,56.88,9.46">Below are the definition from <ref type="bibr" coords="19,231.84,535.40,59.21,9.46;19,70.51,548.95,33.17,9.46" target="#b50">Zhang et al. (2024b)</ref>: Key task events KE are defined to track which team member completes specific tasks in Overcooked.</s><s coords="19,136.68,576.04,154.26,9.46;19,70.87,589.59,218.27,9.46;19,70.87,603.14,157.03,9.46">Based on the burger-making process, each of the three burger types involves a set of essential, non-repeatable events.</s><s coords="19,232.75,603.14,57.75,9.46;19,70.87,616.69,218.27,9.46;19,70.87,630.24,218.27,9.46;19,70.87,643.79,154.08,9.46">For instance, preparing a BeefBurger requires completing five key events: Cooking Beef, Using Beef, Using Bread, Using a Plate, and Serving.</s><s coords="19,228.92,643.79,60.22,9.46;19,70.87,657.34,129.74,9.46">Each of these key events occurs only once.</s><s coords="19,205.82,657.34,83.32,9.46;19,70.87,670.89,220.08,9.46;19,70.87,684.44,196.22,9.46">The completion of these events is triggered by specific "interact" actions, which are referred to as Key Actions.</s><s coords="19,271.84,684.44,17.30,9.46;19,70.87,697.99,218.27,9.46;19,70.53,711.54,36.70,9.46">The key actions mapping with the key events are in Table <ref type="table" coords="19,98.88,711.54,4.17,9.46">5</ref>.</s><s coords="19,114.08,711.54,175.24,9.46;19,70.87,725.09,220.08,9.46;19,70.87,738.63,73.40,9.46">Each key event completed by a player is counted once as their contribution to the overall performance.</s><s coords="19,149.26,738.63,141.68,9.46;19,70.87,752.18,220.08,9.46;19,70.87,765.73,218.27,9.46;19,305.75,74.72,220.56,9.46">Since these key events are nonrepeatable, we can determine each player's contribution by tracking the key events they complete while preparing each successfully served burger.</s><s coords="19,305.63,87.92,200.74,9.81;19,506.45,85.97,2.88,6.99;19,513.56,88.27,12.36,9.46">We define the agent's contribution ratio CR i as:</s></p><formula xml:id="formula_5" coords="19,306.14,97.73,114.79,17.08">CR i = KE i KE i +KE h × 100%</formula><p><s coords="19,420.93,101.47,54.90,9.81;19,476.47,99.52,2.88,6.99;19,482.36,101.47,36.05,9.81;19,519.03,99.52,4.88,6.99;19,306.14,115.37,218.27,9.46;19,306.14,128.92,121.25,9.46">, where KE i and KE h represent the key events completed by the agent and the human respectively.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="19,306.14,152.46,197.60,10.75">F Details of the LLM as Independent</head><p><s coords="19,325.07,166.41,186.31,10.75">System 1 and System 2 Experiments .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="19,306.14,188.71,137.89,9.81">F.1 Models and Deployment</head><p><s coords="19,306.14,207.14,220.08,9.46;19,306.14,220.69,218.26,9.46;19,305.78,234.24,219.99,9.46;19,306.14,247.79,219.63,9.46;19,306.14,261.34,219.00,9.46;19,306.14,274.89,162.09,9.46;19,317.05,288.28,207.36,9.88;19,317.05,302.09,209.17,9.88;19,306.14,316.07,218.27,9.46;19,306.14,329.62,50.29,9.46">In this series of experiments, we use 8 different model series including GPT (OpenAI), Qwen <ref type="bibr" coords="19,305.78,234.24,80.89,9.46" target="#b21">(Yang et al., 2024)</ref>, Llama <ref type="bibr" coords="19,425.66,234.24,95.32,9.46" target="#b37">(Touvron et al., 2023)</ref>, <ref type="bibr" coords="19,306.14,247.79,110.59,9.46">Phi (Abdin et al., 2024)</ref>, Gemma <ref type="bibr" coords="19,466.54,247.79,59.23,9.46;19,306.14,261.34,23.95,9.46" target="#b36">(Team et al., 2024)</ref>, Mistral (AI), DeepSeek <ref type="bibr" coords="19,445.14,261.34,79.99,9.46">(Liu et al., 2024a)</ref> and DeepSeek-R1 <ref type="bibr" coords="19,387.94,274.89,75.54,9.46" target="#b13">(Guo et al., 2025)</ref>: GPT Series: GPT-4o, GPT-4o-mini and o3-mini Qwen Series: Qwen2.5 with 5 different sizes including 3b, 7b, 14b, 32b and 72b (Lisence: Apache license 2.0)</s></p><p><s coords="19,317.05,343.01,128.60,9.88">Llama Series: Llama3.1-8b,</s><s coords="19,448.41,343.43,76.00,9.46;19,306.14,356.98,61.51,9.46">Llama3.2-3b and Llama3.3-70b</s><s coords="19,370.37,356.98,71.85,9.46">(Lisence: llama)</s></p><p><s coords="19,317.05,370.37,208.87,9.88;19,306.14,384.35,23.63,9.46">Phi Series: Phi-3.5-3.8b and Phi-4-14b (Lisence: MIT)</s></p><p><s coords="19,317.05,397.74,207.36,9.88;19,306.14,411.71,191.24,9.46">Gemma Series: Gemma2 with 3 different sizes including 2b, 9b and 27b (Lisence: gemma)</s></p><p><s coords="19,317.05,425.11,207.36,9.88;19,306.14,439.08,93.34,9.46">Mistral Series: Ministral with 2 different sizes including 3b and 8b,  DeepSeek Series: DeepSeek-V2-16b and DeepSeek-V2.5 (Lisence: MIT)</s></p><p><s coords="19,317.05,493.39,209.17,9.88;19,306.14,507.36,218.27,9.46;19,305.78,520.91,67.60,9.46;19,317.05,534.73,207.36,9.46;19,305.75,548.28,218.66,9.46;19,305.78,561.82,218.63,9.46;19,306.14,575.37,151.98,9.46">DeepSeek-R1 Series: DeepSeek-R1 with 5 different sizes including 7b, 8b, 14b, 32b and 70b (Lisence: <ref type="bibr" coords="19,349.76,520.91,23.63,9.46">MIT)</ref> All the open-source models are locally deployed with NVIDIA A800-SXM4-80GB through ollama <ref type="bibr" coords="19,305.78,561.82,90.95,9.46">(Contributors, 2023)</ref>, with the number of cards used determined by the model size.</s><s coords="19,461.52,575.37,64.70,9.46;19,306.14,588.92,218.27,9.46">For DeepSeek-R1 series in Long CoT, we deploy via llama.cpp</s><s coords="19,305.78,602.47,220.44,9.46;19,306.14,616.02,17.00,9.46"><ref type="bibr" coords="19,305.78,602.47,78.86,9.46" target="#b10">(Gerganov, 2023)</ref> for customizing structured output.</s><s coords="19,327.45,616.02,196.96,9.46;19,306.14,629.57,103.67,9.46">The GPT series models use native API calls to conduct experiments.</s><s coords="19,413.20,629.57,111.21,9.46;19,305.75,643.12,218.66,9.46;19,306.14,656.67,172.94,9.46">The experiments use 26.3 A800-SXM4-80GB GPU hours for open-source models and $ 35 in OpenAI API cost.</s><s coords="19,484.96,656.67,41.26,9.46;19,306.14,670.22,218.27,9.46;19,306.14,683.77,218.27,9.46;19,305.87,697.32,30.33,9.46">All models had their temperature parameter set to 0, while the remaining parameters were kept at their default values.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="19,306.14,720.20,100.00,9.81">F.2 Detailed Results</head><p><s coords="19,305.63,738.63,133.33,9.46">We list the data from Figure <ref type="figure" coords="19,433.39,738.63,5.56,9.46" target="#fig_1">2</ref></s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="24,70.87,73.58,211.24,10.75">H Details of Capability in Simultaneous</head><p><s coords="24,92.12,87.52,139.15,10.75">Collaboration Experiments</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="24,70.87,110.90,140.91,9.81">H.1 Models and Deployment</head><p><s coords="24,70.87,130.20,218.27,9.46;24,70.87,143.75,220.08,9.46;24,70.87,157.30,218.27,9.46;24,70.51,170.84,218.90,9.46;24,70.51,184.39,79.99,9.46">In this series of experiments, we used 5 different model series including GPT (OpenAI), Claude (Anthropic, 2024), Qwen <ref type="bibr" coords="24,170.42,157.30,82.09,9.46" target="#b21">(Yang et al., 2024)</ref>, Llama <ref type="bibr" coords="24,70.51,170.84,93.13,9.46" target="#b37">(Touvron et al., 2023)</ref>, Mistral (AI) and DeepSeek <ref type="bibr" coords="24,70.51,184.39,75.29,9.46" target="#b13">(Guo et al., 2025)</ref>.</s></p><p><s coords="24,81.78,198.22,207.36,9.88;24,81.78,212.47,146.40,9.88">GPT Series: GPT-4o, GPT-4o-mini and o3-mini Claude Series: Claude-3.5-haiku</s><s coords="24,81.78,226.72,126.05,9.88">Qwen Series: Qwen2.5-72b</s><s coords="24,210.52,227.15,78.62,9.46;24,70.87,240.70,121.18,9.46">(Lisence: Apache license 2.0) and Qwen-Max</s></p><p><s coords="24,81.78,254.52,128.82,9.88">Llama Series: Llama3.3-70b</s><s coords="24,213.33,254.95,71.85,9.46;24,81.78,268.78,209.17,9.88;24,70.87,282.75,18.17,9.46">(Lisence: llama) Mistral Series: Mixtral-8x22b (Lisence: mistral)</s></p><p><s coords="24,81.78,296.58,92.00,9.81;24,199.96,297.00,90.53,9.46;24,70.87,310.55,218.94,9.46;24,81.78,324.80,207.36,9.46;24,70.47,338.35,218.66,9.46;24,70.51,351.90,218.63,9.46;24,70.87,365.45,133.33,9.46">DeepSeek Series: DeepSeek-R1-671b, DeepSeek-V2.5 and DeepSeek-V3 (Lisence: <ref type="bibr" coords="24,266.53,310.55,23.27,9.46">MIT)</ref> All the open-source models are locally deployed with NVIDIA A800-SXM4-80GB through vLLM <ref type="bibr" coords="24,70.51,351.90,81.68,9.46" target="#b18">(Kwon et al., 2023)</ref>, with the number of cards used determined by the model size.</s><s coords="24,207.59,365.45,83.36,9.46;24,70.59,379.00,218.93,9.46;24,70.87,392.55,218.27,9.46;24,70.51,406.10,95.14,9.46">For DeepSeek-R1-70b and DeepSeek-V3, we use 8 and 16 NVIDIA H100 80GB HBM3 for deployment through vLLM <ref type="bibr" coords="24,70.51,406.10,90.35,9.46" target="#b18">(Kwon et al., 2023)</ref>.</s><s coords="24,174.82,406.10,116.12,9.46;24,70.87,419.65,42.34,9.46">The GPT series, Claude-3.5-haiku</s><s coords="24,116.15,419.65,172.98,9.46;24,70.87,433.20,95.02,9.46">and Qwen-Max use native API calls to conduct experiments.</s><s coords="24,169.41,433.20,119.73,9.46;24,70.47,446.75,220.48,9.46;24,70.87,460.30,219.63,9.46;24,70.87,473.84,218.27,9.46;24,70.87,487.39,125.96,9.46">The experiments use 350.9 A800-SXM4-80GB GPU hours and 210.5 H100-80GB-HBM3 GPU hours for open-source models, $ 400 in OpenAI API cost, $ 80 in Claude API cost and $ 120 in Qwen API cost.</s><s coords="24,200.21,487.39,89.11,9.46;24,70.87,500.94,218.27,9.46;24,70.87,514.49,192.48,9.46">All models had their temperature parameter set to 0, while the remaining parameters were kept at their default values.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="24,70.87,538.89,93.92,9.81">H.2 Other Metrics</head><p><s coords="24,70.35,558.18,218.78,9.46;24,70.87,571.73,143.91,9.46">We list the more metrics Table <ref type="table" coords="24,206.49,558.18,10.94,9.46" target="#tab_12">10</ref> including Score Efficiency and latency in second.</s><s coords="24,70.87,646.37,218.27,9.46;24,70.87,659.92,208.19,9.46">Below is the ToM module output of DPT-Agent in the 78th timestep, driven by DeepSeek-R1-70b.</s><s coords="24,282.43,659.92,6.70,9.46;24,70.87,673.47,218.27,9.46;24,70.87,687.02,220.08,9.46;24,70.87,700.57,112.69,9.46">It demonstrates that DPT-Agent's ToM mechanism effectively helps the agent infer that its partner specializes in preparing beef.</s></p><p><s coords="24,71.49,719.78,99.45,6.97">Inferred Human Behavior :</s></p><p><s coords="24,71.33,727.75,208.23,6.97;24,71.46,735.72,216.52,6.97;24,75.57,743.69,49.34,6.97;24,71.33,751.66,3.49,6.97">-The human player focuses on beef preparation and distribution , frequently passing well -cooked beef to the counter .</s><s coords="24,79.76,751.66,182.97,6.97;24,71.48,759.63,203.82,6.97;24,71.49,767.60,36.69,6.97">-The agent should complement this by handling lettuce preparation , bread management , and burger assembly .</s></p><p><s coords="24,306.61,76.59,216.77,6.97;24,310.96,84.56,203.80,6.97;24,306.72,92.54,174.81,6.97">-The human ' s consistent passing of beef indicates a preference for handling meat , so the agent should focus on other tasks to optimize teamwork .</s></p><p><s coords="24,306.61,100.51,208.17,6.97;24,306.61,108.48,191.40,6.97;24,306.75,116.45,82.73,6.97">-The agent should pass prepared lettuce and bread to the counter to enable the human to assemble burgers efficiently .</s></p><p><s coords="24,306.61,124.42,212.41,6.97;24,306.72,132.39,195.48,6.97;24,306.74,140.36,120.39,6.97">-By dividing tasks based on the human 's focus , the agent can improve overall efficiency and ensure orders are completed on time .</s><s coords="24,306.14,196.44,218.27,9.46;24,306.14,209.99,220.08,9.46;24,306.14,223.54,42.61,9.46">Below is the Reflection and ToM module output of DPT-Agent in the 266th timestep, driven by o3mini-low.</s><s coords="24,352.67,223.54,171.75,9.46;24,306.14,237.09,218.27,9.46;24,306.14,250.64,168.23,9.46">It demonstrates that DPT-Agent's ToM mechanism effectively helps the agent infer that its partner specializes in burger assembly.</s></p><p><s coords="24,306.76,267.86,82.72,6.97;24,306.72,275.83,212.18,6.97;24,306.70,283.80,170.42,6.97;24,306.78,291.77,91.07,6.97">Behavior Guidelines : Focus on avoiding overcooking by closely monitoring beef cooking times and switching to fresh ingredients if needed .</s><s coords="24,403.01,291.77,90.87,6.97;24,306.75,299.74,199.89,6.97">Prioritize orders with minimal remaining time to prevent missed orders .</s><s coords="24,306.72,307.71,203.81,6.97;24,306.75,315.68,128.76,6.97">Avoid repetitive actions like serving beefburgers without verifying order demand .</s><s coords="24,440.66,315.68,70.05,6.97;24,306.75,323.65,203.96,6.97;24,306.67,331.62,199.80,6.97;24,306.70,339.59,40.94,6.97">Delegate tasks by quickly preparing ingredients and passing them to the human player , minimizing counter clutter and idle time .</s></p><p><s coords="24,306.77,355.53,178.95,6.97">Inference on Human Player Behavior Pattern :</s></p><p><s coords="24,306.67,363.50,191.37,6.97;24,306.74,371.47,183.05,6.97;24,306.78,379.44,170.57,6.97">The human player prioritizes urgent beef -based orders and rapid assembly , often focusing on assembling and serving ready -to -go items .</s><s coords="24,482.47,379.44,19.76,6.97;24,306.76,387.41,199.88,6.97;24,306.75,395.38,203.81,6.97;24,306.78,403.35,49.22,6.97">Their approach suggests a preference for quick , orderfocused actions , emphasizing the need for prepped ingredients .</s><s coords="24,361.06,403.35,132.91,6.97;24,306.77,411.32,195.43,6.97;24,306.77,419.29,166.12,6.97;24,306.79,427.26,53.40,6.97">The agent should support this by preparing well -cooked beef and promptly passing completed ingredients to ensure smoother coordination .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="24,306.14,455.50,174.34,10.75;24,306.14,476.85,71.41,9.81">I Details of Human Experiments I.1 Procedure</head><p><s coords="24,305.63,494.75,219.16,9.46;24,306.14,508.30,158.34,9.46">We recruited 71 participants from the university through its internal social platform.</s><s coords="24,468.80,508.30,57.42,9.46;24,306.14,521.85,218.45,9.46;24,306.14,535.40,59.03,9.46">Each participant received a compensation of 50 RMB for their participation.</s><s coords="24,370.14,535.40,156.08,9.46;24,306.14,548.95,220.17,9.46">To enhance engagement and attentiveness, we provided performance-based bonuses.</s></p><p><s coords="24,306.14,562.49,218.27,9.46;24,306.14,576.04,220.07,9.46;24,306.14,589.59,180.88,9.46">Participants within each group were ranked based on their self-play performance and their performance across four different agent games.</s><s coords="24,490.43,589.59,33.98,9.46;24,306.14,603.14,218.27,9.46;24,306.14,616.69,220.08,9.46;24,306.14,630.24,144.86,9.46">The top 25% in playing with each agent and self-play can receive an additional bonus of 3 RMB with a maximum possible bonus of 15 RMB.</s><s coords="24,317.05,643.79,207.36,9.46;24,306.14,657.34,218.27,9.46;24,305.75,670.89,193.32,9.46">The experiment was conducted online, where participants completed the tasks on a designated webpage using a computer with a keyboard.</s><s coords="24,502.45,670.89,21.96,9.46;24,306.14,684.44,183.39,9.46">Each session lasted approximately 40 minutes.</s><s coords="24,493.63,684.44,32.59,9.46;24,306.14,697.99,218.27,9.46;24,306.14,711.54,220.18,9.46">Participants controlled the chef using the arrow keys and interacted with objects by pressing the spacebar.</s><s coords="24,305.80,725.09,218.61,9.46;24,306.14,738.63,201.62,9.46">The entire experimental process was recorded, with playback support available for data validation.</s></p><p><s coords="24,317.05,752.18,207.36,9.46;24,306.14,765.73,45.73,9.46">Participants were randomly assigned to one of two maps.</s><s coords="24,355.74,765.73,170.48,9.46;25,70.87,295.41,218.26,9.46;25,70.87,308.96,218.27,9.46;25,70.87,322.51,63.46,9.46">Within a group, each participant inter-  acted with four different agents, playing two games per agent, resulting in a total of eight games in random order.</s><s coords="25,140.93,322.51,148.20,9.46;25,70.87,336.06,218.26,9.46;25,70.87,349.60,218.27,9.46;25,70.87,363.15,218.27,9.46;25,70.87,376.70,132.73,9.46">To examine whether participants could infer the agents' capabilities, they were not informed of the agent types but were only made aware that the experiment involved four types of agents, differentiated by color.</s><s coords="25,81.78,391.49,207.36,9.46;25,70.87,405.04,218.27,9.46;25,70.87,418.59,220.08,9.46;25,70.87,432.14,28.21,9.46">Before beginning the experiment, all participants completed an informed consent form (Figure <ref type="figure" coords="25,262.62,405.04,4.45,9.46" target="#fig_12">7</ref>) and read instructions detailing the game rules and operations.</s><s coords="25,102.46,432.14,188.49,9.46;25,70.87,445.68,218.27,9.46;25,70.47,459.23,177.24,9.46">Following the instructions, they first participated in a non-scored trial to familiarize themselves with the environment, rules, and controls.</s><s coords="25,251.04,459.23,38.09,9.46;25,70.87,472.78,220.08,9.46;25,70.87,486.33,19.70,9.46">This was followed by a scored trial to assist with data validation.</s></p><p><s coords="25,81.78,501.12,209.17,9.46;25,70.87,514.67,218.45,9.46;25,70.87,528.21,220.18,9.46">In the formal experiment, after each game, participants were asked to rank the agents based on their collaborative capabilities and personal preference.</s><s coords="25,70.87,541.76,218.27,9.46;25,70.87,555.31,218.45,9.46;25,70.87,568.86,218.27,9.46;25,70.87,582.41,75.69,9.46">Upon completing all eight games, they filled out an additional questionnaire, where we collected their perceptions of task load and their intended level of task engagement.</s></p><p><s coords="25,81.78,597.20,200.10,9.46">The experiment use $ 30 in OpenAI API cost.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="25,70.87,623.43,80.19,9.81">I.2 Participants</head><p><s coords="25,70.47,643.79,220.56,9.46">A total of 71 participants participated in the study.</s><s coords="25,70.53,657.34,220.41,9.46;25,70.87,670.89,149.29,9.46">The first and second authors of the article independently validated all collected data.</s><s coords="25,223.54,670.89,65.60,9.46;25,70.87,684.44,218.46,9.46;25,70.87,697.99,220.08,9.46;25,70.59,711.54,220.36,9.46;25,70.87,725.09,218.27,9.46;25,70.87,738.63,192.26,9.46">This validation included checking data completeness (e.g., whether participants completed all the experiments) and reviewing the recorded playbacks to identify any abnormal actions (e.g., instances where participants did not engage in any cooperative behavior).</s><s coords="25,266.51,738.63,22.81,9.46;25,70.87,752.18,220.08,9.46;25,70.87,765.73,218.27,9.46;25,306.14,295.41,219.63,9.46;25,306.14,308.96,220.18,9.46">After data validation, we excluded any data with anomalies, including passive participation and missing data, resulting in 68 valid participants (M = 36, F = 32, and Others = 0, ages between 18 and 31).</s><s coords="25,306.14,322.51,218.27,9.46;25,306.14,336.06,151.83,9.46">Group 1 (Map 1) has 36 valid data points and Group 2 (Map 2) has 32 valid data points.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,306.14,341.13,218.26,8.64;1,306.14,353.09,63.84,8.64;1,392.01,241.79,101.77,69.20"><head>Figure 1 :</head><label>1</label><figDesc><div><p><s coords="1,306.14,341.13,218.26,8.64;1,306.14,353.09,63.84,8.64">Figure 1: How DPT-Agent Collaborates with Human Simultaneously.</s></p></div></figDesc><graphic coords="1,392.01,241.79,101.77,69.20" type="bitmap"/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,306.14,187.09,218.27,9.03;3,305.89,199.04,218.52,9.03;3,306.14,211.39,218.27,8.64;3,306.14,223.34,218.27,8.64;3,306.14,235.30,218.27,8.64;3,306.14,247.25,216.55,8.64"><head>Figure 2 :</head><label>2</label><figDesc><div><p><s coords="3,306.14,187.09,218.27,9.03;3,305.89,199.04,72.00,8.96">Figure 2: LLM as Independent System 1 and System 2 in Overcooked.</s><s coords="3,381.00,199.43,143.41,8.64;3,306.14,211.39,99.13,8.64">Mean score means the inter-quartile mean score of 20 games.</s><s coords="3,408.36,211.39,116.05,8.64;3,306.14,223.34,170.67,8.64">We define score efficiency as the average score gained per macro action.</s><s coords="3,479.91,223.34,44.50,8.64;3,306.14,235.30,218.27,8.64;3,306.14,247.25,216.55,8.64">The size of each model's circle represents latency, which is the time taken from the request to the output of a macro action.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,306.14,161.37,218.49,9.03;6,306.14,173.32,220.01,8.96;6,306.14,185.49,219.92,8.82;6,306.14,197.62,218.26,8.64;6,306.14,209.40,129.14,8.82;6,306.14,70.87,218.27,79.05"><head>Figure 4 :</head><label>4</label><figDesc><div><p><s coords="6,306.14,161.37,218.49,9.03;6,306.14,173.32,220.01,8.96">Figure 4: Two Layouts in Overcooked Challenge for Real-time Simultaneous Human-AI Collaboration.</s><s coords="6,306.14,185.49,219.92,8.82;6,306.14,197.62,164.02,8.64">Left is Map 1 -New Counter Circuit with brief introduction of the item and game mechanism.</s><s coords="6,473.24,197.62,51.17,8.64;6,306.14,209.40,129.14,8.82">Right is Map 2 -New Asymmetric Advantages</s></p></div></figDesc><graphic coords="6,306.14,70.87,218.27,79.05" type="bitmap"/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,79.56,120.99,2.70,5.41;7,78.35,100.57,5.13,5.41;7,77.26,80.16,7.50,5.41;7,77.50,141.40,7.03,5.41;7,140.58,153.65,2.54,5.41;7,191.59,153.45,2.81,5.41;7,199.58,124.12,9.95,4.51;7,192.28,129.02,17.25,4.51;7,91.32,76.55,23.86,4.51;7,102.58,84.86,22.00,5.41;7,177.75,112.00,11.91,4.06;7,101.60,133.64,20.48,4.06;7,157.31,107.31,22.15,4.06;7,164.88,117.72,21.31,4.06;7,126.44,140.79,29.27,4.06;7,123.58,148.95,24.95,4.06;7,161.35,126.09,29.17,4.06;7,167.47,97.51,29.36,4.06;7,110.36,128.13,23.17,4.06;7,123.43,120.78,40.33,7.32;7,128.15,105.67,20.66,4.06;7,192.38,135.48,16.65,16.92;7,125.90,167.46,38.70,7.77;7,224.59,120.99,2.70,5.41;7,223.38,100.57,5.13,5.41;7,222.30,80.16,7.50,5.41;7,222.53,141.40,7.03,5.41;7,285.21,154.27,2.54,5.41;7,336.21,154.27,2.81,5.41;7,236.36,76.55,30.50,4.51;7,278.48,107.10,11.91,4.06;7,247.61,84.86,22.00,5.41;7,252.08,147.52,24.95,4.06;7,237.17,126.90,20.66,4.06;7,268.45,135.07,21.15,4.06;7,229.69,148.14,20.48,4.06;7,313.37,113.84,22.15,4.06;7,229.38,144.05,21.31,4.06;7,287.60,129.76,29.27,4.06;7,233.29,138.13,29.17,4.06;7,300.92,118.33,23.17,4.06;7,265.35,122.82,51.29,5.28;7,343.79,124.12,9.95,4.51;7,336.49,129.02,17.25,4.51;7,336.59,135.48,16.65,16.92;7,264.06,167.46,51.03,7.77;7,368.40,121.19,2.70,5.41;7,367.19,100.78,5.13,5.41;7,366.11,80.36,7.50,5.41;7,366.34,141.61,7.03,5.41;7,429.02,154.47,2.54,5.41;7,480.02,154.47,2.81,5.41;7,380.17,76.75,49.26,4.51;7,391.42,85.06,22.00,5.41;7,477.55,101.59,19.90,4.06;7,450.05,108.94,11.91,4.06;7,463.12,114.86,20.48,4.06;7,485.71,91.79,29.27,4.06;7,463.66,109.75,29.17,4.06;7,443.71,128.74,23.17,4.06;7,400.78,114.25,50.59,7.53;7,443.81,121.19,21.33,4.06;7,417.17,127.92,22.15,4.06;7,417.49,121.80,21.31,4.06;7,469.58,106.08,24.95,4.06;7,503.94,124.12,9.95,4.51;7,496.63,129.02,17.25,4.51;7,497.55,135.68,16.65,16.92;7,396.31,167.46,91.29,7.77"><head/><label/><figDesc><div><p><s coords="7,409.86,167.46,77.74,7.77">DPT-Agent w/o ToM.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,85.46,191.34,424.37,9.03"><head>Figure 5 :</head><label>5</label><figDesc><div><p><s coords="7,85.46,191.34,424.37,9.03">Figure 5: Results of LLM with ReAct, Refelxion and DPT-Agent w/o ToM in the Single Agent Game.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="12,70.87,620.45,220.01,9.03;12,70.54,632.40,218.60,9.03;12,70.87,644.75,218.27,8.64;12,70.87,656.70,218.27,8.64;12,70.87,668.66,110.26,8.64"><head>Figure 6 :</head><label>6</label><figDesc><div><p><s coords="12,70.87,620.45,220.01,9.03;12,70.54,632.40,35.28,8.96">Figure 6: Game Mechanism from Zhang et al. (2024b).</s><s coords="12,111.72,632.79,177.42,8.64;12,70.87,644.75,82.53,8.64">(a), (b), and (c) are the rules for preparing and serving burgers.</s><s coords="12,156.99,644.75,132.15,8.64;12,70.87,656.70,218.27,8.64;12,70.87,668.66,110.26,8.64">(d) demonstrates the mechanism of overcooked beef and the rules for handling the fire caused by overcooked beef.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="13,79.70,233.61,438.37,6.97;13,71.49,241.58,78.52,6.97;13,71.33,249.55,392.47,6.97;13,71.33,257.52,149.65,6.97;13,79.70,265.49,128.86,6.97;13,79.70,273.46,170.70,6.97;13,71.33,281.43,204.22,6.97;13,71.33,289.40,275.35,6.97;13,71.33,297.37,162.38,6.97"><head/><label/><figDesc><div><p><s coords="13,79.70,233.61,438.37,6.97;13,71.49,241.58,78.52,6.97;13,71.33,249.55,3.49,6.97">** Central Counter Area **: The central space has a counter where ingredients can be placed temporarily for efficient workflow .</s><s coords="13,79.70,249.55,384.10,6.97;13,71.33,257.52,149.65,6.97;13,79.70,265.49,128.86,6.97;13,79.70,273.46,170.70,6.97;13,71.33,281.43,204.22,6.97;13,71.33,289.40,3.49,6.97">-** Ingredient Stations **: Distribution stations for picking up `Lettuce `, `Beef `and `Bread `. -** Cooking and Preparation Tools **: -** Pans **: for cooking `Beef `. -** Cutboards **: for preparing `Lettuce `. -** Plate Station **: for picking up empty plates .</s><s coords="13,79.70,289.40,266.98,6.97;13,71.33,297.37,3.49,6.97">-** Fire Extinguisher **: for extinguishing fires and can be moved .</s><s coords="13,79.70,297.37,154.01,6.97">-** Serving Area **: for serving orders .</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="15,71.22,424.31,3.49,6.97;15,87.95,432.28,3.49,6.97;15,104.69,440.25,417.74,6.97;15,104.81,448.22,400.88,6.97;15,104.92,456.19,120.77,6.97"><head/><label/><figDesc><div><p><s coords="15,138.45,440.25,383.98,6.97;15,104.81,448.22,400.88,6.97;15,104.92,456.19,120.77,6.97">json_state : ␣ json_state [ ' objects '][( ' Beef ',␣ 'Well -cooked ') ] ␣ + ␣ json_state [ ' objects '][( ' Beef ',␣ 'In -progress ') ] ␣ &lt;␣ sum ( order [ ' name '] ␣ == ␣ ' BeefBurger '␣ or ␣ order [ ' name '] ␣ == ␣ ' BeefLettuceBurger '␣ for ␣ order ␣ in ␣ json_state [' orders ']</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="24,70.87,596.12,80.01,9.81;24,70.87,615.00,205.47,9.81;24,106.23,628.55,77.26,9.81"><head>H. 3</head><label>3</label><figDesc><div><p><s coords="24,98.44,596.12,52.43,9.81;24,70.87,615.00,205.47,9.81;24,106.23,628.55,77.26,9.81">Case Study H.3.1 Example of DPT-Agent when playing with Beef Agent.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11" coords="24,306.14,166.46,205.47,9.81;24,341.51,180.01,141.27,9.81"><head>H</head><label/><figDesc><div><p><s coords="24,311.11,166.46,200.50,9.81;24,341.51,180.01,141.27,9.81">.3.2 Example of DPT-Agent when playing with Assemble &amp; Serve Agent.</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="26,232.31,625.08,130.66,8.64;26,116.22,208.55,362.83,404.69"><head>Figure 7 :</head><label>7</label><figDesc><div><p><s coords="26,232.31,625.08,130.66,8.64">Figure 7: Experiment Statement.</s></p></div></figDesc><graphic coords="26,116.22,208.55,362.83,404.69" type="bitmap"/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,72.44,75.38,443.41,285.84"><head>Table 1 :</head><label>1</label><figDesc><div><p><s coords="8,122.81,258.74,384.57,8.96">Performance with Standard Errors of Experiments Collaborating with Rule-based Agents.</s></p></div></figDesc><table coords="8,72.44,75.38,443.41,285.84"><row><cell cols="2">Framework</cell><cell/><cell cols="2">Score</cell><cell/><cell cols="2">Agent Contribution Rate</cell></row><row><cell>Model</cell><cell/><cell>ReAct</cell><cell>Refelxion</cell><cell>DPT-Agent DPT-Agent w/o ToM</cell><cell>ReAct</cell><cell>Refelxion</cell><cell>DPT-Agent DPT-Agent w/o ToM</cell></row><row><cell cols="2">o3-mini-low</cell><cell cols="6">7.00(7.491) 33.50(7.06) 44.83(9.74) 51.33(8.67) 0.60(0.05) 0.62(0.02) 0.56(0.04)</cell><cell>0.68(0.03)</cell></row><row><cell>GPT-4o</cell><cell/><cell cols="6">35.67(9.62) 39.17(8.43) 18.67(8.50) 39.50(8.63) 0.60(0.02) 0.61(0.02) 0.60(0.05)</cell><cell>0.69(0.04)</cell></row><row><cell cols="2">GPT-4o-mini</cell><cell>-6.58(5.37)</cell><cell>5.58(7.53)</cell><cell cols="4">50.00(5.27) 52.92(6.34) 0.27(0.07) 0.46(0.06) 0.66(0.02) 0.67(0.02)</cell></row><row><cell cols="2">Qwen-Max</cell><cell cols="6">30.50(6.58) 21.17(6.23) 51.50(9.27) 53.83(7.33) 0.59(0.03) 0.60(0.03) 0.68(0.04)</cell><cell>0.70(0.03)</cell></row><row><cell cols="2">Claude 3.5 Haiku</cell><cell cols="6">29.50(5.63) 24.83(6.58) 43.17(8.01) 41.50(7.69) 0.62(0.04) 0.58(0.03) 0.67(0.03)</cell><cell>0.70(0.03)</cell></row><row><cell cols="2">DeepSeek-V3</cell><cell cols="6">29.17(8.24) 33.33(7.76) 70.33(5.28) 61.83(5.86) 0.60(0.03) 0.58(0.02) 0.74(0.01)</cell><cell>0.74(0.02)</cell></row><row><cell cols="8">DeepSeek-R1-70b 33.83(6.73) -2.67(5.98) 51.00(6.08) 61.50(6.40) 0.57(0.01) 0.55(0.05) 0.69(0.02)</cell><cell>0.66(0.02)</cell></row><row><cell cols="2">DeepSeek-V2.5</cell><cell cols="2">-6.00(5.23) 12.33(4.83)</cell><cell cols="4">31.50(6.58) 23.50(8.44) 0.25(0.02) 0.47(0.04) 0.64(0.04)</cell><cell>0.60(0.04)</cell></row><row><cell cols="2">Qwen2.5-72b</cell><cell cols="6">18.03(4.69) 48.67(5.68) 18.83(5.51) 32.08(5.17) 0.75(0.01) 0.58(0.01) 0.67(0.04)</cell><cell>0.67(0.03)</cell></row><row><cell cols="2">Llama3.3-70b</cell><cell cols="6">27.97(5.68) -15.58(5.28) 30.75(3.86) 28.08(6.68) 0.74(0.03) 0.54(0.05) 0.85(0.02)</cell><cell>0.75(0.05)</cell></row><row><cell cols="2">Mixtral-8x22b</cell><cell cols="6">20.17(6.30) 24.67(6.07) 24.00(6.10) 26.83(5.79) 0.54(0.03) 0.54(0.03) 0.70(0.06)</cell><cell>0.60(0.03)</cell></row><row><cell>Overall</cell><cell/><cell cols="6">19.77(6.51) 20.39(6.49) 39.44(6.75) 43.06(7.00) 0.56(0.03) 0.56(0.03) 0.68(0.03)</cell><cell>0.68(0.03)</cell></row><row><cell/><cell cols="3">Map 1 -New Counter Circuit</cell><cell/><cell/><cell/></row><row><cell>Frameworks</cell><cell>ReAct</cell><cell>Reflexion</cell><cell cols="2">DPT-Agent w/o ToM DPT-Agent</cell><cell/><cell/></row><row><cell>Mean Score</cell><cell>99.03(9.86)</cell><cell>97.78(7.23)</cell><cell>103.19(7.06)</cell><cell>111.53(5.42)</cell><cell/><cell/></row><row><cell>Agent CR</cell><cell>0.51(0.03)</cell><cell>0.53(0.03)</cell><cell>0.62(0.02)</cell><cell>0.62(0.02)</cell><cell/><cell/></row><row><cell/><cell cols="3">Map 2 -New Asymmetric Advantages</cell><cell/><cell/><cell/></row><row><cell>Frameworks</cell><cell>ReAct</cell><cell>Reflexion</cell><cell cols="2">DPT-Agent w/o ToM DPT-Agent</cell><cell/><cell/></row><row><cell cols="3">Mean Score 115.00(9.28) 119.67(10.54)</cell><cell>152.03(8.13)</cell><cell>160.63(7.97)</cell><cell/><cell/></row><row><cell>Agent CR</cell><cell>0.49(0.04)</cell><cell>0.51(0.03)</cell><cell>0.62(0.02)</cell><cell>0.59(0.03)</cell><cell/><cell/></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,70.47,283.44,446.59,491.75"><head>Table 2 :</head><label>2</label><figDesc><div><p><s coords="8,107.60,375.29,183.19,8.96;8,70.87,387.25,107.79,8.96">Performance with Standard Errors of Experiments with Humans.</s><s coords="8,183.10,387.64,106.03,8.64;8,70.87,399.59,73.97,8.64">Agent CR refers to Agent Contribution Rate.</s></p></div></figDesc><table coords="8,70.47,283.44,446.59,424.01"><row><cell cols="4">Layouts Perception ReAct Reflexion</cell><cell cols="2">DPT-Agent DPT-Agent w/o ToM</cell></row><row><cell>Map 1</cell><cell>Cooperation</cell><cell>88</cell><cell>79</cell><cell>86</cell><cell>107</cell></row><row><cell/><cell>Preference</cell><cell>88</cell><cell>80</cell><cell>91</cell><cell>101</cell></row><row><cell>Map 2</cell><cell>Cooperation</cell><cell>65</cell><cell>78</cell><cell>94</cell><cell>83</cell></row><row><cell/><cell>Preference</cell><cell>63</cell><cell>73</cell><cell>95</cell><cell>89</cell></row><row><cell>vide detailed results and case analyses of different</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>partners in Appendix H.3.</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>6.3 Experiments with Real Humans</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>After data validation, we have 68 valid data points</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>in total: 36 of Map 1 and 32 of Map 2. The data</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>validation details are in Appendix I. As shown in</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>Table 2, DPT-Agent achieves the highest scores in</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>both Map 1 and Map 2 when collaborating with</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>humans. DPT-Agent w/o ToM also outperforms</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>ReAct and Reflexion, confirming the effectiveness</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>of asynchronous reflection. Moreover, the ToM</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>module also brought a significant score improve-</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>ment in collaborating with humans, confirming that</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>incorporating human belief reasoning into System</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>2 can foster better collaboration. Regarding hu-</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>man perception (Table 3), DPT-Agent ranks highest</cell><cell/><cell/><cell/><cell/><cell/></row><row><cell>in Map 1, with the most participants recognizing</cell><cell/><cell/><cell/><cell/><cell/></row></table><note coords="8,70.87,711.54,219.63,9.46;8,70.87,725.09,218.27,9.46;8,70.87,738.63,218.45,9.46;8,70.87,752.18,220.08,9.46;8,70.87,765.73,195.27,9.46"><p><s coords="8,70.87,711.54,111.82,9.46">its collaborative abilities.</s><s coords="8,186.32,711.54,104.17,9.46;8,70.87,725.09,218.27,9.46;8,70.87,738.63,218.45,9.46;8,70.87,752.18,220.08,9.46;8,70.87,765.73,195.27,9.46">Interestingly, in Map 2, DPT-Agent w/o ToM surpasses DPT-Agent in both cooperation and preference ranking with a higher agent contribution rate, which may refer to the human preference for partners who work more.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,305.80,361.71,220.42,413.48"><head>Table 3 :</head><label>3</label><figDesc><div><p><s coords="8,341.37,361.71,183.04,8.96;8,306.14,373.67,83.72,8.96">Borda Count Result of Humans' Perceived Subjective Ranking.</s><s coords="8,392.94,374.06,131.47,8.64;8,306.14,386.01,218.27,8.64;8,306.14,397.97,52.30,8.64">In our Borda count, the first place receives 4 points, and each subsequent rank decreases by one point.</s><s coords="9,147.29,285.96,141.85,9.46;9,70.87,299.51,218.27,9.46;9,70.87,313.06,220.08,9.46;9,70.87,326.61,28.74,9.46">We open-source both the method and the environment to foster future research and advancements in simultaneous human-AI collaboration.</s><s coords="9,103.71,326.61,185.42,9.46;9,70.87,340.16,218.26,9.46;9,70.87,353.71,218.27,9.46;9,70.87,367.25,218.27,9.46;9,70.87,380.80,153.91,9.46">To the best of our knowledge, DPT-Agent is the first agent framework to achieve autonomous and simultaneous collaboration with humans in real time, making it a major step forward in language agents for human-AI collaboration.</s></p></div></figDesc><table coords="8,305.80,431.28,220.42,343.91"><row><cell>7 Discussion and Future Works</cell></row><row><cell>The experiment results illustrate the complex inter-</cell></row><row><cell>play between latency, capability, and collaboration</cell></row><row><cell>in real-time tasks. DPT-Agent shows the capability</cell></row><row><cell>to address this issue by effectively balancing la-</cell></row><row><cell>tency and capability, enabling high-latency models</cell></row><row><cell>to convert score efficiency and reasoning capability</cell></row><row><cell>into better outcomes. Moreover, the significant im-</cell></row><row><cell>provement observed when incorporating ToM into</cell></row><row><cell>DPT-Agent during human collaboration confirms</cell></row><row><cell>the value of human-like reasoning in enhancing</cell></row><row><cell>task performance. This insight emphasizes the im-</cell></row><row><cell>portance of integrating cognitive abilities, like ToM,</cell></row><row><cell>to optimize human-agent interactions in real-world</cell></row><row><cell>applications. Interestingly, the absence of ToM in</cell></row><row><cell>DPT-Agent outperformed the complete DPT-Agent</cell></row><row><cell>in some cases, suggesting the models' lack of ToM</cell></row><row><cell>capabilities, which might influence the effective-</cell></row><row><cell>ness of DPT-Agent. For future work, the integra-</cell></row><row><cell>tion approach of DPT-Agent with FSM holds great</cell></row><row><cell>potential for integrating LLMs into existing FSMs</cell></row><row><cell>in the real world, offering the possibility of sup-</cell></row><row><cell>porting more simultaneous human-AI collaboration</cell></row><row><cell>scenarios to achieve stronger capabilities and pro-</cell></row><row><cell>mote better cooperation.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,70.87,74.87,436.84,699.90"><head>Table 4 :</head><label>4</label><figDesc><div><p><s coords="12,393.30,144.80,78.86,8.96">Rewards in Game.</s></p></div></figDesc><table coords="12,322.85,74.87,184.86,55.45"><row><cell>Event</cell><cell>Rewards</cell></row><row><cell>Serve a LettuceBurger</cell><cell>+15</cell></row><row><cell>Serve a BeefBurger</cell><cell>+20</cell></row><row><cell>Serve a BeefLettuceBurger</cell><cell>+25</cell></row><row><cell>Serve a Wrong Burger (or Something not a Burger)</cell><cell>-10</cell></row><row><cell>Miss an order</cell><cell>-10</cell></row></table><note coords="12,83.52,734.36,2.99,5.18;12,87.01,735.33,165.88,8.97;12,70.87,745.30,109.33,8.97;12,83.52,755.17,2.99,5.18;12,87.01,756.15,195.56,8.97;12,70.87,767.00,46.56,7.77"><p><s coords="12,83.52,734.36,2.99,5.18;12,87.01,735.33,165.88,8.97;12,70.87,745.30,109.33,8.97;12,83.52,755.17,2.99,5.18;12,87.01,756.15,195.56,8.97">1 https://github.com/HumanCompatibleAI/ overcooked_ai, MIT License 2 https://github.com/rosewang2008/gym-cooking,</s><s coords="12,70.87,767.00,46.56,7.77">MIT License</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="19,70.87,95.15,220.18,330.63"><head/><label/><figDesc><div><p><s coords="19,70.87,95.15,220.08,9.46;19,70.87,108.70,219.63,9.46;19,70.87,122.25,218.27,9.46;19,70.87,135.80,151.56,9.46;19,70.87,155.81,103.07,9.81">Metrics we used in experiments include Atom Action Occupy, Failure Missed, Failure Wrong Serve, Score Efficiency, Agent Contribution Rate, the total game score, and latency in second.Atom Action Occupy.</s><s coords="19,184.85,156.23,104.28,9.46;19,70.87,169.78,220.18,9.46">The percentage of total time spent by in-game agents performing actions.</s><s coords="19,70.87,182.98,218.27,10.63;19,70.87,196.88,63.30,9.46">t atomic refers to the number of time steps that have atomic action.</s><s coords="19,138.50,196.53,150.64,10.77;19,70.87,210.43,46.67,9.46">t total refers to the total number of time steps.</s></p></div></figDesc><table coords="19,70.87,228.17,219.00,197.61"><row><cell cols="2">Atom Action Occupy =</cell><cell>t atomic t total</cell><cell>(1)</cell></row><row><cell cols="4">Failure Missed. The number of orders missed of</cell></row><row><cell>each games.</cell><cell/><cell/></row><row><cell cols="4">Failure Wrong Serve The number of incorrect</cell></row><row><cell>orders made by agents.</cell><cell/><cell/></row><row><cell cols="4">Score Efficiency. The average score gained per</cell></row><row><cell cols="4">macro action being executed. S total_gain refers to</cell></row><row><cell cols="4">score gained and is excluding penalty points. MA e</cell></row><row><cell cols="4">refers to the number of macro action (MA) being</cell></row><row><cell>executed.</cell><cell/><cell/></row><row><cell>Score Efficiency =</cell><cell cols="2">S total_gain MA e</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="19,305.75,738.63,220.47,36.56"><head/><label/><figDesc><div><p><s coords="19,441.75,738.63,84.47,9.46;19,305.87,752.18,121.51,9.46">in Table 6 and provided more detailed metrics.</s><s coords="19,430.73,752.18,93.68,9.46;19,305.75,765.73,218.66,9.46">Metrics include Atom Action Occupy, Failure Missed, Failure Wrong</s></p></div></figDesc><table/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="21,500.52,213.61,8.82,416.78"><head>Table 6 :</head><label>6</label><figDesc><div><p><s coords="21,500.70,544.28,8.64,50.90;21,500.70,533.49,8.64,8.30;21,500.70,494.74,8.64,36.26;21,500.70,462.36,8.64,29.89;21,500.70,452.12,8.64,7.75;21,500.70,428.59,8.64,21.03;21,500.70,417.80,8.64,8.30;21,500.70,361.09,8.64,54.23;21,500.52,330.93,8.59,27.67;21,500.52,323.46,8.59,4.98">Performance of Different Models in LLM as Indenpendent System 1</s></p></div></figDesc><table coords="21,500.52,213.61,8.82,107.36"><row><cell>Experiments.</cell></row><row><cell>and System 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="22,267.14,174.08,221.11,493.36"><head>Table 7 :</head><label>7</label><figDesc><div><p><s coords="22,267.14,436.78,8.64,50.90;22,267.14,425.99,8.64,8.30;22,267.14,387.24,8.64,36.26;22,267.14,354.86,8.64,29.89;22,267.14,349.05,8.64,3.32;22,267.14,321.11,8.64,25.45">Performance of Different Models -ReAct</s></p></div></figDesc><table coords="22,316.11,174.08,172.14,493.36"><row><cell>Score Latency</cell><cell>Second</cell><cell>-1.50(3.78) 7.49(0.27)</cell><cell>-40.00(2.17) 3.11(0.08)</cell><cell>-16.50(7.12) 8.86(0.23)</cell><cell>-25.56(2.91) 7.64(0.16)</cell><cell>-20.00(4.79) 7.78(0.17)</cell><cell>20.00(4.47) 5.20(0.06)</cell><cell>-40.00(0.00) 1.60(0.02)</cell><cell>-5.00(3.63) 3.11(0.05)</cell><cell>0.50(4.33) 5.58(0.23)</cell><cell>-4.00(4.45) 1.87(0.05)</cell><cell>-40.00(0.00) 2.93(0.05)</cell><cell>-25.00(2.76) 4.66(0.05)</cell></row><row><cell>Score Efficiency</cell><cell>Score/Marco Action</cell><cell>2.14(0.17)</cell><cell>0.00(0.14)</cell><cell>1.78(0.26)</cell><cell>1.24(0.18)</cell><cell>1.44(0.19)</cell><cell>3.25(0.19)</cell><cell>0.00(0.00)</cell><cell>1.43(0.03)</cell><cell>2.44(0.20)</cell><cell>2.44(0.24)</cell><cell>0.00(0.00)</cell><cell>1.47(0.09)</cell></row><row><cell>Metrics Atom Action Occupy Failure Missed Failure Wrong Serve</cell><cell>Model -Times Times</cell><cell>GPT-4o 0.80(0.02) 4.00(0.16) 0.00(0.09)</cell><cell>GPT-4o-mini 0.91(0.01) 4.00(0.07) 0.00(0.00)</cell><cell>o3-mini 0.78(0.02) 4.00(0.18) 0.30(0.11)</cell><cell>DeepSeek-V2.5 0.52(0.01) 4.22(0.13) 0.00(0.00)</cell><cell>DeepSeek-R1-70b 0.66(0.01) 4.00(0.14) 0.00(0.08)</cell><cell>Llama3.3-70b 0.65(0.02) 3.00(0.09) 0.00(0.00)</cell><cell>Mistral-nemo-12b 0.00(0.00) 0.00(0.00) 4.00(0.00)</cell><cell>Mistral-small-24b 0.90(0.01) 3.00(0.09) 0.00(0.10)</cell><cell>Mixtral-8x22b 0.84(0.02) 3.80(0.18) 0.00(0.00)</cell><cell>Qwen2.5-14b 0.91(0.02) 4.00(0.10) 0.00(0.10)</cell><cell>Qwen2.5-32b 0.00(0.00) 4.00(0.00) 0.00(0.00)</cell><cell>Qwen2.5-72b 0.69(0.05) 5.00(0.09) 0.00(0.00)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="22,503.74,314.54,8.64,214.93"><head>Table 8 :</head><label>8</label><figDesc><div><p><s coords="22,503.74,443.35,8.64,50.90;22,503.74,432.56,8.64,8.30;22,503.74,393.81,8.64,36.26;22,503.74,361.43,8.64,29.89;22,503.74,355.62,8.64,3.32;22,503.74,314.54,8.64,38.60">Performance of Different Models -Reflexion</s></p></div></figDesc><table coords="23,184.65,135.28,199.97,573.14"><row><cell>Score Latency</cell><cell>Second</cell><cell>20.50(5.41) 5.08(0.15)</cell><cell>21.00(4.47) 2.13(0.01)</cell><cell>37.50(4.81) 7.03(0.28)</cell><cell>31.50(3.40) 4.73(0.11)</cell><cell>60.00(4.35) 9.09(0.26)</cell><cell>-10.00(6.46) 2.28(0.10)</cell><cell>30.00(5.20) 1.31(0.03)</cell><cell>-1.50(3.63) 3.61(0.31)</cell><cell>0.00(15.00) 4.21(0.17)</cell><cell>1.50(4.11) 1.18(0.02)</cell><cell>1.00(3.83) 1.65(0.03)</cell><cell>11.00(4.88) 3.01(0.12)</cell></row><row><cell>Score Efficiency</cell><cell>Score/Marco Action</cell><cell>3.05(0.24)</cell><cell>3.50(0.23)</cell><cell>3.68(0.19)</cell><cell>3.40(0.14)</cell><cell>4.19(0.15)</cell><cell>1.82(0.34)</cell><cell>3.49(0.21)</cell><cell>2.05(0.17)</cell><cell>2.70(0.20)</cell><cell>2.68(0.22)</cell><cell>2.26(0.13)</cell><cell>2.66(0.21)</cell></row><row><cell>Metrics Atom Action Occupy Failure Missed Failure Wrong Serve</cell><cell>Model -Times Times</cell><cell>GPT-4o 0.91(0.00) 3.60(0.14) 0.00(0.05)</cell><cell>GPT-4o-mini 0.93(0.00) 3.60(0.11) 0.00(0.00)</cell><cell>o3-mini 0.90(0.00) 3.00(0.18) 0.00(0.00)</cell><cell>DeepSeek-V2.5 0.93(0.00) 3.00(0.11) 0.00(0.00)</cell><cell>DeepSeek-R1-70b 0.90(0.01) 2.30(0.17) 0.00(0.00)</cell><cell>Llama3.3-70b 0.94(0.00) 4.00(0.13) 0.00(0.05)</cell><cell>Mistral-nemo-12b 0.91(0.01) 3.30(0.13) 0.00(0.00)</cell><cell>Mistral-small-24b 0.91(0.00) 4.00(0.09) 0.00(0.00)</cell><cell>Mixtral-8x22b 0.95(0.01) 4.00(0.00) 0.00(0.00)</cell><cell>Qwen2.5-14b 0.94(0.00) 4.00(0.05) 0.00(0.00)</cell><cell>Qwen2.5-32b 0.93(0.00) 4.00(0.13) 0.00(0.00)</cell><cell>Qwen2.5-72b 0.94(0.01) 3.70(0.18) 0.00(0.00)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="23,400.71,310.18,8.64,223.66"><head>Table 9 :</head><label>9</label><figDesc><div><p><s coords="23,400.71,447.72,8.64,50.90;23,400.71,436.93,8.64,8.30;23,400.71,398.17,8.64,36.26;23,400.71,365.79,8.64,29.89;23,400.71,359.99,8.64,3.32;23,400.89,310.18,8.05,47.32">Performance of Different Models -DPT-Agent.</s></p></div></figDesc><table/></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="25,94.14,261.16,406.69,9.03"><head>Table 10 :</head><label>10</label><figDesc><div><p><s coords="25,134.34,261.16,366.49,8.96">Results with Standard Errors of Experiments -Collaborating with Rule-based Agents.</s></p></div></figDesc><table/></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p><s coords="20,70.87,285.94,218.26,9.46;20,70.87,299.49,78.30,9.46">Serve), Score Efficiency, the total game score, and latency in second.</s></p><p><s coords="20,70.87,321.44,218.52,10.75;20,92.12,335.39,71.06,10.75">G Details of Capability in Real-time Task Experiments .</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="20,70.87,356.36,140.91,9.81">G.1 Models and Deployment</head><p><s coords="20,70.87,374.26,220.08,9.46;20,70.87,387.81,218.26,9.46;20,70.51,401.36,219.99,9.46;20,70.87,414.91,201.16,9.46">In this series of experiments, we used 5 different model series including GPT (OpenAI), Qwen <ref type="bibr" coords="20,70.51,401.36,80.89,9.46" target="#b21">(Yang et al., 2024)</ref>, Llama <ref type="bibr" coords="20,190.38,401.36,95.32,9.46" target="#b37">(Touvron et al., 2023)</ref>, Mistral (AI) and DeepSeek <ref type="bibr" coords="20,192.04,414.91,75.29,9.46" target="#b13">(Guo et al., 2025)</ref>.</s></p><p><s coords="20,81.78,428.03,207.36,9.88;20,81.78,441.58,209.17,9.88;20,70.87,455.55,218.27,9.46;20,70.87,469.10,17.27,9.46">GPT Series: GPT-4o, GPT-4o-mini and o3-mini Qwen Series: Qwen2.5 with 3 different sizes including 14b, 32b and 72b (Lisence: Apache license 2.0)</s></p><p><s coords="20,81.78,482.23,128.82,9.88">Llama Series: Llama3.3-70b</s><s coords="20,213.33,482.65,71.85,9.46;20,81.78,495.78,166.48,9.88">(Lisence: llama) Mistral Series: Mistral-nemo-12b,  DeepSeek Series: DeepSeek-R1-Distill-Llama-70B and DeepSeek-V2.5 (Lisence: <ref type="bibr" coords="20,226.06,536.85,23.63,9.46">MIT)</ref> All the open-source models are locally deployed with NVIDIA A800-SXM4-80GB through vLLM <ref type="bibr" coords="20,70.51,577.50,81.68,9.46" target="#b18">(Kwon et al., 2023)</ref>, with the number of cards used determined by the model size.</s><s coords="20,255.09,496.20,35.85,9.46">For DeepSeek-R1-70b, we use 8 NVIDIA H100-80GB-HBM3 for deployment through vLLM <ref type="bibr" coords="20,198.43,618.14,87.82,9.46" target="#b18">(Kwon et al., 2023)</ref>.</s><s coords="20,70.87,509.75,29.09,9.46">The GPT series models use native API calls to conduct experiments.</s><s coords="20,99.96,509.75,33.02,9.46">The experiments use 140.3 A800-SXM4-80GB GPU hours and 17.5 H100-80GB-HBM3 GPU hours for open-source models and $ 100 in OpenAI API cost.</s><s coords="20,135.71,509.75,39.16,9.46">All models had their temperature parameter set to 0, while the remaining parameters were kept at their default values.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head coords="20,70.87,734.28,103.03,9.81">G.2 Detailed Results</head><p><s coords="20,70.35,752.18,218.78,9.46;20,70.87,765.73,163.80,9.46">We list the data from Figure <ref type="figure" coords="20,205.89,752.18,5.56,9.46">5</ref> in Tables <ref type="table" coords="20,261.17,752.18,27.96,9.46">7 to 9</ref> and provided more detailed metrics.</s><s coords="20,240.91,765.73,50.03,9.46;20,306.14,285.94,220.07,9.46;20,306.14,299.49,218.27,9.46;20,306.14,313.04,125.26,9.46">Metrics in-clude Atom Action Occupy, Failure Missed, Failure Wrong Serve), Score Efficiency, the total game score, and latency in second.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,306.14,183.67,218.27,8.64;9,317.05,194.63,207.36,8.64;9,317.05,205.59,207.36,8.64;9,317.05,216.55,207.61,8.64;9,317.05,227.51,109.05,8.64" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Jyoti</forename><surname>Marah Abdin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harkirat</forename><surname>Aneja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sébastien</forename><surname>Behl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronen</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suriya</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Russell</forename><forename type="middle">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mojan</forename><surname>Hewett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piero</forename><surname>Javaheripi</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kauffmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.08905</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Marah Abdin, Jyoti Aneja, Harkirat Behl, Sébastien Bubeck, Ronen Eldan, Suriya Gunasekar, Michael Harrison, Russell J Hewett, Mojan Javaheripi, Piero Kauffmann, et al. 2024. Phi-4 technical report. arXiv preprint arXiv:2412.08905.</note>
</biblStruct>

<biblStruct coords="9,306.14,247.42,125.90,8.64;9,306.14,267.33,72.86,8.64;9,394.64,267.33,131.42,8.64;9,317.05,277.30,208.35,9.96;9,317.05,288.26,209.01,9.96;9,317.05,300.21,25.73,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coords="9,354.00,247.42,73.57,8.64">Mistral ai -models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">I</forename><surname>Mistral</surname></persName>
		</author>
		<ptr target="https://www.anthropic.com/news/3-5-models-and-computer-use"/>
	</analytic>
	<monogr>
		<title level="m" coords="9,306.14,267.33,72.86,8.64;9,394.64,267.33,131.42,8.64;9,317.05,278.29,38.03,8.64">Anthropic. 2024. Claude 3.5 models and computer use</title>
		<imprint>
			<date type="published" when="2025-02-08">2025-02-08</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Mistral AI. Mistral ai -models. Anthropic. 2024. Claude 3.5 models and com- puter use. https://www.anthropic.com/news/ 3-5-models-and-computer-use. Accessed: 2025- 02-08.</note>
</biblStruct>

<biblStruct coords="9,306.14,320.12,218.27,8.64;9,317.05,331.08,207.71,8.64;9,317.05,342.04,209.01,8.64;9,317.05,352.99,209.01,8.64;9,317.05,363.95,207.36,8.64;9,317.05,374.91,208.61,8.64;9,317.05,385.87,207.36,8.64;9,317.05,396.83,45.00,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coords="9,391.91,342.04,134.15,8.64;9,317.05,352.99,209.01,8.64;9,317.05,363.95,23.47,8.64">Effects of communication directionality and ai agent differences in human-ai interaction</title>
		<author>
			<persName coords=""><forename type="first">Zahra</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Casey</forename><surname>Dugan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qian</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sadhana</forename><surname>Kumaravel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="DOI">10.1145/3411764.3445256</idno>
	</analytic>
	<monogr>
		<title level="m" coords="9,359.34,363.95,165.07,8.64;9,317.05,374.91,204.59,8.64">Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, CHI '21</title>
		<meeting>the 2021 CHI Conference on Human Factors in Computing Systems, CHI '21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Zahra Ashktorab, Casey Dugan, James Johnson, Qian Pan, Wei Zhang, Sadhana Kumaravel, and Murray Campbell. 2021. Effects of communication direc- tionality and ai agent differences in human-ai inter- action. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, CHI '21, New York, NY, USA. Association for Computing Machinery.</note>
</biblStruct>

<biblStruct coords="9,306.14,416.74,220.01,8.64;9,316.30,427.70,208.10,8.64;9,317.05,438.66,130.10,8.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coords="9,348.70,427.70,175.71,8.64;9,317.05,438.66,19.55,8.64">Does the autistic child have a "theory of mind</title>
		<author>
			<persName coords=""><forename type="first">Simon</forename><surname>Baron-Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">M</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Uta</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="9,350.57,438.66,38.12,8.64">Cognition</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46"/>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Simon Baron-Cohen, Alan M Leslie, and Uta Frith. 1985. Does the autistic child have a "theory of mind"? Cognition, 21(1):37-46.</note>
</biblStruct>

<biblStruct coords="9,306.14,458.57,218.26,8.64;9,317.05,469.53,209.01,8.64;9,317.05,480.49,209.10,8.64;9,317.05,491.45,208.62,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coords="9,432.44,469.53,93.62,8.64;9,317.05,480.49,204.95,8.64">The complexity of decentralized control of markov decision processes</title>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Daniel S Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Neil</forename><surname>Givan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shlomo</forename><surname>Immerman</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zilberstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="9,317.05,491.45,140.45,8.64">Mathematics of operations research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="819" to="840"/>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Daniel S Bernstein, Robert Givan, Neil Immerman, and Shlomo Zilberstein. 2002. The complexity of de- centralized control of markov decision processes. Mathematics of operations research, 27(4):819-840.</note>
</biblStruct>

<biblStruct coords="9,306.14,511.36,219.51,8.64;9,317.05,522.32,209.10,8.64;9,317.05,533.28,209.01,8.64;9,317.05,544.24,207.36,8.64;9,317.05,555.20,94.09,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coords="9,317.05,533.28,209.01,8.64;9,317.05,544.24,61.51,8.64">On the utility of learning about humans for humanai coordination</title>
		<author>
			<persName coords=""><forename type="first">Micah</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rohin</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanjit</forename><surname>Seshia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anca</forename><surname>Dragan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="9,392.45,544.24,131.96,8.64;9,317.05,555.20,74.89,8.64">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Micah Carroll, Rohin Shah, Mark K Ho, Tom Griffiths, Sanjit Seshia, Pieter Abbeel, and Anca Dragan. 2019. On the utility of learning about humans for human- ai coordination. Advances in neural information processing systems, 32.</note>
</biblStruct>

<biblStruct coords="9,306.14,575.11,219.92,8.64;9,317.05,586.07,87.16,8.64" xml:id="b6">
	<monogr>
		<title level="m" type="main" coords="9,427.53,575.11,98.54,8.64;9,317.05,586.07,83.46,8.64">Ollama: Run large language models locally</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Ollama Contributors</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Ollama Contributors. 2023. Ollama: Run large lan- guage models locally.</note>
</biblStruct>

<biblStruct coords="9,306.14,605.98,218.27,8.64;9,317.05,616.94,209.01,8.64;9,317.05,627.90,207.36,8.64;9,317.05,638.85,30.71,8.64" xml:id="b7">
	<monogr>
		<title level="m" type="main" coords="9,511.19,616.94,14.87,8.64;9,317.05,627.90,207.36,8.64;9,317.05,638.85,26.33,8.64">Cooperative ai: machines must learn to find common ground</title>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Dafoe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoram</forename><surname>Bachrach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gillian</forename><surname>Hadfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kate</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Allan Dafoe, Yoram Bachrach, Gillian Hadfield, Eric Horvitz, Kate Larson, and Thore Graepel. 2021. Co- operative ai: machines must learn to find common ground.</note>
</biblStruct>

<biblStruct coords="9,306.14,658.77,219.92,8.64;9,317.05,669.72,207.36,8.64;9,317.05,680.68,207.36,8.64;9,317.05,691.64,208.60,8.64;9,317.05,702.60,207.52,8.64;9,317.05,713.56,92.33,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coords="9,496.62,658.77,29.45,8.64;9,317.05,669.72,184.91,8.64">Awareness and coordination in shared workspaces</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Dourish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victoria</forename><surname>Bellotti</surname></persName>
		</author>
		<idno type="DOI">10.1145/143457.143468</idno>
	</analytic>
	<monogr>
		<title level="m" coords="9,317.05,680.68,207.36,8.64;9,317.05,691.64,204.74,8.64">Proceedings of the 1992 ACM Conference on Computer-Supported Cooperative Work, CSCW '92</title>
		<meeting>the 1992 ACM Conference on Computer-Supported Cooperative Work, CSCW '92<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="107" to="114"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Paul Dourish and Victoria Bellotti. 1992. Aware- ness and coordination in shared workspaces. In Proceedings of the 1992 ACM Conference on Computer-Supported Cooperative Work, CSCW '92, page 107-114, New York, NY, USA. Association for Computing Machinery.</note>
</biblStruct>

<biblStruct coords="9,306.14,733.47,220.01,8.64;9,317.05,744.43,209.01,8.64;9,316.80,755.39,207.61,8.64;9,317.05,766.35,91.03,8.64" xml:id="b9">
	<analytic>
		<title level="a" type="main" coords="9,317.05,744.43,209.01,8.64;9,316.80,755.39,75.88,8.64">Dual-process theories of higher cognition: Advancing the debate</title>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keith</forename><forename type="middle">E</forename><surname>Stanovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="9,403.07,755.39,121.34,8.64;9,317.05,766.35,27.83,8.64">Perspectives on psychological science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="223" to="241"/>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jonathan St BT Evans and Keith E Stanovich. 2013. Dual-process theories of higher cognition: Ad- vancing the debate. Perspectives on psychological science, 8(3):223-241.</note>
</biblStruct>

<biblStruct coords="10,70.87,75.34,218.27,8.64;10,81.78,86.30,62.98,8.64" xml:id="b10">
	<monogr>
		<title level="m" type="main" coords="10,167.49,75.34,121.64,8.64;10,81.78,86.30,58.76,8.64">llama.cpp: Port of meta's llama model in c/c++</title>
		<author>
			<persName coords=""><forename type="first">Georgi</forename><surname>Gerganov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Georgi Gerganov. 2023. llama.cpp: Port of meta's llama model in c/c++.</note>
</biblStruct>

<biblStruct coords="10,70.87,107.18,219.51,8.64;10,81.78,118.14,208.60,8.64;10,81.78,129.10,209.01,8.64;10,81.78,140.06,207.36,8.64;10,81.78,151.02,208.74,8.64;10,81.78,161.97,133.46,8.64" xml:id="b11">
	<analytic>
		<title level="a" type="main" coords="10,261.37,129.10,29.42,8.64;10,81.78,140.06,147.05,8.64">Mindagent: Emergent gaming interaction</title>
		<author>
			<persName coords=""><forename type="first">Ran</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qiuyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaojian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yusuke</forename><surname>Noda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zane</forename><surname>Durante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zilong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Demetri</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hoi</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,254.26,140.06,34.88,8.64;10,81.78,151.02,208.74,8.64;10,81.78,161.97,53.99,8.64">Findings of the Association for Computational Linguistics: NAACL 2024</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="3154" to="3183"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Ran Gong, Qiuyuan Huang, Xiaojian Ma, Yusuke Noda, Zane Durante, Zilong Zheng, Demetri Terzopoulos, Li Fei-Fei, Jianfeng Gao, and Hoi Vo. 2024. Minda- gent: Emergent gaming interaction. In Findings of the Association for Computational Linguistics: NAACL 2024, pages 3154-3183.</note>
</biblStruct>

<biblStruct coords="10,70.87,182.86,219.51,8.64;10,81.78,193.82,207.36,8.64;10,81.20,204.77,207.93,8.64;10,81.53,215.73,207.86,8.64;10,81.78,226.69,109.05,8.64" xml:id="b12">
	<monogr>
		<title level="m" type="main" coords="10,156.28,204.77,132.85,8.64;10,81.53,215.73,175.10,8.64">Efficient human-ai coordination via preparatory language-based convention</title>
		<author>
			<persName coords=""><forename type="first">Cong</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chunpeng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yichen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Feng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lihe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yunjia</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.00416</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Cong Guan, Lichao Zhang, Chunpeng Fan, Yichen Li, Feng Chen, Lihe Li, Yunjia Tian, Lei Yuan, and Yang Yu. 2023. Efficient human-ai coordination via preparatory language-based convention. arXiv preprint arXiv:2311.00416.</note>
</biblStruct>

<biblStruct coords="10,70.87,247.57,219.51,8.64;10,81.78,258.53,208.60,8.64;10,81.78,269.49,209.01,8.64;10,81.78,280.45,209.01,8.64;10,81.78,291.41,195.12,8.64" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Dejian</forename><surname>Daya Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haowei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Runxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qihao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shirong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peiyi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2501.12948</idno>
		<title level="m" coords="10,221.25,269.49,69.54,8.64;10,81.78,280.45,209.01,8.64;10,81.78,291.41,53.65,8.64">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: In- centivizing reasoning capability in llms via reinforce- ment learning. arXiv preprint arXiv:2501.12948.</note>
</biblStruct>

<biblStruct coords="10,70.87,312.29,220.01,8.64;10,81.03,323.25,209.76,8.64;10,81.78,334.21,207.36,8.64;10,81.78,345.17,195.36,8.64" xml:id="b14">
	<analytic>
		<title level="a" type="main" coords="10,111.08,323.25,179.71,8.64;10,81.78,334.21,112.54,8.64">A formal basis for the heuristic determination of minimum cost paths</title>
		<author>
			<persName coords=""><forename type="first">Nils</forename><forename type="middle">J</forename><surname>Peter E Hart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bertram</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Raphael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="10,203.82,334.21,85.31,8.64;10,81.78,345.17,131.97,8.64">IEEE transactions on Systems Science and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="107"/>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Peter E Hart, Nils J Nilsson, and Bertram Raphael. 1968. A formal basis for the heuristic determina- tion of minimum cost paths. IEEE transactions on Systems Science and Cybernetics, 4(2):100-107.</note>
</biblStruct>

<biblStruct coords="10,70.87,366.05,218.27,8.64;10,81.78,377.01,207.36,8.64;10,81.78,387.97,209.01,8.64;10,81.78,398.93,207.36,8.64;10,81.78,409.89,207.36,8.64;10,81.78,420.84,208.60,8.64;10,81.78,431.80,207.36,8.64;10,81.78,442.76,46.77,8.64" xml:id="b15">
	<analytic>
		<title level="a" type="main" coords="10,236.08,377.01,53.06,8.64;10,81.78,387.97,209.01,8.64;10,81.78,398.93,16.49,8.64">Planning like human: A dual-process framework for dialogue planning</title>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuanxing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zerui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.acl-long.262</idno>
	</analytic>
	<monogr>
		<title level="m" coords="10,120.64,398.93,168.50,8.64;10,81.78,409.89,207.36,8.64;10,126.91,420.84,72.62,8.64">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4768" to="4791"/>
		</imprint>
	</monogr>
	<note>: Long Papers)</note>
	<note type="raw_reference">Tao He, Lizi Liao, Yixin Cao, Yuanxing Liu, Ming Liu, Zerui Chen, and Bing Qin. 2024. Planning like human: A dual-process framework for dialogue plan- ning. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4768-4791, Bangkok, Thailand. Association for Computational Linguistics.</note>
</biblStruct>

<biblStruct coords="10,70.87,463.64,220.01,8.64;10,81.78,474.60,103.76,8.64" xml:id="b16">
	<monogr>
		<title level="m" type="main" coords="10,186.76,463.64,99.95,8.64">Thinking, fast and slow</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Farrar, Straus and Giroux</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Daniel Kahneman. 2011. Thinking, fast and slow. Farrar, Straus and Giroux.</note>
</biblStruct>

<biblStruct coords="10,70.87,495.48,218.27,8.64;10,81.59,506.44,209.20,8.64;10,81.78,517.40,207.36,8.64;10,81.78,528.36,207.36,8.64;10,81.78,539.32,204.76,8.64" xml:id="b17">
	<analytic>
		<title level="a" type="main" coords="10,189.24,517.40,99.90,8.64;10,81.78,528.36,207.36,8.64;10,81.78,539.32,59.87,8.64">i think i know what you mean": The role of theory of mind in collaborative communication</title>
		<author>
			<persName coords=""><forename type="first">Meredyth</forename><surname>Krych-Appelbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julie</forename><forename type="middle">Banzon</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dayna</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allyson</forename><surname>Barnacz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amanda</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julian</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keenan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="10,149.84,539.32,73.50,8.64">Interaction Studies</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="280"/>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Meredyth Krych-Appelbaum, Julie Banzon Law, Dayna Jones, Allyson Barnacz, Amanda Johnson, and Ju- lian Paul Keenan. 2007. "i think i know what you mean": The role of theory of mind in collaborative communication. Interaction Studies, 8(2):267-280.</note>
</biblStruct>

<biblStruct coords="10,70.87,560.20,218.27,8.64;10,81.78,571.16,209.01,8.64;10,81.78,582.12,207.36,8.64;10,81.78,593.08,209.01,8.64;10,81.78,604.04,207.36,8.64;10,81.78,615.00,207.36,8.64;10,81.78,625.96,42.34,8.64" xml:id="b18">
	<analytic>
		<title level="a" type="main" coords="10,254.39,582.12,34.74,8.64;10,81.78,593.08,209.01,8.64;10,81.78,604.04,90.56,8.64">Efficient memory management for large language model serving with pagedattention</title>
		<author>
			<persName coords=""><forename type="first">Woosuk</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cody</forename><forename type="middle">Hao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ion</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,190.47,604.04,98.66,8.64;10,81.78,615.00,207.36,8.64;10,81.78,625.96,38.49,8.64">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</title>
		<meeting>the ACM SIGOPS 29th Symposium on Operating Systems Principles</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gon- zalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serv- ing with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles.</note>
</biblStruct>

<biblStruct coords="10,70.87,646.84,219.52,8.64;10,81.42,657.80,207.72,8.64;10,81.78,668.75,209.01,8.64;10,81.78,679.71,207.36,8.64;10,81.78,690.67,209.10,8.64" xml:id="b19">
	<analytic>
		<title level="a" type="main" coords="10,239.86,657.80,49.27,8.64;10,81.78,668.75,209.01,8.64;10,81.78,679.71,40.29,8.64">Cooperative open-ended learning framework for zero-shot coordination</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jichen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yali</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinbing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,144.94,679.71,21.96,8.64;10,240.44,679.71,48.70,8.64;10,81.78,690.67,121.25,8.64">Proceedings of Machine Learning Research</title>
		<meeting>Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="20470" to="20484"/>
		</imprint>
	</monogr>
	<note>ICML</note>
	<note type="raw_reference">Yang Li, Shao Zhang, Jichen Sun, Yali Du, Ying Wen, Xinbing Wang, and Wei Pan. 2023. Cooperative open-ended learning framework for zero-shot co- ordination. In ICML, volume 202 of Proceedings of Machine Learning Research, pages 20470-20484.</note>
</biblStruct>

<biblStruct coords="10,81.78,701.63,29.62,8.64" xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="raw_reference">PMLR.</note>
</biblStruct>

<biblStruct coords="10,70.87,722.51,219.52,8.64;10,81.20,733.47,209.68,8.64;10,81.78,744.43,209.01,8.64;10,81.78,755.39,207.36,8.64;10,81.78,766.35,151.07,8.64" xml:id="b21">
	<analytic>
		<title level="a" type="main" coords="10,107.71,744.43,183.08,8.64;10,81.78,755.39,113.11,8.64">Tackling cooperative incompatibility for zeroshot human-ai coordination</title>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jichen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yali</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinbing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="10,207.50,755.39,81.63,8.64;10,81.78,766.35,84.19,8.64">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="1139" to="1185"/>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Yang Li, Shao Zhang, Jichen Sun, Wenhao Zhang, Yali Du, Ying Wen, Xinbing Wang, and Wei Pan. 2024. Tackling cooperative incompatibility for zero- shot human-ai coordination. Journal of Artificial Intelligence Research, 80:1139-1185.</note>
</biblStruct>

<biblStruct coords="10,306.14,75.34,218.26,8.64;10,317.05,86.30,207.71,8.64;10,317.05,97.26,209.01,8.64;10,317.05,108.22,207.36,8.64;10,317.05,119.18,207.72,8.64;10,317.05,130.13,207.35,8.64;10,317.05,141.09,73.88,8.64" xml:id="b22">
	<analytic>
		<title level="a" type="main" coords="10,368.67,97.26,157.39,8.64;10,317.05,108.22,112.48,8.64">Code as policies: Language model programs for embodied control</title>
		<author>
			<persName coords=""><forename type="first">Jacky</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenlong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karol</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pete</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICRA48891.2023.10160591</idno>
	</analytic>
	<monogr>
		<title level="m" coords="10,449.15,108.22,75.26,8.64;10,317.05,119.18,207.72,8.64;10,317.05,130.13,17.93,8.64">IEEE International Conference on Robotics and Automation, ICRA 2023</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023-05-29">2023. May 29 -June 2, 2023</date>
			<biblScope unit="page" from="9493" to="9500"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. 2023. Code as policies: Language model pro- grams for embodied control. In IEEE International Conference on Robotics and Automation, ICRA 2023, London, UK, May 29 -June 2, 2023, pages 9493-9500. IEEE.</note>
</biblStruct>

<biblStruct coords="10,306.14,160.88,219.52,8.64;10,317.05,171.84,207.35,8.64;10,317.05,182.80,209.10,8.64;10,317.05,193.76,129.84,8.64;10,463.78,193.76,60.63,8.64;10,317.05,204.71,75.02,8.64" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Aixin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bing</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bochao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengda</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenggang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengqi</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chong</forename><surname>Ruan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.19437</idno>
		<title level="m" coords="10,317.05,193.76,126.01,8.64">Deepseek-v3 technical report</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. 2024a. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437.</note>
</biblStruct>

<biblStruct coords="10,306.14,224.50,218.27,8.64;10,317.05,235.46,209.02,8.64;10,317.05,246.42,209.01,8.64;10,317.05,257.38,207.36,8.64;10,317.05,268.34,207.36,8.64;10,317.05,279.30,209.01,8.64;10,317.05,290.25,207.36,8.64;10,316.69,301.21,129.51,8.64" xml:id="b24">
	<analytic>
		<title level="a" type="main" coords="10,459.18,235.46,66.89,8.64;10,317.05,246.42,209.01,8.64;10,317.05,257.38,40.29,8.64">Llm-powered hierarchical language agent for real-time human-ai coordination</title>
		<author>
			<persName coords=""><forename type="first">Jijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaxuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qingmin</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,376.01,257.38,148.40,8.64;10,317.05,268.34,207.36,8.64;10,317.05,279.30,96.54,8.64">Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems, AAMAS '24</title>
		<meeting>the 23rd International Conference on Autonomous Agents and Multiagent Systems, AAMAS '24</meeting>
		<imprint>
			<publisher>Richland, SC. International Foundation for Autonomous Agents and Multiagent Systems</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1219" to="1228"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Jijia Liu, Chao Yu, Jiaxuan Gao, Yuqing Xie, Qingmin Liao, Yi Wu, and Yu Wang. 2024b. Llm-powered hi- erarchical language agent for real-time human-ai co- ordination. In Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems, AAMAS '24, page 1219-1228, Rich- land, SC. International Foundation for Autonomous Agents and Multiagent Systems.</note>
</biblStruct>

<biblStruct coords="10,306.14,321.00,69.43,8.64" xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Openai</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="raw_reference">OpenAI. Openai.</note>
</biblStruct>

<biblStruct coords="10,306.14,340.78,218.27,8.64;10,317.05,351.74,208.60,8.64;10,317.05,362.70,209.10,8.64;10,316.74,373.66,209.32,8.64;10,317.05,384.62,207.36,8.64;10,317.05,395.58,207.36,8.64;10,317.05,406.54,188.52,8.64" xml:id="b26">
	<analytic>
		<title level="a" type="main" coords="10,316.74,373.66,209.32,8.64;10,317.05,384.62,116.12,8.64">The widening gap: The benefits and harms of generative ai for novice programmers</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Prather</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brent</forename><forename type="middle">N</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Juho</forename><surname>Leinonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Macneil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Arisoa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brett</forename><forename type="middle">A</forename><surname>Randrianasolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bailey</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jared</forename><surname>Kimmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Briggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,451.44,384.62,72.97,8.64;10,317.05,395.58,207.36,8.64;10,317.05,406.54,80.57,8.64">Proceedings of the 2024 ACM Conference on International Computing Education Research</title>
		<meeting>the 2024 ACM Conference on International Computing Education Research</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="469" to="486"/>
		</imprint>
	</monogr>
	<note type="raw_reference">James Prather, Brent N Reeves, Juho Leinonen, Stephen MacNeil, Arisoa S Randrianasolo, Brett A Becker, Bailey Kimmel, Jared Wright, and Ben Briggs. 2024. The widening gap: The benefits and harms of genera- tive ai for novice programmers. In Proceedings of the 2024 ACM Conference on International Computing Education Research-Volume 1, pages 469-486.</note>
</biblStruct>

<biblStruct coords="10,306.14,426.32,218.27,8.64;10,317.05,437.28,207.36,8.64;10,317.05,448.24,117.87,8.64" xml:id="b27">
	<analytic>
		<title level="a" type="main" coords="10,487.57,426.32,36.84,8.64;10,317.05,437.28,142.76,8.64">Does the chimpanzee have a theory of mind?</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Premack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guy</forename><surname>Woodruff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="10,464.01,437.28,60.40,8.64;10,317.05,448.24,54.68,8.64">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="515" to="526"/>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
	<note type="raw_reference">David Premack and Guy Woodruff. 1978. Does the chimpanzee have a theory of mind? Behavioral and brain sciences, 1(4):515-526.</note>
</biblStruct>

<biblStruct coords="10,306.14,468.03,218.26,8.64;10,317.05,478.99,209.10,8.64;10,317.05,489.95,207.36,8.64;10,317.05,500.90,207.36,8.64;10,317.05,511.86,207.36,8.64;10,317.05,522.82,152.45,8.64" xml:id="b28">
	<analytic>
		<title level="a" type="main" coords="10,348.66,489.95,101.05,8.64">Machine theory of mind</title>
		<author>
			<persName coords=""><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Perbet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francis</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="10,475.71,489.95,48.70,8.64;10,317.05,500.90,207.36,8.64;10,317.05,511.86,34.23,8.64">Proceedings of the 35th International Conference on Machine Learning</title>
		<title level="s" coords="10,423.37,511.86,101.04,8.64;10,317.05,522.82,73.12,8.64">Proceedings of Machine Learning Research</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="4218" to="4227"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Neil Rabinowitz, Frank Perbet, Francis Song, Chiyuan Zhang, S. M. Ali Eslami, and Matthew Botvinick. 2018. Machine theory of mind. In Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 4218-4227.</note>
</biblStruct>

<biblStruct coords="10,471.99,522.82,29.62,8.64" xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="raw_reference">PMLR.</note>
</biblStruct>

<biblStruct coords="10,306.14,542.61,219.51,8.64;10,317.05,553.57,209.01,8.64;10,317.05,564.53,207.36,8.64;10,317.05,575.48,207.36,8.64;10,317.05,586.44,75.02,8.64" xml:id="b30">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zahra</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Djallel</forename><surname>Bouneffouf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Payel</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.19726</idno>
		<title level="m" coords="10,410.42,564.53,114.00,8.64;10,317.05,575.48,137.95,8.64">Can large language models adapt to other agents in-context?</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Matthew Riemer, Zahra Ashktorab, Djallel Bouneffouf, Payel Das, Miao Liu, Justin D Weisz, and Mur- ray Campbell. 2024. Can large language models adapt to other agents in-context? arXiv preprint arXiv:2412.19726.</note>
</biblStruct>

<biblStruct coords="10,306.14,606.23,218.27,8.64;10,317.05,617.19,168.81,8.64" xml:id="b31">
	<monogr>
		<title level="m" type="main" coords="10,488.44,606.23,35.97,8.64;10,317.05,617.19,126.85,8.64">Artificial intelligence: a modern approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Pearson</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Stuart J Russell and Peter Norvig. 2016. Artificial intelligence: a modern approach. Pearson.</note>
</biblStruct>

<biblStruct coords="10,306.14,636.97,219.52,8.64;10,317.05,647.93,207.61,8.64;10,316.86,658.89,207.54,8.64;10,317.05,669.85,207.36,8.64;10,317.05,680.81,207.36,8.64;10,317.05,691.77,207.36,8.64;10,317.05,702.73,207.35,8.64;10,317.05,713.69,106.44,8.64" xml:id="b32">
	<analytic>
		<title level="a" type="main" coords="10,456.22,658.89,68.19,8.64;10,317.05,669.85,207.36,8.64;10,317.05,680.81,110.13,8.64">An evaluation of situational autonomy for human-ai collaboration in a shared workspace setting</title>
		<author>
			<persName coords=""><forename type="first">Vildan</forename><surname>Salikutluk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janik</forename><surname>Schöpper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Franziska</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Katrin</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Frodl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Balfanz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Jäkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dorothea</forename><surname>Koert</surname></persName>
		</author>
		<idno type="DOI">10.1145/3613904.3642564</idno>
	</analytic>
	<monogr>
		<title level="m" coords="10,448.70,680.81,75.71,8.64;10,317.05,691.77,207.36,8.64;10,317.05,702.73,68.78,8.64">Proceedings of the CHI Conference on Human Factors in Computing Systems, CHI '24</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems, CHI '24<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Vildan Salikutluk, Janik Schöpper, Franziska Herbert, Katrin Scheuermann, Eric Frodl, Dirk Balfanz, Frank Jäkel, and Dorothea Koert. 2024. An evaluation of situational autonomy for human-ai collaboration in a shared workspace setting. In Proceedings of the CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA. Association for Computing Machinery.</note>
</biblStruct>

<biblStruct coords="10,306.14,733.47,219.52,8.64;10,317.05,744.43,209.01,8.64;10,316.69,755.39,209.37,8.64;10,317.05,766.35,180.45,8.64" xml:id="b33">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yijia</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vinay</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yucheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.15701</idno>
		<title level="m" coords="10,407.57,744.43,118.49,8.64;10,316.69,755.39,209.37,8.64;10,317.05,766.35,38.99,8.64">Collaborative gym: A framework for enabling and evaluating human-agent collaboration</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Yijia Shao, Vinay Samuel, Yucheng Jiang, John Yang, and Diyi Yang. 2024. Collaborative gym: A frame- work for enabling and evaluating human-agent col- laboration. arXiv preprint arXiv:2412.15701.</note>
</biblStruct>

<biblStruct coords="11,70.87,75.34,219.52,8.64;11,81.78,86.30,209.01,8.64;11,81.78,97.26,209.01,8.64;11,81.78,108.22,207.36,8.64;11,81.78,119.18,96.31,8.64" xml:id="b34">
	<analytic>
		<title level="a" type="main" coords="11,276.11,86.30,14.67,8.64;11,81.78,97.26,209.01,8.64;11,81.78,108.22,56.92,8.64">Reflexion: Language agents with verbal reinforcement learning</title>
		<author>
			<persName coords=""><forename type="first">Noah</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Federico</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ashwin</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,153.44,108.22,135.69,8.64;11,81.78,119.18,76.90,8.64">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2024. Re- flexion: Language agents with verbal reinforce- ment learning. Advances in Neural Information Processing Systems, 36.</note>
</biblStruct>

<biblStruct coords="11,70.87,141.16,218.27,8.64;11,81.78,152.12,209.01,8.64;11,81.78,163.08,207.36,8.64;11,81.78,174.04,208.85,8.64;11,81.03,185.00,27.40,8.64" xml:id="b35">
	<analytic>
		<title level="a" type="main" coords="11,244.50,152.12,46.29,8.64;11,81.78,163.08,150.06,8.64">Collaborating with humans without human data</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Dj Strouse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matt</forename><surname>Mckee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Everett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,239.73,163.08,49.40,8.64;11,81.78,174.04,157.89,8.64">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="14502" to="14515"/>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">DJ Strouse, Kevin McKee, Matt Botvinick, Edward Hughes, and Richard Everett. 2021. Collaborat- ing with humans without human data. Advances in Neural Information Processing Systems, 34:14502- 14515.</note>
</biblStruct>

<biblStruct coords="11,70.87,206.98,219.52,8.64;11,81.78,217.94,209.01,8.64;11,81.78,228.90,207.61,8.64;11,81.78,239.86,208.74,8.64;11,81.78,250.82,209.10,8.64;11,81.78,261.77,133.98,8.64" xml:id="b36">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Gemma</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Morgane</forename><surname>Riviere</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shreya</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pier</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giuseppe</forename><surname>Sessa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cassidy</forename><surname>Hardin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Surya</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Léonard</forename><surname>Hussenot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Mesnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bobak</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexandre</forename><surname>Ramé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.00118</idno>
		<title level="m" coords="11,247.76,239.86,42.76,8.64;11,81.78,250.82,205.47,8.64">Gemma 2: Improving open language models at a practical size</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupati- raju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024. Gemma 2: Improving open language models at a practical size. arXiv preprint arXiv:2408.00118.</note>
</biblStruct>

<biblStruct coords="11,70.87,283.76,218.44,8.64;11,81.78,294.72,208.60,8.64;11,81.78,305.68,208.60,8.64;11,81.78,316.64,209.01,8.64;11,81.78,327.59,207.36,8.64;11,81.78,338.55,75.02,8.64" xml:id="b37">
	<monogr>
		<title level="m" type="main" coords="11,195.65,316.64,95.14,8.64;11,81.78,327.59,138.39,8.64">Llama: Open and efficient foundation language models</title>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and effi- cient foundation language models. arXiv preprint arXiv:2302.13971.</note>
</biblStruct>

<biblStruct coords="11,70.87,360.54,219.52,8.64;11,81.78,371.50,209.01,8.64;11,81.78,382.45,209.01,8.64;11,81.78,393.41,209.01,8.64;11,81.78,404.37,207.53,8.64;11,81.78,415.33,118.16,8.64" xml:id="b38">
	<analytic>
		<title level="a" type="main" coords="11,229.04,371.50,61.74,8.64;11,81.78,382.45,209.01,8.64;11,81.78,393.41,209.01,8.64;11,81.78,404.37,10.37,8.64">it felt like having a second mind": Investigating human-ai cocreativity in prewriting with large language models</title>
		<author>
			<persName coords=""><forename type="first">Qian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siying</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Piaohong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhicong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,100.65,404.37,188.66,8.64;11,81.78,415.33,41.84,8.64">Proceedings of the ACM on Human-Computer Interaction</title>
		<meeting>the ACM on Human-Computer Interaction</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="26"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Qian Wan, Siying Hu, Yu Zhang, Piaohong Wang, Bo Wen, and Zhicong Lu. 2024. " it felt like hav- ing a second mind": Investigating human-ai co- creativity in prewriting with large language mod- els. Proceedings of the ACM on Human-Computer Interaction, 8(CSCW1):1-26.</note>
</biblStruct>

<biblStruct coords="11,70.87,437.32,219.92,8.64;11,81.78,448.27,207.36,8.64;11,81.78,459.23,207.36,8.64;11,81.78,470.19,209.01,8.64;11,81.78,481.15,35.85,8.64;11,134.54,481.15,154.60,8.64;11,81.78,492.11,207.36,8.64;11,81.78,503.07,94.54,8.64" xml:id="b39">
	<analytic>
		<title level="a" type="main" coords="11,151.37,459.23,137.76,8.64;11,81.78,470.19,209.01,8.64;11,81.78,481.15,31.87,8.64">Zsc-eval: An evaluation toolkit and benchmark for multi-agent zero-shot coordination</title>
		<author>
			<persName coords=""><forename type="first">Xihuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wentao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingxiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,149.65,481.15,139.48,8.64;11,81.78,492.11,207.36,8.64;11,81.78,503.07,90.32,8.64">The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Xihuai Wang, Shao Zhang, Wenhao Zhang, Wen- tao Dong, Jingxiao Chen, Ying Wen, and Weinan Zhang. 2024. Zsc-eval: An evaluation toolkit and benchmark for multi-agent zero-shot coor- dination. In The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track.</note>
</biblStruct>

<biblStruct coords="11,70.87,525.05,218.27,8.64;11,81.78,536.01,208.60,8.64;11,81.78,546.97,209.01,8.64;11,81.78,557.93,207.36,8.64;11,81.78,568.89,201.18,8.64" xml:id="b40">
	<analytic>
		<title level="a" type="main" coords="11,130.39,546.97,160.39,8.64;11,81.78,557.93,123.27,8.64">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coords="11,213.06,557.93,76.07,8.64;11,81.78,568.89,124.42,8.64">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837"/>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits rea- soning in large language models. Advances in neural information processing systems, 35:24824-24837.</note>
</biblStruct>

<biblStruct coords="11,70.87,590.87,218.27,8.64;11,81.31,601.83,207.99,8.64;11,81.78,612.79,207.36,8.64;11,81.78,623.75,165.45,8.64" xml:id="b41">
	<analytic>
		<title level="a" type="main" coords="11,145.27,601.83,144.03,8.64;11,81.78,612.79,138.16,8.64">Probabilistic recursive reasoning for multi-agent reinforcement learning</title>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rui</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,238.23,612.79,50.91,8.64;11,81.78,623.75,161.32,8.64">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Ying Wen, Yaodong Yang, Rui Luo, Jun Wang, and Wei Pan. 2019. Probabilistic recursive reasoning for multi-agent reinforcement learning. In International Conference on Learning Representations.</note>
</biblStruct>

<biblStruct coords="11,70.87,645.73,219.52,8.64;11,81.78,656.69,208.60,8.64;11,81.78,667.65,209.01,8.64;11,81.78,678.61,207.36,8.64;11,81.78,689.57,207.36,8.64;11,81.78,700.53,156.77,8.64" xml:id="b42">
	<analytic>
		<title level="a" type="main" coords="11,193.61,667.65,97.17,8.64;11,81.78,678.61,156.23,8.64">Theory of mind and selfpresentation in human-llm interactions</title>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Wester</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rune</forename><forename type="middle">Møberg</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sander</forename><surname>De Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naja</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kathrine</forename><forename type="middle">Kollerup</forename><surname>Als</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Helena</forename><surname>Bøjer Djernaes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Niels</forename><surname>Van Berkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,257.03,678.61,32.10,8.64;11,81.78,689.57,207.36,8.64;11,81.78,700.53,152.31,8.64">Adjunct Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Joel Wester, Rune Møberg Jacobsen, Sander de Jong, Naja Kathrine Kollerup Als, Helena Bøjer Djernaes, and Niels van Berkel. 2024. Theory of mind and self- presentation in human-llm interactions. In Adjunct Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems.</note>
</biblStruct>

<biblStruct coords="11,70.87,722.51,220.01,8.64;11,81.47,733.47,209.32,8.64;11,81.31,744.43,207.83,8.64;11,81.78,755.39,207.36,8.64;11,81.78,766.35,139.07,8.64" xml:id="b43">
	<analytic>
		<title level="a" type="main" coords="11,140.69,744.43,148.45,8.64;11,81.78,755.39,163.34,8.64">Too many cooks: Bayesian inference for coordinating multi-agent collaboration</title>
		<author>
			<persName coords=""><forename type="first">Sarah</forename><forename type="middle">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rose</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12525</idno>
	</analytic>
	<monogr>
		<title level="j" coords="11,252.57,755.39,36.57,8.64;11,81.78,766.35,70.69,8.64">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="414" to="432"/>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Sarah A. Wu, Rose E. Wang, James A. Evans, Joshua B. Tenenbaum, David C. Parkes, and Max Kleiman- Weiner. 2021. Too many cooks: Bayesian inference for coordinating multi-agent collaboration. Topics in Cognitive Science, 13(2):414-432.</note>
</biblStruct>

<biblStruct coords="11,306.14,75.34,219.51,8.64;11,317.05,86.30,208.60,8.64;11,317.05,97.26,209.01,8.64;11,317.05,108.22,208.60,8.64;11,316.86,119.18,208.80,8.64;11,317.05,130.13,207.36,8.64;11,316.69,141.09,209.37,8.64;11,317.05,152.05,207.36,8.64;11,317.05,163.01,208.60,8.64;11,316.47,173.97,207.93,8.64;11,317.05,184.93,207.36,8.64;11,317.05,195.89,75.02,8.64" xml:id="b44">
	<monogr>
		<author>
			<persName coords=""><forename type="first">An</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Baosong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dayiheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Huan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianhong</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaxi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Keqin</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kexin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingfeng</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Qin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rui</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Runji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tingyu</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xingzhang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yichang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuqiong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zeyu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhenru</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zihan</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.15115</idno>
		<title level="m" coords="11,362.38,184.93,98.28,8.64">Qwen2.5 technical report</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jian- hong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tian- hao Li, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2024. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115.</note>
</biblStruct>

<biblStruct coords="11,306.14,215.81,218.52,8.64;11,317.05,226.77,209.10,8.64;11,317.05,237.73,207.36,8.64;11,317.05,248.69,168.84,8.64" xml:id="b45">
	<monogr>
		<title level="m" type="main" coords="11,317.05,237.73,207.36,8.64;11,317.05,248.69,26.81,8.64">React: Synergizing reasoning and acting in language models</title>
		<author>
			<persName coords=""><forename type="first">Shunyu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03629</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629.</note>
</biblStruct>

<biblStruct coords="11,306.14,268.61,219.52,8.64;11,317.05,279.57,207.36,8.64;11,317.05,290.53,209.10,8.64;11,317.05,301.49,133.98,8.64" xml:id="b46">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Zihao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiarui</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianhao</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhe</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.18013</idno>
		<title level="m" coords="11,446.83,279.57,77.59,8.64;11,317.05,290.53,204.76,8.64">A survey on recent advances in llm-based multi-turn dialogue systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zihao Yi, Jiarui Ouyang, Yuwen Liu, Tianhao Liao, Zhe Xu, and Ying Shen. 2024. A survey on recent advances in llm-based multi-turn dialogue systems. arXiv preprint arXiv:2402.18013.</note>
</biblStruct>

<biblStruct coords="11,306.14,321.42,218.27,8.64;11,316.74,332.38,209.32,8.64;11,317.05,343.33,207.36,8.64;11,317.05,354.29,186.16,8.64" xml:id="b47">
	<analytic>
		<title level="a" type="main" coords="11,500.04,332.38,26.02,8.64;11,317.05,343.33,207.36,8.64;11,317.05,354.29,72.09,8.64">Learning zero-shot cooperation with humans, assuming humans are biased</title>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaxuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weilin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Botian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,407.51,354.29,91.17,8.64">ICLR. OpenReview.net</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Chao Yu, Jiaxuan Gao, Weilin Liu, Botian Xu, Hao Tang, Jiaqi Yang, Yu Wang, and Yi Wu. 2023. Learn- ing zero-shot cooperation with humans, assuming humans are biased. In ICLR. OpenReview.net.</note>
</biblStruct>

<biblStruct coords="11,306.14,374.22,220.01,8.64;11,317.05,385.18,207.36,8.64;11,317.05,396.14,75.02,8.64" xml:id="b48">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Ping</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ilia</forename><surname>Kulikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.06023</idno>
		<title level="m" coords="11,317.05,385.18,138.25,8.64">Distilling system 2 into system 1</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Ping Yu, Jing Xu, Jason Weston, and Ilia Kulikov. 2024. Distilling system 2 into system 1. arXiv preprint arXiv:2407.06023.</note>
</biblStruct>

<biblStruct coords="11,306.14,416.06,219.52,8.64;11,317.05,427.02,207.36,8.64;11,317.05,437.98,209.01,8.64;11,317.05,448.94,207.36,8.64;11,317.05,459.90,207.36,8.64;11,317.05,470.86,208.60,8.64;11,317.05,481.82,82.46,8.64" xml:id="b49">
	<analytic>
		<title level="a" type="main" coords="11,474.87,437.98,51.19,8.64;11,317.05,448.94,207.36,8.64;11,317.05,459.90,87.06,8.64">a. Proagent: building proactive cooperative agents with large language models</title>
		<author>
			<persName coords=""><forename type="first">Ceyao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kaijie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Siyi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zihao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guanghe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yihang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhaowei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anji</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coords="11,422.89,459.90,101.52,8.64;11,317.05,470.86,151.79,8.64">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="17591" to="17599"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, et al. 2024a. Proa- gent: building proactive cooperative agents with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 17591-17599.</note>
</biblStruct>

<biblStruct coords="11,306.14,501.74,218.27,8.64;11,317.05,512.70,209.02,8.64;11,317.05,523.66,207.71,8.64;11,317.05,534.62,207.36,8.64;11,317.05,545.58,207.35,8.64;11,316.69,556.54,201.09,8.64" xml:id="b50">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Shao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xihuai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wenhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yongshan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Landi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dakuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xinbing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2409.08811</idno>
		<title level="m" coords="11,466.27,523.66,58.49,8.64;11,317.05,534.62,207.36,8.64;11,317.05,545.58,207.35,8.64;11,316.69,556.54,59.82,8.64">Mutual theory of mind in human-ai collaboration: An empirical study with llm-driven ai agents in a real-time shared workspace task</title>
		<imprint>
			<date type="published" when="2024">2024b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Shao Zhang, Xihuai Wang, Wenhao Zhang, Yongshan Chen, Landi Gao, Dakuo Wang, Weinan Zhang, Xin- bing Wang, and Ying Wen. 2024b. Mutual theory of mind in human-ai collaboration: An empirical study with llm-driven ai agents in a real-time shared workspace task. arXiv preprint arXiv:2409.08811.</note>
</biblStruct>

<biblStruct coords="11,306.14,576.46,219.52,8.64;11,316.47,587.42,209.18,8.64;11,316.47,598.38,209.32,8.64;11,317.05,609.34,207.36,8.64;11,317.05,620.30,207.36,8.64;11,317.05,631.26,207.36,8.64;11,317.05,642.21,208.60,8.64;11,317.05,653.17,207.36,8.64;11,317.05,664.13,209.02,8.64;11,317.05,675.09,16.33,8.64" xml:id="b51">
	<analytic>
		<title level="a" type="main" coords="11,482.96,598.38,42.83,8.64;11,317.05,609.34,207.36,8.64;11,317.05,620.30,49.77,8.64">Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization</title>
		<author>
			<persName coords=""><forename type="first">Wenqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ke</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mengna</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yongliang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guiyang</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zeqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.acl-long.292</idno>
	</analytic>
	<monogr>
		<title level="m" coords="11,390.90,620.30,133.51,8.64;11,317.05,631.26,207.36,8.64;11,317.05,642.21,204.12,8.64">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024-08-11">2024. August 11-16, 2024</date>
			<biblScope unit="page" from="5348" to="5375"/>
		</imprint>
	</monogr>
	<note type="raw_reference">Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, and Weiming Lu. 2024c. Agent-pro: Learning to evolve via policy-level reflection and optimization. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 5348-5375. Association for Computational Linguis- tics.</note>
</biblStruct>

<biblStruct coords="11,306.14,695.02,219.92,8.64;11,317.05,705.97,208.60,8.64;11,317.05,716.93,207.35,8.64;11,317.05,727.89,207.61,8.64;11,317.05,738.85,109.05,8.64" xml:id="b52">
	<monogr>
		<title level="m" type="main" coords="11,476.31,716.93,48.10,8.64;11,317.05,727.89,177.06,8.64">A survey on efficient inference for large language models</title>
		<author>
			<persName coords=""><forename type="first">Zixuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuefei</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ke</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tianyu</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiaming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shiyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuming</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhihang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiuhong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.14294</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note type="raw_reference">Zixuan Zhou, Xuefei Ning, Ke Hong, Tianyu Fu, Ji- aming Xu, Shiyao Li, Yuming Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, et al. 2024. A survey on efficient inference for large language models. arXiv preprint arXiv:2404.14294.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>